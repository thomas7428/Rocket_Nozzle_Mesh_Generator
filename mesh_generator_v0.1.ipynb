{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a37f25d",
   "metadata": {},
   "source": [
    "# Rocket Engine Nozzle Mesh Generator (Beginner-Friendly Guide)\n",
    "\n",
    "This Jupyter Notebook helps you **generate 2D and 3D mesh geometries** for rocket engine nozzles, focusing on real datas (not included), but also allowing for custom designs. It uses the [GMSH](https://gmsh.info/) Python API for geometry creation and meshing, and supports advanced features like cooling channels and reinforcement ribs.\n",
    "\n",
    "---\n",
    "\n",
    "## What Does This Notebook Do?\n",
    "\n",
    "- **Loads real or custom nozzle geometry data** (from CSV or parameters)\n",
    "- **Builds the nozzle shape** using mathematical curves or real data\n",
    "- **Adds cooling channels and reinforcements** to the nozzle wall\n",
    "- **Creates 3D geometry** by revolving 2D profiles around the nozzle axis\n",
    "- **Generates a mesh** suitable for simulation (CFD, FEA, etc.)\n",
    "- **Exports the mesh** to standard formats (`.msh`, `.stl`) for use in other tools\n",
    "\n",
    "---\n",
    "\n",
    "## Main Features\n",
    "\n",
    "- **Real Data Integration:** Use real rocket engine data for accurate geometry.\n",
    "- **Custom Geometry:** Easily switch to your own nozzle parameters.\n",
    "- **Profile Generation:** Supports BÃ©zier and de Laval curves for smooth shapes.\n",
    "- **Cooling Channels:** Automatically create and subtract cooling circuits from the nozzle wall.\n",
    "- **Radial Reinforcements:** Add reinforcement ribs at specified positions.\n",
    "- **Physical Group Management:** Keeps track of different parts of the geometry for easy simulation setup.\n",
    "- **Visualization:** Plots profiles and geometry for easy verification.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "### 1. **Dependencies**\n",
    "\n",
    "The notebook uses these Python packages:\n",
    "- `gmsh`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "- `scipy`\n",
    "- `pandas`\n",
    "- `math`\n",
    "\n",
    "If any are missing, the notebook will try to install them automatically.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Workflow Overview**\n",
    "\n",
    "1. **Imports & Checks:**  \n",
    "   Ensures all required packages are available.\n",
    "\n",
    "2. **Load Geometry Data:**  \n",
    "   - Use real Vulcain 2.1 data (from CSV) or\n",
    "   - Define your own nozzle parameters.\n",
    "\n",
    "3. **Set Parameters:**  \n",
    "   - Wall thickness, number of cooling channels, mesh resolution, etc.\n",
    "\n",
    "4. **Initialize GMSH:**  \n",
    "   - Set mesh size and options.\n",
    "\n",
    "5. **Geometry Creation:**  \n",
    "   - Build 2D profiles for the nozzle and channels.\n",
    "   - Revolve profiles to create 3D geometry.\n",
    "\n",
    "6. **Add Features:**  \n",
    "   - Add cooling channels and reinforcements.\n",
    "\n",
    "7. **Mesh Generation:**  \n",
    "   - Generate and export the mesh.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Basic Example**\n",
    "\n",
    "To generate a nozzle with a cooling circuit, run:\n",
    "\n",
    "```python\n",
    "mesh_generator(\"Solid\", path_for_save=\"Rocket_Engine_Meshes/\", debug=True)\n",
    "```\n",
    "\n",
    "You can also generate just the inner fluid, outer fluid, or only the cooling channels by changing the argument to `\"Inner_Fluid\"`, `\"Outer_Fluid\"`, or `\"Cooling_Channels\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Visualization**\n",
    "\n",
    "- The notebook plots the nozzle and channel profiles so you can check the geometry before meshing.\n",
    "- You can open the generated `.msh` or `.stl` files in the GMSH GUI for 3D inspection.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Customization Tips**\n",
    "\n",
    "- **Change Geometry:**  \n",
    "  Edit the parameters or CSV files to use your own nozzle shape.\n",
    "- **Adjust Mesh Quality:**  \n",
    "  Change mesh size parameters for finer or coarser meshes.\n",
    "- **Add/Remove Features:**  \n",
    "  Set the number of cooling channels or reinforcements as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **No Elements in Volume Error:**  \n",
    "  This means the geometry is not closed or valid. Check your parameters and input data.\n",
    "- **Mesh Not Exported:**  \n",
    "  Make sure all geometry steps complete without errors before meshing.\n",
    "\n",
    "---\n",
    "\n",
    "**Tip:**  \n",
    "If you are new to GMSH or mesh generation, start by running the notebook as-is, then gradually change parameters and observe the effects on the geometry and mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import gmsh\n",
    "except ImportError:\n",
    "    print(\"gmsh is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install gmsh\")\n",
    "    import gmsh\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    print(\"matplotlib is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install matplotlib\")\n",
    "    import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    print(\"numpy is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install numpy\")\n",
    "    import numpy as np\n",
    "    \n",
    "try: \n",
    "    import scipy\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "except ImportError:\n",
    "    print(\"scipy is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install scipy\")\n",
    "    import scipy\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"pandas is not installed. Trying to install it...\")\n",
    "    %pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "try:\n",
    "    import math\n",
    "except ImportError:\n",
    "    print(\"math is not installed. Trying to install it...\")\n",
    "    %pip install math\n",
    "    import math\n",
    "    \n",
    "try:\n",
    "    import scipy.interpolate\n",
    "except ImportError:\n",
    "    print(\"scipy.interpolate is not installed. Trying to install it...\")\n",
    "    %pip install scipy\n",
    "    import scipy.interpolate\n",
    "\n",
    "try: \n",
    "    import threading\n",
    "except ImportError:\n",
    "    print(\"threading is not installed. Trying to install it...\")\n",
    "    %pip install threading\n",
    "    import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766aed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === CSV data extractor === ###\n",
    "\n",
    "def csv_extractor(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls):\n",
    "    \"\"\"\n",
    "    This function extracts the geometry from a CSV file and returns the values as a dataframe.\n",
    "    input: \n",
    "    file_name: names of the CSV files\n",
    "    columns_names: list of column names to extract\n",
    "    output: values: dataframes containing the values from the CSV file \n",
    "    \"\"\"\n",
    "    # Read the CSV file with specified column names\n",
    "    # The first row is the header, so we need to skip it\n",
    "    df_interior = pd.read_csv(file_name_interior, names=columns_names_interior, header=0)\n",
    "    df_walls = pd.read_csv(file_name_walls, names=columns_names_walls, header=0)\n",
    "    \n",
    "    return df_interior, df_walls\n",
    "\n",
    "def width_by_method(x, method, function, derivative, debug = False):\n",
    "    if method == \"ortho\":\n",
    "        return function(x)\n",
    "    if method == \"angle\":\n",
    "        # Calculate the angle using the derivative\n",
    "        angle = math.atan(derivative(x))\n",
    "        # Calculate the width using the angle\n",
    "        y_factor = math.cos(angle)\n",
    "        initial_width = function(x) * y_factor\n",
    "        x_factor = math.sin(angle)\n",
    "        x_used = x + x_factor* initial_width\n",
    "        width = function(x_used) * y_factor\n",
    "        if debug:\n",
    "            return width, x_factor * initial_width\n",
    "        return width\n",
    "\n",
    "def geometry_creator(dataframe_interior, dataframe_wall, method, debug = False):\n",
    "    \"\"\"\n",
    "    This function creates the geometry from the dataframe and returns the values as a list.\n",
    "    input: \n",
    "    dataframe: dataframe containing the values from the CSV file\n",
    "    method: method for the extraction of the geometry for the angle : \"ortho\" or \"angle\"\n",
    "    output: values: list containing the values from the CSV file \n",
    "    \"\"\"\n",
    "    # Extract the values from the dataframe\n",
    "    x_interior = dataframe_interior[\"x\"].values\n",
    "    y_interior = dataframe_interior[\"y\"].values\n",
    "    x_walls = dataframe_wall[\"x\"].values\n",
    "    channel_height = dataframe_wall[\"channel height\"].values\n",
    "    channel_width = dataframe_wall[\"channel width\"].values\n",
    "    hot_gas_wall = dataframe_wall[\"hot gas wall\"].values\n",
    "    outer_thickness = dataframe_wall[\"outer thickness\"].values\n",
    "    number_channels = dataframe_wall[\"number channels\"].values\n",
    "\n",
    "    # Interpolate functions for the different values\n",
    "    interior_func = scipy.interpolate.interp1d(x_interior, y_interior, kind='linear', fill_value=\"extrapolate\")\n",
    "    channel_height_func = scipy.interpolate.interp1d(x_walls, channel_height, kind='linear', fill_value=\"extrapolate\")\n",
    "    channel_width_func = scipy.interpolate.interp1d(x_walls, channel_width, kind='linear', fill_value=\"extrapolate\")\n",
    "    hot_gas_wall_func = scipy.interpolate.interp1d(x_walls, hot_gas_wall, kind='linear', fill_value=\"extrapolate\")\n",
    "    outer_thickness_func = scipy.interpolate.interp1d(x_walls, outer_thickness, kind='linear', fill_value=\"extrapolate\")\n",
    "    number_channels_func = scipy.interpolate.interp1d(x_walls, number_channels, kind='linear', fill_value=\"extrapolate\")\n",
    "        \n",
    "    # Calculate the derivatives of the functions to get their angles\n",
    "    interior_derivative = np.gradient(interior_func(x_interior), x_interior)\n",
    "    channel_height_derivative = np.gradient(channel_height_func(x_walls), x_walls)\n",
    "    hot_gas_wall_derivative = np.gradient(hot_gas_wall_func(x_walls), x_walls)\n",
    "    outer_thickness_derivative = np.gradient(outer_thickness_func(x_walls), x_walls)\n",
    "\n",
    "    # Interpolate the derivatives to get the values at the same points as the functions\n",
    "    interior_derivative = scipy.interpolate.interp1d(x_interior, interior_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "    channel_height_derivative = scipy.interpolate.interp1d(x_walls, channel_height_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "    hot_gas_wall_derivative = scipy.interpolate.interp1d(x_walls, hot_gas_wall_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "    outer_thickness_derivative = scipy.interpolate.interp1d(x_walls, outer_thickness_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "        \n",
    "    # Create a new dataframe with the new values\n",
    "    new_dataframe = pd.DataFrame(columns=[\"x\", \"nozzle inner wall\", \"nozzle outer wall\", \"channel inner wall\", \"channel outer wall\", \"channel width\", \"number channels\"])\n",
    "    for i,x in enumerate(x_interior):\n",
    "        # We push x\n",
    "        new_dataframe.loc[i, \"x\"] = x\n",
    "        # First layer : the interior wall which is the first so the derivative is 0. We will jsut use the ortho method\n",
    "        current_width = width_by_method(x, \"ortho\", interior_func, lambda x: 0)\n",
    "        new_dataframe.loc[i, \"nozzle inner wall\"] = current_width\n",
    "        # Second layer : the inner wall of the channel\n",
    "        current_width = current_width +  width_by_method(x, method, hot_gas_wall_func, interior_derivative)\n",
    "        new_dataframe.loc[i, \"channel inner wall\"] = current_width\n",
    "        # Third layer : the outer wall of the channel\n",
    "        current_width = current_width + width_by_method(x, method, channel_height_func, hot_gas_wall_derivative)\n",
    "        new_dataframe.loc[i, \"channel outer wall\"] = current_width\n",
    "        # Fourth layer : the outer wall of the channel\n",
    "        current_width = current_width + width_by_method(x, method, outer_thickness_func, channel_height_derivative)\n",
    "        new_dataframe.loc[i, \"nozzle outer wall\"] = current_width\n",
    "        \n",
    "        # Other values\n",
    "        new_dataframe.loc[i, \"channel width\"] = channel_width_func(x)\n",
    "        new_dataframe.loc[i, \"number channels\"] = int(number_channels_func(x))\n",
    "    \n",
    "    # Debug: plot the new values\n",
    "    if debug:\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"nozzle inner wall\"], label=\"nozzle inner wall\")\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"nozzle outer wall\"], label=\"nozzle outer wall\")\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"channel inner wall\"], label=\"channel inner wall\")\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"channel outer wall\"], label=\"channel outer wall\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"values\")\n",
    "        plt.title(\"New geometry values\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(new_dataframe)\n",
    "    \n",
    "    return new_dataframe\n",
    "\n",
    "def geometry_dataframe(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls, method, debug = False, minimum_caracteristic_length = False):\n",
    "    \"\"\"\n",
    "    This function creates the geometry from the dataframe and returns the values as a list.\n",
    "    input: \n",
    "    file_name: names of the CSV files\n",
    "    columns_names: list of column names to extract\n",
    "    method: method for the extraction of the geometry for the angle : \"ortho\" or \"angle\"\n",
    "    output: values: list containing the values from the CSV file \n",
    "    \"\"\"\n",
    "    # Extract the geometry from the CSV file\n",
    "    values = csv_extractor(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls)\n",
    "    # Create the geometry\n",
    "    geometry = geometry_creator(values[0], values[1], method)\n",
    "    # Get the minimum caracteristic length\n",
    "    if minimum_caracteristic_length:\n",
    "        min_carac_length = min(min(values[1][\"channel width\"]), min(values[1][\"channel height\"]), min(values[1][\"outer thickness\"]), min(values[1][\"hot gas wall\"]))\n",
    "        return geometry, min_carac_length\n",
    "    return geometry\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c61f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Parameters for the rocket engine geometry === ###\n",
    "\n",
    "DEBUG = False\n",
    "proximity_tol = 0.0001\n",
    "MULTITHREADING = 10\n",
    "DIM_MESH = 3  # Dimension of mesh generation (2 will give you a 3D mesh but possibly with false positive)\n",
    "\n",
    "# Parameters for extracting the data from the CSV files\n",
    "current_directory = os.getcwd()\n",
    "file_name_interior = \"nozzle_curve.csv\" #\"hgw_input_placeholder.csv\"\n",
    "file_name_walls = \"nozzle_layers.csv\" #\"geometry_input_placeholder_alt.csv\"\n",
    "columns_names_interior = [\"x\",\"y\"]\n",
    "columns_names_walls = [\"x\",\"channel height\",\"channel width\",\"hot gas wall\",\"outer thickness\",\"number channels\"]\n",
    "extracting_method=\"angle\" # Method for the extraction of the geometry for the angle : \"ortho\" or \"angle\"\n",
    "Multiplicator_X_CSV = 1.0\n",
    "\n",
    "# Extract the geometry from the CSV file\n",
    "geometry_data, min_carac_length = geometry_dataframe(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls, extracting_method, debug = False, minimum_caracteristic_length = True) \n",
    "\n",
    "# Multiply the length by N\n",
    "geometry_data[\"x\"] = geometry_data[\"x\"] * Multiplicator_X_CSV\n",
    "\n",
    "# We create a basic geometry with only X and Y in case of a need of simplicity\n",
    "X_CSV = geometry_data[\"x\"].values\n",
    "Y_CSV = geometry_data[\"nozzle inner wall\"].values\n",
    "\n",
    "# Adapt X_Parameters and D_Parameters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_CSV, Y_CSV, 'r-', label='CSV Basic Profile')\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "plt.axis('equal')\n",
    "plt.title('Basic geometry')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Parameters direclty from the CSV data\n",
    "X_Start = X_CSV[0]  # Starting point of the nozzle\n",
    "X_Exit = X_CSV[-1]  # Exit point\n",
    "length = X_CSV[-1] - X_CSV[0]  # Length of the engine\n",
    "chamber_length = X_CSV[np.where(Y_CSV == Y_CSV.min())[0][0]] - X_CSV[0]\n",
    "nozzle_length = length - chamber_length\n",
    "X_Throat = X_Start + chamber_length  # Adjust the throat position based on the chamber length\n",
    "D_Start = Y_CSV[0] * 2 # Diameter at the start of the nozzle\n",
    "D_Throat = Y_CSV.min() * 2  # Diameter at the throat\n",
    "D_Exit = Y_CSV[-1] * 2 # Diameter at the exit\n",
    "\n",
    "# Define the nozzle parameters\n",
    "X_Parameters_Nozzle = [X_Start, X_Throat, X_Exit]  # X coordinates of the nozzle\n",
    "D_Parameters_Nozzle = [D_Start, D_Throat, D_Exit]  # Diameter parameters of the nozzle\n",
    "Nozzle_Angle_Revolution = np.pi / 4  # Angle of revolution for the nozzle\n",
    "Nozzle_Modificator_Inner = lambda x: 0.\n",
    "Nozzle_Modificator_Outer = lambda x: 0.\n",
    "\n",
    "# Define the cooling circuit parameters\n",
    "X_Cooling_Start = X_Start  # Starting point of the cooling circuit\n",
    "X_Cooling_Throat = X_Throat  # Throat position of the cooling circuit\n",
    "X_Cooling_Exit = X_Exit  # Exit position of the cooling circuit\n",
    "X_Cooling_Parameters = [X_Cooling_Start, X_Cooling_Throat, X_Cooling_Exit]  # X coordinates of the cooling circuit\n",
    "Cooling_Channel_Angle_Size = - np.pi / 16  # Angle size of the cooling channel\n",
    "Cooling_Channel_Extension = chamber_length * 0.1  # Extension of the cooling channel\n",
    "Cooling_Channel_Modificator_Inner = lambda x: 0.\n",
    "Cooling_Channel_Modificator_Outer = lambda x: 0.\n",
    "Cooling_Channel_Angle_Offset = 0.0 # Angle offset of the cooling channel as a multiplier between two channels. By default at 0.0 the first channel intersect with the side. ATTENTION, it could lead to topological problems if not used properly.\n",
    "\n",
    "# Define the reinforcement parameters\n",
    "Radial_Reinforcement_Width = 0.003  # Width of the radial reinforcement\n",
    "Radial_Reinforcement_Height = 0.01  # Height of the radial reinforcement\n",
    "Radial_Reinforcement_Number = 20 # Number of radial reinforcements\n",
    "Radial_Reinforcement_Density = lambda x: x * 0  # Density of the radial reinforcement (x*0 to get a uniform distribution) It needs to return a numpy array !!\n",
    "Radial_Reinforcement_Margin_Entry = 0.01  # Margin of the radial reinforcement at the entry\n",
    "Radial_Reinforcement_Margin_Exit = 0.01  # Margin of the radial reinforcement at the exit\n",
    "\n",
    "# Profile treatment Parameters\n",
    "number_of_points_profile = 150  # Number of points for the nozzle profile\n",
    "ratio_for_accel_points = 0.5  # Ratio of points selected for the acceleration in a reduction of points. The rest is uniformly distributed\n",
    "reduce_points_method = 'density' # Method to reduce points: 'density' or 'accel' \n",
    "\n",
    "# Output parameters\n",
    "Radius_Study_Margin = 0.1 # Added space for the exterior radius\n",
    "\n",
    "# Initialize some variables\n",
    "Angle_Revolution = Nozzle_Angle_Revolution\n",
    "start_tag = 1\n",
    "\n",
    "# Output files parameters\n",
    "output_folder = os.path.join(current_directory, \"Rocket_Engine_Meshes/\")\n",
    "output_in_stl = True\n",
    "output_in_msh = True\n",
    "other_type_output = None # Specify a .[type] to output the geometry in this format. If None, no other output is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ae13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Parameters for GMSH === ###\n",
    "def GMSH_initialise(caracteristic_length_min=0.0005, caracteristic_length_max=None, thread_number = 1):\n",
    "    \"\"\"\n",
    "    Initialize GMSH with specific options.\n",
    "    \"\"\"\n",
    "    # Check if caracteristic_length_max is None. If it is, set it to 100 times caracteristic_length_min\n",
    "    if caracteristic_length_max is None:\n",
    "        caracteristic_length_max = 1000*caracteristic_length_min\n",
    "        \n",
    "    # Initialize GMSH\n",
    "    gmsh.initialize()\n",
    "    \n",
    "    gmsh.option.setNumber(\"General.Verbosity\", 5)  # 2=Warning, 3=Info, 4=Debug, 5=Trace\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthMax\", caracteristic_length_max)  # maille max de 0.05\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeFromCurvature\", 1)  # Adapt mesh size to curvature\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthFromCurvature\", 1)  # Enable mesh size adaptation based on curvature\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthMin\", caracteristic_length_min)  # maille min de 0.0005\n",
    "    gmsh.option.setNumber(\"Mesh.Algorithm\", 6)  # 6 = use the Frontal-Delaunay algorithm for mesh generation\n",
    "    gmsh.option.setNumber(\"Mesh.MinimumElementsPerTwoPi\", 20)  # Minimum number of mesh elements per 2*pi radians (for circular features)\n",
    "    #gmsh.option.setNumber(\"Mesh.Smoothing\", 0)\n",
    "    gmsh.option.setNumber(\"Mesh.Optimize\", 1)\n",
    "    #gmsh.option.setNumber(\"Mesh.OptimizeNetgen\", 0) \n",
    "    #gmsh.option.setNumber(\"Mesh.SecondOrderLinear\", 0)\n",
    "    #gmsh.option.setNumber(\"Mesh.CharacteristicLengthExtendFromBoundary\", 0)  # Do not extend mesh size from boundary\n",
    "    gmsh.option.setNumber(\"General.NumThreads\", thread_number)# for parallel 3D meshing\n",
    "    #gmsh.option.setNumber(\"Mesh.SubdivisionAlgorithm\", 1)\n",
    "    '''\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthMax\", 0.5)  # maille max de 0.05\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthMin\", 0.00005)  # maille min de 0.0005\n",
    "    gmsh.option.setNumber(\"Mesh.Algorithm\", 6)  # 6 = use the Frontal-Delaunay algorithm for mesh generation\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthFromCurvature\", 1)  # Enable mesh size adaptation based on curvature\n",
    "    gmsh.option.setNumber(\"Mesh.MinimumElementsPerTwoPi\", 30)  # Minimum number of mesh elements per 2*pi radians (for circular features)\n",
    "    gmsh.option.setNumber(\"Mesh.Optimize\", 1)  # Mesh optimization\n",
    "    gmsh.option.setNumber(\"Mesh.OptimizeNetgen\", 1)  # Netgen mesh optimization\n",
    "    gmsh.option.setNumber(\"Mesh.Smoothing\", 10)  # Mesh smoothing\n",
    "    gmsh.option.setNumber(\"Mesh.SecondOrderLinear\", 0)  # Disable second order linear elements\n",
    "    gmsh.option.setNumber(\"Mesh.SaveAll\", 1)  # Save all entities\n",
    "    gmsh.option.setNumber(\"Mesh.SurfaceFaces\", 1)  # Save surface faces in the .msh file\n",
    "    gmsh.option.setNumber(\"Mesh.VolumeFaces\", 1)  # Save volume faces in the .msh file\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeExtendFromBoundary\", 0)  # Do not extend mesh size from boundary\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeFromPoints\", 1)  # Use mesh size from points\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeFromCurvature\", 1)  # Adapt mesh size to curvature\n",
    "    gmsh.option.setNumber(\"Mesh.RandomFactor\", 1e-6)  # Add small noise to avoid degenerate elements\n",
    "    '''\n",
    "    \n",
    "    print(\"=== GMSH initialized ===\")\n",
    "    print(f\"Minumum caracterist length used : {caracteristic_length_min} \")\n",
    "    print(f\"Maximum caracterist length used : {caracteristic_length_max} \")\n",
    "    print(f\"Number of threads used : {thread_number}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Bible of the geometry === ###\n",
    "\n",
    "def create_bible():\n",
    "    \"\"\"\n",
    "    This function creates the bible of the geometry.\n",
    "    The Bible contains all the data of the geometry in a dataframe.\n",
    "    The columns are:\n",
    "    - dimtag_entity: the tag of the geometry in the format [(dim, tag)]\n",
    "    - entity_name: the name of the geometry (not used by GMSH), theoretically the name of the physical group in the format [name]\n",
    "    - entity_coordinates: the coordinates of the geometry in the format [x, y, z]\n",
    "    - entity_dimension: the dimension of the geometry in the format [x_length, y_length, z_length]\n",
    "    - dimtag_group: the tag of the physical group of the entity in the format [(dim, tag)]\n",
    "    - group_name: the name of the physical group of the entity ine format [name]\n",
    "    - dimtag_parent: the tag of the parent entity in the format [(dim, tag)] (usually a volume)\n",
    "    \"\"\"\n",
    "    # Create the bible\n",
    "    bible = pd.DataFrame(columns=[\"dimtag_entity\", \"entity_name\", \"entity_coordinates\", \"entity_dimension\", \"dimtag_group\", \"group_name\", \"dimtag_parent\"])\n",
    "    return bible\n",
    "\n",
    "def print_bible(bible):\n",
    "    \"\"\"\n",
    "    This function prints the bible of the geometry.\n",
    "    \"\"\"\n",
    "    print(\"=== Bible of the geometry: ===\")\n",
    "    print(bible)\n",
    "\n",
    "def dimtag_to_tuple(dimtag, debug=False):\n",
    "    \"\"\"\n",
    "    This function converts a dimtag to a tuple. \n",
    "    It will also convert the element to int.\n",
    "    \"\"\"\n",
    "    if dimtag is None or len(dimtag) == 0:\n",
    "        return None\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Converting dimtag {dimtag} to tuple\")\n",
    "    dim = int(dimtag[0])\n",
    "    tag = int(dimtag[1])\n",
    "    return (dim, tag)\n",
    "    \n",
    "def write_data_to_bible(data, column, bible_index, overwrite, debug=False):\n",
    "    # Get Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Get the values at the index\n",
    "    values = Bible.loc[bible_index, column]\n",
    "    # Check if the values are None\n",
    "    if values is None or overwrite:\n",
    "        # If they are None or we want to overwrite, we write the data\n",
    "        Bible.loc[bible_index, column] = data\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Writing {data} to {column} at index {bible_index}\")\n",
    "    return None  \n",
    "\n",
    "def add_to_bible(dimtag_entity=None, entity_name=None, entity_coordinates=None, entity_dimension=None, dimtag_group=None, group_name=None, dimtag_parent=None, overwrite=False, debug=False):\n",
    "    \"\"\"\n",
    "    Add a new element to the bible of the geometry.\n",
    "    It will automatically try to find corresponding existing elements in the bible via dimtags and compelte the data or overwrite them.\n",
    "    If it doesn't find any, it will create a new element.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    \n",
    "    # Convert dimtag_entity and dimtag_group to tuples if they are not None\n",
    "    dimtag_entity = dimtag_to_tuple(dimtag_entity, debug=debug)\n",
    "    dimtag_group = [dimtag_to_tuple(dimtag, debug=debug) for dimtag in dimtag_group] if dimtag_group is not None else None\n",
    "    \n",
    "    # Check dimension\n",
    "    if dimtag_entity is not None and dimtag_entity[0] < 2:\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Skipping entity {dimtag_entity} because its dimension is lower than 2\")\n",
    "        return Bible\n",
    "    \n",
    "    \n",
    "    # Define the data to write\n",
    "    Data_to_write = {\n",
    "        \"dimtag_entity\": dimtag_entity,\n",
    "        \"entity_name\": entity_name,\n",
    "        \"entity_coordinates\": entity_coordinates,\n",
    "        \"entity_dimension\": entity_dimension,\n",
    "        \"dimtag_group\": dimtag_group,\n",
    "        \"group_name\": group_name,\n",
    "        \"dimtag_parent\": dimtag_parent\n",
    "    }\n",
    "    \n",
    "    # Check if the element already exists in the bible by dimtag_entity\n",
    "    index = None\n",
    "    if dimtag_entity is not None:\n",
    "        existing_element = filter_bible(dimtag_entity=dimtag_entity)\n",
    "        if not existing_element.empty:\n",
    "            index = existing_element.index[0]\n",
    "    elif dimtag_group is not None and index is None:\n",
    "        # If the element does not exist, we check if it exists by dimtag_group\n",
    "        existing_element = filter_bible(dimtag_group=dimtag_group)\n",
    "        if not existing_element.empty:\n",
    "                index = existing_element.index[0]\n",
    "    if index is not None:\n",
    "        # If the element exists, we update the data\n",
    "        for col, val in Data_to_write.items():\n",
    "            if val is not None:\n",
    "                # If the value is None and we have a new value, we write it\n",
    "                write_data_to_bible(val, col, index, overwrite, debug)\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] Updated {col} for dimtag_entity={dimtag_entity}\")\n",
    "            elif debug:\n",
    "                print(f\"[DEBUG] No update for {col} for dimtag_entity={dimtag_entity} because value is None\")\n",
    "        \n",
    "    else:\n",
    "        # If the element does not exist, we create a new element with the right data\n",
    "        Bible = pd.concat([Bible, pd.DataFrame([Data_to_write], columns=Bible.columns)], ignore_index=True)\n",
    "        index = Bible.index[-1]\n",
    "    \n",
    "    return Bible\n",
    "\n",
    "def correct_bible_gmsh_by_entity(dimtag_entity, debug=False, child_correction=True, name_overwrite=None):\n",
    "    \"\"\"\n",
    "    This function corrects the bible of the geometry for a single specified entity using the gmsh API.\n",
    "    It will update the bible entry for the given dimtag_entity with the latest data from gmsh.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Get the information for the specified entity\n",
    "    dim, tag = int(dimtag_entity[0]), int(dimtag_entity[1])\n",
    "    # Check if the entity is a valid entity from the gmsh API\n",
    "    if gmsh.model.getType(dim, tag) == \"Unknown\":\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Entity {dimtag_entity} is not valid in gmsh API\")\n",
    "        \n",
    "        # If the entity is in the bible, remove it (robust tuple comparison)\n",
    "        mask = Bible[\"dimtag_entity\"].apply(lambda x: tuple(x) != tuple(dimtag_entity) if x is not None else True)\n",
    "        if len(Bible) != mask.sum():\n",
    "            Bible = Bible[mask]\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] Removed invalid entity {dimtag_entity} from bible\")\n",
    "        return Bible\n",
    "    \n",
    "    # Get the coordinates, dimension, group dimtag, group name and parent dimtag\n",
    "    entity_coordinates = gmsh.model.occ.getCenterOfMass(dim, tag)\n",
    "    bounding_box = gmsh.model.occ.getBoundingBox(dim, tag)\n",
    "    entity_dimension = [bounding_box[3] - bounding_box[0], bounding_box[4] - bounding_box[1], bounding_box[5] - bounding_box[2]]\n",
    "    group_tags = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "    dimtag_group = [(dim, int(group_tag)) for group_tag in group_tags]\n",
    "    group_name = [gmsh.model.getPhysicalName(dg[0], dg[1]) for dg in dimtag_group] if dimtag_group else []\n",
    "    upward_adjacencies = gmsh.model.getAdjacencies(dim, tag)[0]\n",
    "    dimtag_parent = [(int(dim+1), int(tag)) for tag in upward_adjacencies]\n",
    "    name = None\n",
    "    if name_overwrite is not None:\n",
    "        name = name_overwrite\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Overwriting name for entity {dimtag_entity} to {name}\")\n",
    "        \n",
    "    # Add or update the entry in the bible\n",
    "    add_to_bible(\n",
    "        dimtag_entity=dimtag_entity,\n",
    "        entity_name=name,\n",
    "        entity_coordinates=entity_coordinates,\n",
    "        entity_dimension=entity_dimension,\n",
    "        dimtag_group=dimtag_group,\n",
    "        group_name=group_name,\n",
    "        dimtag_parent=dimtag_parent,\n",
    "        overwrite=True,\n",
    "        debug=debug\n",
    "    )\n",
    "    \n",
    "    # We also need to check for child entities\n",
    "    \n",
    "    if child_correction:\n",
    "        child_entities = gmsh.model.getBoundary([dimtag_entity], oriented=False)\n",
    "        for child_entity in child_entities:\n",
    "            if child_entity[0] < dimtag_entity[0] and child_entity[0] > 0:\n",
    "                # If the child entity is a lower dimension, we need to correct it\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] Correcting child entity {child_entity} for parent {dimtag_entity}\")\n",
    "                # Recursively correct the child entity\n",
    "                correct_bible_gmsh_by_entity(child_entity, debug=debug)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Corrected bible entry for entity {dimtag_entity}\")\n",
    "\n",
    "    return Bible\n",
    "    \n",
    "def correct_bible_gmsh(minimum_dimension=2, debug=False):\n",
    "    \"\"\"\n",
    "    This function corrects the bible of the geometry using the gmsh API.\n",
    "    It will get from a dimtag the coordinates, dimension, group dimtag, group name and parent dimtag.\n",
    "    For that, it will first get the list of all the entities in the gmsh API and then it will get the information for each entity and verify the bible.\n",
    "    Then, it will delete bible elements that are not in the gmsh API.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    # Get the list of all the entities in the gmsh API\n",
    "    gmsh.model.occ.synchronize()\n",
    "    entities = gmsh.model.getEntities()\n",
    "    \n",
    "    # Loop over all the entities and get their information\n",
    "    for entity in entities:\n",
    "        if entity[0] >= minimum_dimension:\n",
    "            # If the entity is a volume or a surface, we need to correct it\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] Correcting bible for entity {entity}\")\n",
    "            # Get the dimtag of the entity\n",
    "            dimtag_entity = (entity[0], entity[1])\n",
    "            # Correct the bible for the entity\n",
    "            Bible = correct_bible_gmsh_by_entity(dimtag_entity, child_correction=False, debug=debug)\n",
    "        else:\n",
    "            if False:\n",
    "                print(f\"[DEBUG] Skipping entity {entity} because its dimension is lower than {minimum_dimension}\")\n",
    "    return Bible\n",
    "    \n",
    "def save_bible(file_name=\"bible.csv\", debug=False):\n",
    "    \"\"\"\n",
    "    This function saves the bible of the geometry to a CSV file.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    Bible.to_csv(file_name, index=False)\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Saved bible to {file_name}\")\n",
    "\n",
    "def filter_element(value, name, filtered_bible):\n",
    "    \"\"\"\n",
    "    This function filters the bible of the geometry by a specific element.\n",
    "    It will return a new dataframe with only the elements that match the criteria.\n",
    "    \"\"\"\n",
    "    if value is not None:\n",
    "        # Handle list/tuple/np.ndarray of values (for \"in\" or exact match)\n",
    "        if isinstance(value, (list, tuple, np.ndarray)):\n",
    "            # If the column contains lists/tuples, check if any element matches\n",
    "            def match_func(x):\n",
    "                # If both are lists/tuples/arrays, check for intersection or exact match\n",
    "                if isinstance(x, (list, tuple, np.ndarray)):\n",
    "                    # Exact match\n",
    "                    if list(x) == list(value):\n",
    "                        return True\n",
    "                    # Any element in value matches any element in x\n",
    "                    return any(\n",
    "                        (v == x or (isinstance(v, (list, tuple, np.ndarray)) and list(v) == list(x)))\n",
    "                        or (isinstance(xi, (list, tuple, np.ndarray)) and xi == v)\n",
    "                        for v in value for xi in (x if isinstance(x, (list, tuple, np.ndarray)) else [x])\n",
    "                    )\n",
    "                else:\n",
    "                    # x is scalar, value is list: check if x in value\n",
    "                    return x in value\n",
    "            filtered_bible = filtered_bible[filtered_bible[name].apply(match_func)]\n",
    "        else:\n",
    "            # Scalar value: check for equality or membership in list/tuple/array\n",
    "            def match_func(x):\n",
    "                if isinstance(x, (list, tuple, np.ndarray)):\n",
    "                    return value in x or any(\n",
    "                        (isinstance(xi, (list, tuple, np.ndarray)) and list(xi) == list(value))\n",
    "                        for xi in x\n",
    "                    )\n",
    "                else:\n",
    "                    return x == value\n",
    "            filtered_bible = filtered_bible[filtered_bible[name].apply(match_func)]\n",
    "    return filtered_bible\n",
    "\n",
    "def filter_bible(dimtag_entity=None, dimtag_group=None, group_name=None, group_tag=None, dimtag_parent=None, debug=False):\n",
    "    \"\"\"\n",
    "    This function filters the bible of the geometry.\n",
    "    It will return a new dataframe with only the elements that match the criteria.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    filtered_bible = Bible.copy()\n",
    "    \n",
    "    # Create a list of (value, name) tuples to filter\n",
    "    filter_list = [\n",
    "        (dimtag_entity, \"dimtag_entity\"),\n",
    "        (dimtag_group, \"dimtag_group\"),\n",
    "        (group_name, \"group_name\"),\n",
    "        (group_tag, \"dimtag_group\"),\n",
    "        (dimtag_parent, \"dimtag_parent\")\n",
    "    ]\n",
    "    \n",
    "    # Loop over the filter list and filter the elements\n",
    "    for value, name in filter_list:\n",
    "        if value is not None:\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] Filtering by {name} with value {value}\")\n",
    "            filtered_bible = filter_element(value, name, filtered_bible)\n",
    "    \n",
    "\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Filtered bible with {len(filtered_bible)} elements\")\n",
    "    \n",
    "    return filtered_bible\n",
    "\n",
    "if False:\n",
    "    \n",
    "    global Bible\n",
    "    \n",
    "    # Create the bible\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Print the bible\n",
    "    print_bible(Bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Lists and positions functions === ###\n",
    "\n",
    "def positions_from_density(density, number_positions, debug=False):\n",
    "    \"\"\"Generate positions based on a density function.\n",
    "    Args:\n",
    "        density (function): A function that takes a single argument and returns a density value.\n",
    "        number_positions (int): The number of positions to generate.\n",
    "        debug (bool): If True, plot the density function and the generated positions.\n",
    "    Returns:\n",
    "        np.ndarray: An array of positions generated based on the density function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a fine grid for integration and inversion\n",
    "    x = np.linspace(0, 1, 1000)\n",
    "    y_density = density(x)\n",
    "    # Avoid negative or zero densities\n",
    "    y_density = np.clip(y_density, 1e-12, None)\n",
    "    # Compute cumulative density (numerical integration)\n",
    "    y_cum_density = np.cumsum(y_density)\n",
    "    y_cum_density = y_cum_density / y_cum_density[-1]  # Normalize to [0,1]\n",
    "\n",
    "    # Invert the cumulative density to get positions\n",
    "    target_cum = np.linspace(0, 1, number_positions)\n",
    "    positions = np.interp(target_cum, y_cum_density, x)\n",
    "\n",
    "    # For plotting/debugging\n",
    "    if debug:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x, y_density, label='Density Function')\n",
    "        plt.title('Density Function and Generated Positions')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    if debug:\n",
    "        plt.plot(x, y_cum_density, label='Cumulative Density Function')\n",
    "        for pos in positions:\n",
    "            plt.axvline(x=pos, color='g', linestyle='--')\n",
    "        plt.axhline(y=0, color='k', linestyle='--')\n",
    "        plt.axhline(y=1, color='k', linestyle='--')\n",
    "        plt.axvline(x=0, color='k', linestyle='--')\n",
    "        plt.axvline(x=1, color='k', linestyle='--')\n",
    "        plt.title('Density Function')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def reduce_number_points_list(initial_list, number_points_target, accel_ratio=ratio_for_accel_points, mode=reduce_points_method, debug=False):\n",
    "    \"\"\"\n",
    "    Reduce dynamically the number of points in a list to a specified number.\n",
    "    Keeps points of most importance via acceleration, but also distributes points uniformly.\n",
    "    The first and last points are always preserved.\n",
    "    :param initial_list: List of points to reduce.\n",
    "    :param number_points: Number of points to keep.\n",
    "    :param accel_ratio: Ratio of points to select by acceleration (0-1).\n",
    "    :return: Reduced list of points.\n",
    "    \"\"\"\n",
    "\n",
    "    # For the number of points we need at least 2 points\n",
    "    number_points = max(2, number_points_target)\n",
    "    if number_points >= len(initial_list):\n",
    "        return np.array(initial_list)\n",
    "    initial_list_np = np.array(initial_list)\n",
    "    \n",
    "    # We need to choose between the distribution by acceleration and by density\n",
    "    if mode == 'density':\n",
    "        # Calculate normalized x for density mapping\n",
    "        initial_start = initial_list_np[0, 0]\n",
    "        initial_end = initial_list_np[-1, 0]\n",
    "        initial_length = initial_end - initial_start\n",
    "\n",
    "        # Interpolate y-values and smooth acceleration for density\n",
    "        initial_function = scipy.interpolate.interp1d(initial_list_np[:, 0], initial_list_np[:, 1], kind='linear', fill_value=\"extrapolate\")\n",
    "        derivative = np.gradient(initial_list_np, axis=0)\n",
    "        acceleration = np.gradient(derivative, axis=0)\n",
    "        acceleration_magnitude = np.linalg.norm(acceleration, axis=1)\n",
    "        # Smooth acceleration to avoid spurious peaks\n",
    "        window = 7 if len(acceleration_magnitude) > 7 else max(3, len(acceleration_magnitude)//2*2+1)\n",
    "        acceleration_smoothed = np.convolve(acceleration_magnitude, np.ones(window)/window, mode='same')\n",
    "        # Avoid zero density\n",
    "        acceleration_smoothed = np.clip(acceleration_smoothed, 1e-8, None)\n",
    "        acceleration_function = scipy.interpolate.interp1d(initial_list_np[:, 0], acceleration_smoothed, kind='linear', fill_value=\"extrapolate\")\n",
    "        # Add a cosntant to avoid zero density and get points everywhere\n",
    "        mean_acceleration = np.mean(acceleration_smoothed)\n",
    "        # Density function normalized to [0, 1]\n",
    "        density_func = lambda x: acceleration_function(x * initial_length + initial_start) + 0.1 * mean_acceleration\n",
    "        # Generate new x positions based on density\n",
    "        new_x_positions = positions_from_density(density_func, number_points, debug=debug) * initial_length + initial_start\n",
    "        new_y_positions = initial_function(new_x_positions)\n",
    "        new_positions = np.column_stack((new_x_positions, new_y_positions))\n",
    "        if debug:\n",
    "            plt.plot(initial_list_np[:, 0], initial_list_np[:, 1], label='Initial Points')\n",
    "            plt.plot(new_positions[:, 0], new_positions[:, 1], label='Reduced Points')\n",
    "            plt.plot(initial_list_np[:, 0], acceleration_magnitude, label='Acceleration Magnitude')\n",
    "            plt.plot(derivative[:, 0], derivative[:, 1], label='Derivative')\n",
    "            plt.plot(new_x_positions, new_y_positions, label='New Positions')\n",
    "            plt.title('Density Function')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('Density')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        # Replace the first and last points with the original ones\n",
    "        new_positions[0] = initial_list_np[0]\n",
    "        new_positions[-1] = initial_list_np[-1]\n",
    "        \n",
    "        # We do not want use non valid points (nan, inf)\n",
    "        reduced_positions = new_positions[~np.isnan(new_positions).any(axis=1)]\n",
    "    \n",
    "    elif mode == 'accel':\n",
    "        derivative = np.gradient(initial_list_np, axis=0)\n",
    "        acceleration = np.gradient(derivative, axis=0)\n",
    "        acceleration_magnitude = np.linalg.norm(acceleration[1:-1], axis=1)\n",
    "        n_to_select = number_points - 2  # Exclude first and last\n",
    "        # Split between acceleration-based and uniform\n",
    "        n_accel = int(np.round(n_to_select * accel_ratio))\n",
    "        n_uniform = n_to_select - n_accel\n",
    "        # Always keep the first and last points\n",
    "        keep_indices = {0, len(initial_list) - 1}\n",
    "        # Acceleration-based selection\n",
    "        candidate_indices = np.arange(1, len(initial_list) - 1)\n",
    "        sorted_indices = candidate_indices[np.argsort(acceleration_magnitude)]\n",
    "        accel_indices = sorted_indices[-n_accel:] if n_accel > 0 else np.array([], dtype=int)\n",
    "        # Uniform selection (excluding already chosen)\n",
    "        remaining_indices = sorted(set(candidate_indices) - set(accel_indices))\n",
    "        if n_uniform > 0 and len(remaining_indices) > 0:\n",
    "            uniform_indices = np.linspace(0, len(remaining_indices) - 1, n_uniform, dtype=int)\n",
    "            uniform_indices = np.array(remaining_indices)[uniform_indices]\n",
    "        else:\n",
    "            uniform_indices = np.array([], dtype=int)\n",
    "        # Combine all indices and sort\n",
    "        all_indices = np.sort(np.concatenate((np.array(list(keep_indices)), accel_indices, uniform_indices)))\n",
    "        reduced_positions = initial_list_np[all_indices]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Use 'density' or 'accel'.\")\n",
    "    \n",
    "    return reduced_positions\n",
    "\n",
    "def profile_points_modificator(initial_profile, modificator, interpolate=True, smooth=True):\n",
    "    \"\"\"\n",
    "    Modifies the profile points based on a given modificator function.\n",
    "    \n",
    "    :param initial_profile: Initial profile points.\n",
    "    :param modificator: Function to modify the profile points.\n",
    "    :return: Modified profile points.\n",
    "    \"\"\"\n",
    "    if modificator is None:\n",
    "        return initial_profile\n",
    "    \n",
    "    if interpolate:\n",
    "        # Number of points\n",
    "        number_points = len(initial_profile)\n",
    "        # Curve fitting \n",
    "        initial_function = scipy.interpolate.interp1d(initial_profile[:, 0], initial_profile[:, 1], kind='linear', fill_value=\"extrapolate\")\n",
    "        # Modify the function\n",
    "        modified_function = lambda x: initial_function(x) + modificator(x)\n",
    "        # Generate x values for the modified function\n",
    "        x_values = np.linspace(initial_profile[0, 0], initial_profile[-1, 0], number_points)        \n",
    "        # Calculate the modified Y values using the modified function\n",
    "        modified_profile = []\n",
    "        for x in x_values:\n",
    "            modified_profile.append([x, modified_function(x)])\n",
    "        # Convert the modified profile to a numpy array\n",
    "        modified_profile = np.array(modified_profile)\n",
    "    else:\n",
    "        # Apply the modificator function to each point in the initial profile\n",
    "        modified_profile = []\n",
    "        for point in initial_profile:\n",
    "            X_initial = point[0]\n",
    "            Y_initial = point[1]\n",
    "            X_modified = X_initial\n",
    "            Y_modified = Y_initial + modificator(X_initial)\n",
    "            modified_profile.append([X_modified, Y_modified])\n",
    "        # Convert the modified profile to a numpy array\n",
    "        modified_profile = np.array(modified_profile)\n",
    "        \n",
    "    return modified_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === GMSH positions functions === ###\n",
    "\n",
    "def cartesian_to_polar_x_axis(position, Angle):\n",
    "    \"\"\"\n",
    "    Convert a 3D position to polar coordinates around the X axis.\n",
    "    \n",
    "    :param position: 3D position (x, y, z).\n",
    "    :return: Polar coordinates (r, theta, z).\n",
    "    \"\"\"\n",
    "    x, y, z = position\n",
    "    r = math.sqrt(y**2 + z**2)\n",
    "    theta = math.atan2(z, y) + Angle\n",
    "    return r, theta, x\n",
    "\n",
    "def polar_to_cartesian(polar_position, Angle):\n",
    "    \"\"\"\n",
    "    Convert polar coordinates around the X axis to a 3D position.\n",
    "    \n",
    "    :param polar_position: Polar coordinates (r, theta, z).\n",
    "    :return: 3D position (x, y, z).\n",
    "    \"\"\"\n",
    "    r, theta, x = polar_position\n",
    "    y = r * math.cos(theta - Angle)\n",
    "    z = r * math.sin(theta - Angle)\n",
    "    return x, y, z    \n",
    "    \n",
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def entity_position(entity, use_gmsh=False, debug=DEBUG):\n",
    "    \"\"\"\n",
    "    Get the position of a GMSH entity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    if not use_gmsh:\n",
    "        # Compare each row as tuple\n",
    "        mask = Bible[\"dimtag_entity\"].apply(lambda x: tuple(x) == tuple(entity))\n",
    "        filtered = Bible[mask]\n",
    "        if filtered.empty:\n",
    "            #raise ValueError(f\"Entity {entity} not found in bible.\")\n",
    "            print(f\"[DEBUG] Entity {entity} not found in bible.\")\n",
    "            return None\n",
    "        pos = filtered[\"entity_coordinates\"].values[0]\n",
    "    \n",
    "    else:\n",
    "        pos = gmsh.model.occ.getCenterOfMass(entity[0], entity[1])\n",
    "    \n",
    "    #Convert to float list and not np.ndarray\n",
    "    pos = [float(coord) for coord in pos] if isinstance(pos, (list, tuple, np.ndarray)) else [float(pos)]\n",
    "    return pos\n",
    "\n",
    "def entity_dimension(entity, use_gmsh=False, debug=DEBUG):\n",
    "    \"\"\"\n",
    "    Get the length of a GMSH entity.\n",
    "    \n",
    "    :param entity: The entity to get the length of.\n",
    "    :param use_gmsh: If True, use the GMSH API to get the length.\n",
    "    :param debug: If True, print debug information.\n",
    "    :return: The length of the entity.\n",
    "    \"\"\"\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    # Compare each row as tuple\n",
    "    if not use_gmsh:\n",
    "        mask = Bible[\"dimtag_entity\"].apply(lambda x: tuple(x) == tuple(entity))\n",
    "        filtered = Bible[mask]\n",
    "    else:\n",
    "        filtered = None\n",
    "    \n",
    "    # If the entity is not found in the bible, use the GMSH API\n",
    "    if (filtered is None or filtered.empty) or use_gmsh:\n",
    "        # Debug:\n",
    "        if debug and not use_gmsh:\n",
    "            print(f\"[DEBUG] Entity {entity} not found in bible, using GMSH API\")\n",
    "        # Get the bounding box from GMSH\n",
    "        bounding_box = gmsh.model.occ.getBoundingBox(entity[0], entity[1])\n",
    "        entity_dimension = [\n",
    "            bounding_box[3] - bounding_box[0],\n",
    "            bounding_box[4] - bounding_box[1],\n",
    "            bounding_box[5] - bounding_box[2]\n",
    "        ]\n",
    "        # Add the dimension to the bible\n",
    "        if not use_gmsh:\n",
    "            add_to_bible(dimtag_entity=entity, entity_dimension=entity_dimension, overwrite=True)\n",
    "    else:\n",
    "        # Get the dimension from the bible\n",
    "        entity_dimension = filtered[\"entity_dimension\"].values[0]\n",
    "        if isinstance(entity_dimension, (list, tuple, np.ndarray)) and len(entity_dimension) == 3:\n",
    "            entity_dimension = np.array(entity_dimension, dtype=float)\n",
    "        else:\n",
    "            print(f\"[DEBUG] Invalid format for dimension of entity {entity}: {entity_dimension} Using GMSH API instead.\")\n",
    "            bounding_box = gmsh.model.occ.getBoundingBox(entity[0], entity[1])\n",
    "            entity_dimension = [bounding_box[3] - bounding_box[0], bounding_box[4] - bounding_box[1], bounding_box[5] - bounding_box[2]]\n",
    "    \n",
    "    # Return the dimension\n",
    "    return entity_dimension\n",
    "\n",
    "def angles_close(a, b, tol=1e-6):\n",
    "    return np.isclose(np.mod(a - b + np.pi, 2 * np.pi) - np.pi, 0, atol=tol)\n",
    "\n",
    "def rotate_position(arguments, debug=False):\n",
    "    \"\"\"\n",
    "    Rotate a position around the Z axis.\n",
    "    \n",
    "    :param args: Arguments for rotation (x, y, z, ax, ay, az, angle).\n",
    "    :return: Rotated position.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the angle of the Nozzle\n",
    "    global Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Get the arguments of the rotation\n",
    "    dimTags, x, y, z, ax, ay, az, angle = arguments\n",
    "    \n",
    "    # Get the tag and position of each entity\n",
    "    rotated_entity_to_tag_and_position = {}\n",
    "    for dim, tag in dimTags:\n",
    "        # Try to get the position from the bible\n",
    "        try:\n",
    "            position = entity_position([dim, tag])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not get position for entity {(dim, tag)}: {e}\")        \n",
    "        \n",
    "        # Simple method to rotate the position around the X axis\n",
    "        polar_position = cartesian_to_polar_x_axis(position, -Nozzle_Angle_Revolution)\n",
    "        rotated_polar_position = (polar_position[0], polar_position[1] + np.pi, polar_position[2])\n",
    "        rotated_position = polar_to_cartesian(rotated_polar_position, -Nozzle_Angle_Revolution)\n",
    "        \n",
    "        if True:\n",
    "            if angle!=0 and rotated_position[0] == position[0] and rotated_position[1] == position[1] and rotated_position[2] == position[2]:\n",
    "                raise ValueError(f\"Position of entity {(dim, tag)} has not been correctly rotated. Expected different position, got {rotated_position}.\")\n",
    "            \n",
    "        # Correct the format of the rotated position\n",
    "        if isinstance(rotated_position, (list, tuple, np.ndarray)) and len(rotated_position) == 3:\n",
    "            rotated_position = np.array(rotated_position, dtype=float)\n",
    "        \n",
    "        # Save the tag and rotated position in a dictionary\n",
    "        rotated_entity_to_tag_and_position[tag] = {\"tag\": tag, \"position\": rotated_position}\n",
    " \n",
    "        # Actualize the bible with the new position\n",
    "        dimtag_entity = dimtag_to_tuple((dim, tag))\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Adding : dimtag {dimtag_entity}, position {rotated_position}\")\n",
    "        add_to_bible(dimtag_entity=dimtag_entity, entity_coordinates=rotated_position, overwrite=True)\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Rotated entity {tag} to position {rotated_position}\")\n",
    "            \n",
    "        # Debug: Verify that the position has been correctly rotated\n",
    "        if True:\n",
    "            new_position = entity_position((dim, tag), use_gmsh=False)\n",
    "            if new_position[0] == position[0] and new_position[1] == position[1] and new_position[2] == position[2]:\n",
    "                raise ValueError(f\"Position of entity {(dim, tag)} has not been correctly rotated. Expected {rotated_position}, got {new_position}.\")\n",
    "            new_position_polar = cartesian_to_polar_x_axis(new_position, -Nozzle_Angle_Revolution)\n",
    "            if not (\n",
    "                np.isclose(new_position_polar[0], rotated_polar_position[0], atol=1e-8)\n",
    "                and angles_close(new_position_polar[1], rotated_polar_position[1])\n",
    "                and np.isclose(new_position_polar[2], rotated_polar_position[2], atol=1e-8)\n",
    "                ):\n",
    "                raise ValueError(\n",
    "                    f\"Polar position of entity {(dim, tag)} has not been correctly rotated. \"\n",
    "                    f\"Expected {rotated_polar_position}, got {new_position_polar}.\"\n",
    "                )\n",
    "    return rotated_entity_to_tag_and_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Delete something === ###\n",
    "\n",
    "def delete_entity(dimTags, debug=False):\n",
    "    \"\"\"\n",
    "    Delete entities from a specified list.\n",
    "    :param dimTags: List of tuples (dim, tag) to delete.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    deleted = []\n",
    "    for dim, tag in dimTags:\n",
    "        try:\n",
    "            gmsh.model.occ.remove([(dim, tag)], recursive=True)\n",
    "            gmsh.model.occ.synchronize()\n",
    "            \n",
    "            # Also remove the physical group\n",
    "            physical_groups = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "            for physical_group in physical_groups:\n",
    "                if debug:\n",
    "                    print(f\"Removing physical group: {physical_group}\")\n",
    "                try:\n",
    "                    gmsh.model.removePhysicalGroups([(dim, physical_group)])\n",
    "                    gmsh.model.occ.synchronize()\n",
    "                    deleted.append((dim, physical_group))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing physical group {physical_group}: {e}\")\n",
    "                # Verify that the physical group is deleted\n",
    "                try:\n",
    "                    gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "                except Exception as e:\n",
    "                    if debug:\n",
    "                        print(f\"Physical group {physical_group} is deleted.\")\n",
    "                else:\n",
    "                    print(f\"ATTENTION : Physical group {physical_group} is not deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing entity {tag}: {e}\")\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Verify that the entity is deleted\n",
    "    for dim, tag in deleted:\n",
    "        if (dim, tag) not in gmsh.model.getEntities(dim):\n",
    "            if debug:\n",
    "                print(f\"Entity {tag} is deleted.\")\n",
    "        else:\n",
    "            print(f\"ATTENTION : Entity {tag} is not deleted.\")\n",
    "\n",
    "    return deleted\n",
    "\n",
    "def delete_entities_without_physical_group(dimDeletion=2, debug=False):\n",
    "    \"\"\"\n",
    "    Delete entities without a physical group.\n",
    "    \"\"\"\n",
    "    # Get all entities\n",
    "    entities = gmsh.model.getEntities(dimDeletion)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    removed_entities = []\n",
    "    # Loop through all entities\n",
    "    for dim, tag in entities:\n",
    "        # Check if the entity has a physical group\n",
    "        physical_groups = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "        if len(physical_groups) == 0:\n",
    "            # Delete the entity\n",
    "            try:\n",
    "                deleted = delete_entity([(dim, tag)])\n",
    "                if len(deleted) > 0:\n",
    "                    removed_entities.append((dim, tag))\n",
    "                    print(f\"Entity {tag} is deleted.\")\n",
    "                else:\n",
    "                    if DEBUG:\n",
    "                        name = group_name_via_tags([(dim, tag)])\n",
    "                        print(f\"Entity {tag} is not deleted. It is in the group {name}.\")\n",
    "                    else:\n",
    "                        print(f\"Entity {tag} is not deleted.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing entity {tag}: {e}\")\n",
    "       \n",
    "    return removed_entities\n",
    "\n",
    "def delete_entities_with_physical_group(dimtags, debug=False):\n",
    "    \"\"\"\n",
    "    Delete entities and their groups from a specified list.\n",
    "    :param dimtags: List of tuples (dim, tag) to delete.\n",
    "    \n",
    "    \"\"\"\n",
    "    removed_entities = []\n",
    "    for dim, tag in dimtags:\n",
    "        try:\n",
    "            physical_groups = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "            for physical_group in physical_groups:\n",
    "                if DEBUG:\n",
    "                    print(f\"Removing physical group: {physical_group}\")\n",
    "                try:\n",
    "                    gmsh.model.removePhysicalGroups([(dim, physical_group)])\n",
    "                    gmsh.model.occ.synchronize()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing physical group {physical_group}: {e}\")\n",
    "            try:\n",
    "                deleted = delete_entity([(dim, tag)])\n",
    "                if len(deleted) > 0:\n",
    "                    removed_entities.append((dim, tag))\n",
    "                    print(f\"Entity {tag} is deleted.\")\n",
    "                else:\n",
    "                    print(f\"Entity {tag} is not deleted.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing entity {tag}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing entity {tag}: {e}\")\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    return removed_entities\n",
    "\n",
    "def delete_physical_groups(dim, tag, debug=False):\n",
    "    \"\"\"\n",
    "    Delete physical groups from a specified list.\n",
    "    :param dim: Dimension of the group to delete.\n",
    "    :param tag: Tag of the group to delete.\n",
    "    \n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    try:\n",
    "        gmsh.model.removePhysicalGroups([(dim, tag)])\n",
    "        gmsh.model.occ.synchronize()\n",
    "        if debug:\n",
    "            print(f\"Group {tag} (dim={dim}) deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing group {tag}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    '''\n",
    "    # Actualize the bible by deleting the line with the group\n",
    "    index = Bible[Bible[\"dimtag_group\"].apply(lambda x: x == [(dim, tag)])].index\n",
    "    if len(index) > 0:\n",
    "        Bible = Bible.drop(index)\n",
    "        if debug:\n",
    "            print(f\"Group {tag} (dim={dim}) deleted from bible.\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Group {tag} (dim={dim}) not found in bible.\")\n",
    "    '''\n",
    "    return True\n",
    "\n",
    "def delete_groups_by_prefix(prefix, debug=False):\n",
    "    \"\"\"\n",
    "    Delete groups with a specific prefix.\n",
    "    :param prefix: Prefix of the groups to delete.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    \n",
    "    for dim, tag in physical_groups:\n",
    "        try:\n",
    "            name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        except Exception:\n",
    "            name = \"\"\n",
    "        if name.startswith(prefix):\n",
    "            result = delete_physical_groups(dim, tag, debug=debug)\n",
    "            if debug:\n",
    "                if result:\n",
    "                    print(f\"Group {name} is deleted.\")\n",
    "                else:\n",
    "                    print(f\"Group {name} is not deleted.\")\n",
    "    return True\n",
    "\n",
    "def remove_duplicate_points(points, tol=1e-8):\n",
    "    unique = []\n",
    "    for p in points:\n",
    "        if not any(np.allclose(p, q, atol=tol) for q in unique):\n",
    "            unique.append(p)\n",
    "    return np.array(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2682af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Entities, groups and tags functions === ###\n",
    "\n",
    "def print_everything():\n",
    "    \"\"\"\n",
    "    Print physical entities, their name, tags and entities via a dataframe.\n",
    "    After that, it shows entities with their tags, physical groups (names and tags)\n",
    "    \"\"\"\n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    \n",
    "    # Create a list to store the data\n",
    "    data = []\n",
    "    \n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        # Get the tags in the group\n",
    "        tags = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "        # Append the data to the list\n",
    "        data.append([dim, tag, name, tags])\n",
    "    \n",
    "    # Create a dataframe from the data\n",
    "    df = pd.DataFrame(data, columns=[\"dim\", \"tag\", \"name\", \"tags\"])\n",
    "    \n",
    "    # Print the dataframe\n",
    "    print(f\"%%%% === Physical groups === %%% {physical_groups}\")\n",
    "    print(df)\n",
    "\n",
    "    # Print entities without physical groups\n",
    "    entities = gmsh.model.getEntities(2)\n",
    "    data = []\n",
    "    for dim, tag in entities:\n",
    "        # Get the name of the group\n",
    "        try:\n",
    "            group = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "            name = gmsh.model.getPhysicalName(dim, group[0])\n",
    "        except Exception as e:\n",
    "            group = []\n",
    "            name = \"No group\"\n",
    "        # Append the data to the list\n",
    "        data.append([dim, tag, name])\n",
    "    \n",
    "    # Create a dataframe from the data\n",
    "    df = pd.DataFrame(data, columns=[\"dim\", \"tag\", \"name\"])\n",
    "    # Print the dataframe\n",
    "    print(f\"%%%% === Entities === %%% {entities}\")\n",
    "    print(df)\n",
    "    return None\n",
    " \n",
    "def entities_tags_via_group_name(group_name=\"\", debug=False):\n",
    "    \"\"\"\n",
    "    Get the tags of a group by its name.\n",
    "    \n",
    "    :param group_name: Name of the group.\n",
    "    :return: List of tags in the group.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=None, group_name=group_name, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the tags\n",
    "    if not filtered.empty:\n",
    "        # Get the tags from the filtered Bible\n",
    "        tags_list = filtered[\"dimtag_entity\"].values[0]\n",
    "        return tags_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Group name {group_name} not found in Bible, using GMSH API\")\n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Initiate the list of tags\n",
    "    tags_list = []\n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        if group_name in name:\n",
    "            # Get the tags in the group\n",
    "            tags = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "            for found_tag in tags:\n",
    "                tags_list.append((dim, found_tag))\n",
    "    return tags_list\n",
    "\n",
    "def group_tags_via_group_name(group_name=\"\", debug=False):\n",
    "    \"\"\"\n",
    "    Get the tags of a group by its name.\n",
    "    \n",
    "    :param group_name: Name of the group.\n",
    "    :return: List of tags in the group.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=None, group_name=group_name, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the tags\n",
    "    if not filtered.empty:\n",
    "        # Get the tags from the filtered Bible\n",
    "        dimtag_list = filtered[\"dimtag_group\"].values[0]\n",
    "        # Ensure the tags are in the correct format\n",
    "        dimtag_list = extract_dimtags_list(dimtag_list)\n",
    "        # Convert to a list of tags\n",
    "        tags_list = [tag for dim, tag in dimtag_list]\n",
    "        return tags_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Group name {group_name} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Initiate the list of tags\n",
    "    tags_list = []\n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        if group_name in name:\n",
    "            tags_list.append((dim,tag))\n",
    "    return tags_list\n",
    "\n",
    "def group_name_via_tags(tags, debug=False):\n",
    "    \"\"\"\n",
    "    Get the names of groups by their tags.\n",
    "    :param tags: Tags of the group.\n",
    "    :return: Names of the group.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    mask = Bible[\"dimtag_group\"].apply(lambda x: any(tag in x for tag in tags))\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=None, group_name=None, group_tag=tags, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the names\n",
    "    if not filtered.empty:\n",
    "        # Get the names from the filtered Bible\n",
    "        names_list = filtered[\"group_name\"].values[0]\n",
    "        # Flatten the list of names\n",
    "        names_list = [name for sublist in names_list for name in sublist]\n",
    "        # Ensure the names are in the correct format\n",
    "        names_list = [name for name in names_list if isinstance(name, str)]\n",
    "        # Remove duplicates\n",
    "        names_list = list(set(names_list))\n",
    "        return names_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Group tags {tags} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Initiate the list of names\n",
    "    names_list = []\n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        #Get the entities tags in the group\n",
    "        tags_entitites = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "        #Check if one of the entities tags is in the tags\n",
    "        if any(tag in tags_entitites for tag in tags):\n",
    "            # Add the name to the list\n",
    "            names_list.append(name)\n",
    "    return names_list\n",
    "\n",
    "def group_tags_via_entity_tag(dimtag, debug=False):\n",
    "    \"\"\"\n",
    "    Get the tags of a group by its entity tag.\n",
    "    :param dimtag: Tag of the entity.\n",
    "    :return: List of tags in the group.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    filtered = filter_bible(dimtag_entity=dimtag, dimtag_group=None, group_name=None, group_tag=None, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the tags\n",
    "    if not filtered.empty:\n",
    "        # Get the tags from the filtered Bible\n",
    "        group_dimtag_list = filtered[\"dimtag_group\"].values[0]\n",
    "        # Ensure the tags are in the correct format\n",
    "        group_dimtag_list = extract_dimtags_list(group_dimtag_list)\n",
    "        # Convert to a list of tags\n",
    "        tags_list = [tag for dim, tag in group_dimtag_list]\n",
    "        return tags_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Entity tag {dimtag} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get the tags of the entity\n",
    "    group_tags = []\n",
    "    dim, tag = dimtag\n",
    "    \n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Loop through all physical groups\n",
    "    for dim_pg, tag_pg in physical_groups:\n",
    "        # Get the tags in the group\n",
    "        tags = gmsh.model.getEntitiesForPhysicalGroup(dim_pg, tag_pg)\n",
    "        if (dim, tag) in tags:\n",
    "            group_tags.append((dim_pg, tag_pg))\n",
    "    return group_tags\n",
    "\n",
    "def change_group_name(dimtag, new_name, debug=False):\n",
    "    \"\"\"\n",
    "    Change the name of a group, using the Bible if available, otherwise fallback to GMSH API.\n",
    "    \n",
    "    :param dimtag: Tag of the group (dim, tag).\n",
    "    :param new_name: New name of the group.\n",
    "    :param debug: Print debug info.\n",
    "    :return: True if the name was changed, False otherwise.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "\n",
    "    # Filter the Bible to the dimtag of the group\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=dimtag, group_name=None, group_tag=None, debug=debug)\n",
    "    \n",
    "    # Actualize the group name in the Bible\n",
    "    if not filtered.empty:\n",
    "        # Get the group name from the filtered Bible\n",
    "        old_names = filtered[\"group_name\"].values[0]\n",
    "        # Ensure old_names is a list of names by flattening it\n",
    "        old_names = [name for sublist in old_names for name in sublist]\n",
    "        # Take the most present name in the old_names list\n",
    "        old_name = max(set(old_names), key=old_names.count)\n",
    "        # Replace the instances of the old name in the group_name lists of the Bible\n",
    "        Bible[\"group_name\"] = Bible[\"group_name\"].apply(lambda x: [new_name if name == old_name else name for name in x])\n",
    "        # Verify that the group name is updated\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[Bible] Changed group name from {old_name} to {new_name} for (dim, tag)=({dimtag})\")\n",
    "    else:\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[Bible] Group (dim, tag)=({dimtag}) not found in Bible, fallback to GMSH\")            \n",
    "\n",
    "    # Always update in GMSH (fallback or sync)\n",
    "    try:\n",
    "        dim, tag = dimtag\n",
    "        current_name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        tags = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "        gmsh.model.removePhysicalGroups([(dim, tag)])\n",
    "        gmsh.model.occ.synchronize()\n",
    "        gmsh.model.addPhysicalGroup(dim, tags, tag)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        gmsh.model.setPhysicalName(dim, tag, new_name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_real_name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[GMSH] Current name: {current_name}\")\n",
    "            print(f\"[GMSH] New name: {new_name}\")\n",
    "            print(f\"[GMSH] New real name: {new_real_name}\")\n",
    "        return new_name != current_name and new_real_name == new_name\n",
    "    except Exception as e:\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[GMSH] Failed to change group name in GMSH: {e}\")\n",
    "        return False\n",
    "\n",
    "def change_group_name_via_entity(dimtag, new_name, debug=False):\n",
    "    \"\"\"\n",
    "    Change the name of a group by its entity tag.\n",
    "    \n",
    "    :param dimtag: Tag of the entity.\n",
    "    :param new_name: New name of the group.\n",
    "    \"\"\"\n",
    "    # Get the group tags of the entity\n",
    "    physical_groups_tags = group_tags_via_entity_tag(dimtag, debug=debug)\n",
    "           \n",
    "    # Get the first physical group\n",
    "    if len(physical_groups_tags) == 0:\n",
    "        print(f\"Entity {dimtag} has no physical group.\")\n",
    "        return False\n",
    "    else:\n",
    "        grouptag = physical_groups_tags[0]\n",
    "    # Rename the group\n",
    "    if change_group_name((dimtag[0], grouptag), new_name):\n",
    "        if debug:\n",
    "            print(f\"Group {grouptag} is renamed to {new_name}.\")\n",
    "    else:\n",
    "        print(f\"Group {grouptag} is not renamed to {new_name}.\")\n",
    "        return False\n",
    "    \n",
    "    #Verify that the entity is in the new group\n",
    "    entities = gmsh.model.getEntitiesForPhysicalGroup(dimtag[0], grouptag)\n",
    "    if dimtag in entities:\n",
    "        if debug:\n",
    "            print(f\"Entity {dimtag} is in the new group {new_name}.\")\n",
    "    else:\n",
    "        print(f\"Entity {dimtag} is not in the new group {new_name}.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_child_entities(dimtag, minimal_dim=2, debug=False):\n",
    "    # We iterate over all entities to get the children of the given entity after that we reiterate over the children to get the children of the children\n",
    "    dimtag = extract_dimtags_list(dimtag)\n",
    "    child_dimtags = []\n",
    "    current_dimtags = dimtag\n",
    "    counter = dimtag[0][0]\n",
    "    while counter > minimal_dim:\n",
    "        counter -= 1\n",
    "        added_dimtags = []\n",
    "        for dim, tag in current_dimtags:\n",
    "            # Get the children of the entity\n",
    "            children_tags = gmsh.model.getAdjacencies(dim, tag)[1]\n",
    "            added_dimtags = [(dim-1,tag) for tag in children_tags]\n",
    "        current_dimtags = added_dimtags\n",
    "        child_dimtags += added_dimtags\n",
    "    # Verify the format\n",
    "    child_dimtags = extract_dimtags_list(child_dimtags)\n",
    "    # Remove duplicates\n",
    "    child_dimtags = list(set(child_dimtags))\n",
    "    return child_dimtags\n",
    "\n",
    "def get_parent_volumes_of_entities(entities, use_bible=False, debug=False):\n",
    "    \"\"\"\n",
    "    Get the parent volumes of a GMSH entity.\n",
    "    \n",
    "    :param entities: The entity to get the parent volumes of.\n",
    "    :param use_bible: If True, use the Bible to get the parent volumes.\n",
    "    :param debug: If True, print debug information.\n",
    "    :return: The parent volumes of the entity.\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_bible:\n",
    "        # Get the Bible\n",
    "        global Bible\n",
    "        \n",
    "        # Filter the Bible to find the entity\n",
    "        filtered = filter_bible(dimtag_entity=entities, dimtag_group=None, group_name=None, group_tag=None)\n",
    "        \n",
    "        # If the entity is found in the Bible, return the parent volumes\n",
    "        if not filtered.empty:\n",
    "            parent_volumes = filtered[\"dimtag_parent\"].values[0]\n",
    "            parent_volumes = extract_dimtags_list(parent_volumes)\n",
    "            return parent_volumes\n",
    "    \n",
    "        # If the entity is not found in the Bible, use GMSH API\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Entity {entities} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get the parent volumes of the entity\n",
    "    parent_tags = gmsh.model.getAdjacencies(entities[0][0], entities[0][1])[0]\n",
    "    parent_volumes = [(entities[0][0]+1, tag) for tag in parent_tags]\n",
    "    parent_volumes = extract_dimtags_list(parent_volumes)\n",
    "    \n",
    "    return parent_volumes\n",
    "    \n",
    "def replace_entities_from_volume(old_entities, new_entities , debug=False):\n",
    "    \"\"\"\n",
    "    Replace old entities with new entities in a volume.\n",
    "\n",
    "    :param old_entities: List of old entities to replace.\n",
    "    :param new_entities: List of new entities to replace with.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the parent volumes of the old entities\n",
    "    volumes = get_parent_volumes_of_entities(old_entities)\n",
    "    if not volumes:\n",
    "        if DEBUG:\n",
    "            print(\"No parent volumes found for the given old_entities.\")\n",
    "        return None\n",
    "\n",
    "    volume = volumes[0]\n",
    "\n",
    "    # Get the list of entities in the volume\n",
    "    entities_in_volume = gmsh.model.getBoundary([volume], oriented=False)\n",
    "\n",
    "    # New entities for the volume\n",
    "    new_entities_for_volume = [entity for entity in entities_in_volume if entity not in old_entities]\n",
    "    new_entities_for_volume += new_entities\n",
    "\n",
    "    # Remove the old volume\n",
    "    gmsh.model.removeEntities([volume])\n",
    "    gmsh.model.occ.remove([volume])\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Create a new surface loop\n",
    "    surfaceTags = [tag for dim, tag in new_entities_for_volume if dim == 2]\n",
    "    if not surfaceTags:\n",
    "        if DEBUG:\n",
    "            print(\"No surface tags found for the new volume.\")\n",
    "        return None\n",
    "    new_loop = gmsh.model.occ.addSurfaceLoop(surfaceTags)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Create the new volume\n",
    "    new_volume = gmsh.model.occ.addVolume([new_loop])\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Debug : verify the new volume has the right faces and is not empty\n",
    "    if debug:\n",
    "        print(\"New volume: \", new_volume)\n",
    "        new_entities_in_volume = gmsh.model.getBoundary([(3, new_volume)], oriented=False)\n",
    "        print(\"New entities in volume: \", new_entities_in_volume)\n",
    "        if len(new_entities_in_volume) == 0:\n",
    "            print(\"Error: New volume is empty\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"New volume is not empty\")\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Actualize the Bible with the new volume\n",
    "    for dim, tag in new_entities_for_volume:\n",
    "        add_to_bible(dimtag_entity=(dim, tag), dimtag_parent=(3, new_volume), overwrite=True)\n",
    "    \n",
    "    return new_volume\n",
    "    \n",
    "def extract_dimtags_list(obj, dim=None):\n",
    "    \"\"\"\n",
    "    Extract a list of (dim, tag) tuples with the specified dimension from a possibly nested or mixed list/array.\n",
    "    Handles input as list, tuple, numpy array, or single (dim, tag) tuple.\n",
    "    If dim is None, returns all found (dim, tag) tuples.\n",
    "    :param obj: Input list/array/tuple of tags or dimtags.\n",
    "    :param dim: Dimension to filter for (e.g., 3 for volumes), or None for all.\n",
    "    :return: List of (dim, tag) tuples with the specified dimension or all if dim is None.\n",
    "    \"\"\"\n",
    "\n",
    "    def flatten_dimtags(o):\n",
    "        # Recursively flatten and extract (dim, tag) pairs\n",
    "        if isinstance(o, (list, tuple, np.ndarray)):\n",
    "            # If it's a (dim, tag) pair\n",
    "            if len(o) == 2 and all(isinstance(x, (int, np.integer)) for x in o):\n",
    "                return [tuple(int(x) for x in o)]\n",
    "            # Otherwise, flatten recursively\n",
    "            result = []\n",
    "            for item in o:\n",
    "                result.extend(flatten_dimtags(item))\n",
    "            return result\n",
    "        # If it's a single (dim, tag) pair as a numpy array\n",
    "        if isinstance(o, np.generic) and hasattr(o, 'shape') and o.shape == (2,):\n",
    "            return [tuple(int(x) for x in o)]\n",
    "        return []\n",
    "\n",
    "    all_dimtags = flatten_dimtags(obj)\n",
    "    if dim is None:\n",
    "        return all_dimtags\n",
    "    filtered = [dt for dt in all_dimtags if dt[0] == dim]\n",
    "    return filtered\n",
    "\n",
    "def create_physical_group(dim, tags, name, group_tag=None, debug=False):\n",
    "    \"\"\"\n",
    "    Create a physical group with the specified dimension, tags, and name.\n",
    "    \n",
    "    :param dim: Dimension of the group (e.g., 1 for lines, 2 for surfaces).\n",
    "    :param tags: List of tags to include in the group.\n",
    "    :param name: Name of the group.\n",
    "    :param group_tag: Optional tag for the group.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Verify that the tags exists\n",
    "    entities = gmsh.model.getEntities(dim)\n",
    "    tags_not_ok = all(tag not in [t for d, t in entities] for tag in tags)\n",
    "    if tags_not_ok:\n",
    "        print(f\"ATTENTION : None of the tags {tags} exists in the model\")\n",
    "        return False\n",
    "\n",
    "    # Get the group tag\n",
    "    if group_tag is None:\n",
    "        group_tag_used = start_tag\n",
    "    else:\n",
    "        group_tag_used = group_tag\n",
    "    \n",
    "    # Ensure the name is in the correct format\n",
    "    name = str(name)\n",
    "    \n",
    "    # Create the group\n",
    "    gmsh.model.occ.synchronize()\n",
    "    gmsh.model.addPhysicalGroup(dim=dim, tags=tags, tag=group_tag_used, name=name)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Get the name of the group\n",
    "    name_used = gmsh.model.getPhysicalName(dim, group_tag_used)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    if name_used != str(name):\n",
    "        if debug:\n",
    "            print(f\"ATTENTION : Group name {name_used} is not the same as {name}\")\n",
    "            return False\n",
    "        \n",
    "    # Actualize the start tag\n",
    "    start_tag = group_tag_used + 1\n",
    "    \n",
    "    # Add the group to the Bible\n",
    "    for tag in tags:\n",
    "        add_to_bible(dimtag_entity=(dim, tag), dimtag_group=[(dim, group_tag_used)], group_name=[name], overwrite=True, debug=debug)\n",
    "        \n",
    "    # Verify that the group is created by getting the entities in the group\n",
    "    try:\n",
    "        entities = gmsh.model.getEntitiesForPhysicalGroup(dim, group_tag_used)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting entities for physical group {group_tag_used}: {e}\")\n",
    "        entities = []\n",
    "    \n",
    "    # Check if the group is created\n",
    "    if len(entities) == 0:\n",
    "        print(f\"ATTENTION : Physical group {name} is not created\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Physical group {name} is created with tag {group_tag_used}\")\n",
    "    \n",
    "    #Check if the entities are in the group\n",
    "    if len(tags) > 0:\n",
    "        for tag in tags:\n",
    "            if (dim, tag) not in entities:\n",
    "                return False\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"Entity {tag} is in the group {name}\")\n",
    "    \n",
    "    # Actualize the start tag\n",
    "    start_tag = group_tag_used + 1\n",
    "\n",
    "    return True\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === GMSH functions recovering tags and names === ###\n",
    "\n",
    "def cost_function(A_polar, B_polar, r_norm, theta_norm, x_norm):\n",
    "    \"\"\"\n",
    "    Cost function to compute the distance at each coordinate in a polar coordinate system.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Compute the differences for each coordinate\n",
    "    r_diff = abs(A_polar[0] - B_polar[0]) / r_norm\n",
    "    theta_diff = (A_polar[1] - B_polar[1]) / theta_norm\n",
    "    x_diff = abs(A_polar[2] - B_polar[2]) / x_norm\n",
    "    \n",
    "    # Weight the differences\n",
    "    r_factor = 0 ; theta_factor = 1/np.pi ; x_factor = 0\n",
    "    \n",
    "    # Compute the cost as a weighted sum of the differences\n",
    "    cost = r_factor * r_diff + theta_factor * theta_diff + x_factor * x_diff\n",
    "    \n",
    "    # Modify the cost to improve the assignment\n",
    "    #cost = cost**2\n",
    "    cost = np.log1p(cost)  # Use log1p to avoid issues with zero cost\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def polar_distance(a, b, r_norm=1, theta_norm=1, x_norm=1):\n",
    "    # Distance euclidienne pondÃ©rÃ©e, angle modulo 2Ï\n",
    "    dr = (a[0] - b[0]) / r_norm\n",
    "    dtheta = np.angle(np.exp(1j * (a[1] - b[1]))) / theta_norm  # distance angulaire [-Ï, Ï]\n",
    "    dx = (a[2] - b[2]) / x_norm\n",
    "    return np.sqrt(dr**2 + dtheta**2 + dx**2)\n",
    "\n",
    "def dimtags_assignment(old_entities_dimtags, new_entities_dimtags, debug=False, distance_weight=1.0, area_weight=0.0, type_weight=2.0, distance_threshold=None):\n",
    "    \"\"\"\n",
    "    Robust assignment of old to new dimtags using a multi-criteria cost matrix.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "    if len(old_entities_dimtags) == 0 or len(new_entities_dimtags) == 0:\n",
    "        return [[], []]\n",
    "\n",
    "    old_entities_dimtags = sorted(old_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "    new_entities_dimtags = sorted(new_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    # Get positions and dimensions\n",
    "    bible_positions = [entity_position(entity, use_gmsh=False) for entity in old_entities_dimtags]\n",
    "    gmsh_positions = [entity_position(entity, use_gmsh=True) for entity in new_entities_dimtags]\n",
    "    bible_dims = [entity_dimension(entity, use_gmsh=False) for entity in old_entities_dimtags]\n",
    "    gmsh_dims = [entity_dimension(entity, use_gmsh=True) for entity in new_entities_dimtags]\n",
    "    bible_types = [entity[0] for entity in old_entities_dimtags]\n",
    "    gmsh_types = [entity[0] for entity in new_entities_dimtags]\n",
    "\n",
    "    # Compute area/volume for each entity (product of dimensions)\n",
    "    def prod(lst): return np.prod(lst) if lst is not None else 0\n",
    "    bible_areas = [prod(dim) for dim in bible_dims]\n",
    "    gmsh_areas = [prod(dim) for dim in gmsh_dims]\n",
    "\n",
    "    # Normalization factors\n",
    "    max_dist = max(np.linalg.norm(np.array(bp) - np.array(gp)) for bp in bible_positions for gp in gmsh_positions)\n",
    "    max_area = max(max(bible_areas), max(gmsh_areas), 1)\n",
    "\n",
    "    # Build cost matrix\n",
    "    cost_matrix = np.full((len(bible_positions), len(gmsh_positions)), np.inf)\n",
    "    for i, (old_pos, old_area, old_type) in enumerate(zip(bible_positions, bible_areas, bible_types)):\n",
    "        for j, (new_pos, new_area, new_type) in enumerate(zip(gmsh_positions, gmsh_areas, gmsh_types)):\n",
    "            # Distance cost\n",
    "            dist = np.linalg.norm(np.array(old_pos) - np.array(new_pos)) / max_dist\n",
    "            # Area/volume cost\n",
    "            area_cost = abs(old_area - new_area) / max_area\n",
    "            # Type cost\n",
    "            type_cost = 0 if old_type == new_type else 1\n",
    "            # Total cost\n",
    "            cost = distance_weight * dist + area_weight * area_cost + type_weight * type_cost\n",
    "            # Optional: threshold on distance\n",
    "            if distance_threshold is not None and dist > distance_threshold:\n",
    "                cost = np.inf\n",
    "            cost_matrix[i, j] = cost\n",
    "\n",
    "    # VÃ©rification de la faisabilitÃ©\n",
    "    if np.all(np.isinf(cost_matrix)):\n",
    "        raise ValueError(\"Aucune correspondance possibleâ¯: toutes les distances sont au-dessus du seuil ou types incompatibles.\")\n",
    "\n",
    "    if np.any(np.all(np.isinf(cost_matrix), axis=1)) or np.any(np.all(np.isinf(cost_matrix), axis=0)):\n",
    "        raise ValueError(\"Matrice de coÃ»t infaisableâ¯: au moins une ligne ou colonne ne contient que des np.inf.\")\n",
    "\n",
    "    if True:\n",
    "        import pandas as pd\n",
    "        cost_df = pd.DataFrame(cost_matrix, columns=[str(e) for e in new_entities_dimtags], index=[str(e) for e in old_entities_dimtags])\n",
    "        cost_df.to_csv(f\"cost_matrix_dim_{old_entities_dimtags[0][0]}.csv\")\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    return row_ind, col_ind\n",
    "\n",
    "def recover_group_entities_and_names_via_positions(old_entities_dimtags, new_entities_dimtags, debug=False):\n",
    "    \"\"\"\n",
    "    Recover the group entities and names via positions.\n",
    "\n",
    "    This function matches new entities to their corresponding old entities based on their positions.\n",
    "    It uses a tolerance value to determine if two entities are close enough to be considered the same.\n",
    "    The function updates the group-to-entities-and-names mapping to reflect the new entities and their\n",
    "    corresponding physical groups.\n",
    "\n",
    "    :param new_entity_to_tag_and_position: Dictionary mapping new entity tags to their positions.\n",
    "    :param rotated_entity_to_tag_and_position: Dictionary mapping rotated entity tags to their positions.\n",
    "    :param group_to_entities_and_names: Dictionary mapping physical group tags to their entities and names.\n",
    "    :param tol: Tolerance value for matching positions (default is 1e-3).\n",
    "    :return: Updated group-to-entities-and-names mapping.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Specific debug for uneven number of entities\n",
    "    if len(old_entities_dimtags) != len(new_entities_dimtags):\n",
    "        debug_alt = True\n",
    "    else:\n",
    "        debug_alt = False\n",
    "        \n",
    "    # Sort the entities by their dimtag\n",
    "    old_entities_dimtags = extract_dimtags_list(old_entities_dimtags)\n",
    "    new_entities_dimtags = extract_dimtags_list(new_entities_dimtags)\n",
    "    old_entities_dimtags = sorted(old_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "    new_entities_dimtags = sorted(new_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "    \n",
    "    # Create a list of lists of dimtags by dimension\n",
    "    old_entities_by_dim = [[] for _ in range(4)]\n",
    "    new_entities_by_dim = [[] for _ in range(4)]\n",
    "    for dimtag in old_entities_dimtags:\n",
    "        old_entities_by_dim[dimtag[0]].append(dimtag)\n",
    "    for dimtag in new_entities_dimtags:\n",
    "        # Verify that the dimtag exists in occ\n",
    "        try:\n",
    "            gmsh.model.getPhysicalGroupsForEntity(dimtag[0], dimtag[1])  # This will raise an error if the entity does not exist\n",
    "            new_entities_by_dim[dimtag[0]].append(dimtag)\n",
    "        except Exception as e:\n",
    "            if debug or DEBUG:\n",
    "                print(f\"[DEBUG] Entity {dimtag} does not exist in GMSH: {e}\")\n",
    "    \n",
    "    # Solve the assignment problem for each dimension\n",
    "    assignment_results = []\n",
    "    for dim in range(4):\n",
    "        assignment_results.append(dimtags_assignment(old_entities_by_dim[dim], new_entities_by_dim[dim], debug=debug_alt))\n",
    "    \n",
    "    # Create the complete solution\n",
    "    row_ind = []\n",
    "    col_ind = []\n",
    "    for dim in range(4):\n",
    "        row_ind += [i + sum(len(old_entities_by_dim[d]) for d in range(dim)) for i in assignment_results[dim][0]]\n",
    "        col_ind += [i + sum(len(new_entities_by_dim[d]) for d in range(dim)) for i in assignment_results[dim][1]]\n",
    "    \n",
    "    # Solve the assignment problem using linear_sum_assignment\n",
    "    old_dimtags = [old_entities_dimtags[i] for i in row_ind]\n",
    "    new_dimtags = [new_entities_dimtags[i] for i in col_ind]\n",
    "    \n",
    "    # Get the index of the old entities in the Bible according to thir dimtags\n",
    "    old_index = []\n",
    "    for old_dimtag in old_dimtags:\n",
    "        # Get the index of the old entity in the Bible\n",
    "        filtered = Bible[Bible[\"dimtag_entity\"] == old_dimtag]\n",
    "        if not filtered.empty:\n",
    "            index = filtered.index[0]\n",
    "            old_index.append(int(index))\n",
    "        else:\n",
    "            raise ValueError(f\"Entity {old_dimtag} not found in Bible\")\n",
    "        \n",
    "    # Create a dataframe from the Bible containing : index, old dimtag, new dimtag, name, group name\n",
    "    df_assignment = pd.DataFrame({\n",
    "        \"old_index\": old_index,\n",
    "        \"old_dimtag\": old_dimtags,\n",
    "        \"new_dimtag\": new_dimtags,\n",
    "        \"old_entity_name\": [Bible.loc[i, \"entity_name\"] if i in Bible.index else None for i in old_index],\n",
    "        \"old_group_name\": [Bible.loc[i, \"group_name\"] if i in Bible.index else None for i in old_index],\n",
    "        \"old_group_dimtag\": [Bible.loc[i, \"dimtag_group\"] if i in Bible.index else None for i in old_index]\n",
    "    })\n",
    "    \n",
    "    # Delete the old groups\n",
    "    for i in range(len(row_ind)):\n",
    "        old_group_dimtag = df_assignment[\"old_group_dimtag\"][i]\n",
    "        if old_group_dimtag is not None:\n",
    "            for dimtag in old_group_dimtag:\n",
    "                if not delete_physical_groups(dimtag[0], dimtag[1], debug=debug):\n",
    "                    raise ValueError(f\"Failed to delete physical group {dimtag[1]} in GMSH\")\n",
    "    \n",
    "    if len(new_entities_dimtags) != len(old_entities_dimtags):\n",
    "        # Print the result of the assignment\n",
    "        print(f\"[DEBUG] Result of the assignment : {[f\"{old_entities_dimtags[i]} -> {new_entities_dimtags[j]}\" for i, j in zip(row_ind, col_ind)]}\")\n",
    "        # Save the old and new dimtags to a CSV file\n",
    "        dimtags_df = pd.DataFrame({\"Old_dimtag\": old_dimtags, \"New_dimtag\": new_dimtags})\n",
    "        dimtags_df.to_csv(\"dimtags.csv\", index=False)\n",
    "        print(old_index)\n",
    "        # Save the assignment result to a CSV file\n",
    "        df_assignment.to_csv(\"assignment_result.csv\", index=False)\n",
    "        \n",
    "    # Loop through the assignment result\n",
    "    for i in range(len(row_ind)):\n",
    "        # Get the information from the assignment result\n",
    "        old_index = df_assignment[\"old_index\"][i]\n",
    "        old_dimtag = df_assignment[\"old_dimtag\"][i]\n",
    "        new_dimtag = df_assignment[\"new_dimtag\"][i]\n",
    "        old_entity_name = df_assignment[\"old_entity_name\"][i]\n",
    "        old_group_name = df_assignment[\"old_group_name\"][i]\n",
    "        \n",
    "        # Create the new group\n",
    "        new_group_dimtag = [(old_dimtag[0], start_tag + 1)]\n",
    "        start_tag += 1\n",
    "        \n",
    "        # Create the physical group in GMSH\n",
    "        if old_group_name is not None and old_group_name != []:\n",
    "            # Create the physical group in GMSH\n",
    "            group_name = old_group_name[0] if isinstance(old_group_name, list) else old_group_name\n",
    "            if not create_physical_group(dim=new_dimtag[0], tags=[new_dimtag[1]], name=group_name, group_tag=new_group_dimtag[0][1], debug=debug):\n",
    "                raise ValueError(f\"Failed to create physical group {group_name} in GMSH\")\n",
    "            gmsh.model.occ.synchronize()\n",
    "            \n",
    "        # Add the new entity to the Bible\n",
    "        add_to_bible(dimtag_entity=new_dimtag, dimtag_group=new_group_dimtag, group_name=group_name, entity_name=old_entity_name, overwrite=True, debug=debug)\n",
    "          \n",
    "    return Bible\n",
    "    \n",
    "def gmsh_function_preserve_physical_groups(operation_type, arguments, debug = False, ignore_dimtags=None, reassign_everything=True):\n",
    "    \"\"\"\n",
    "    Preserve physical groups after a boolean operation in GMSH.\n",
    "    \n",
    "    :param operation_type: Type of boolean operation ('union', 'difference', 'rotation').\n",
    "    :param arguments: Arguments for the boolean operation.\n",
    "    :return: Result of the boolean operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def concerned_entities_dimtags(object_dimtags, tools_dimtags=None, reassign_everything=reassign_everything):\n",
    "        \"\"\"\n",
    "        Get the concerned entities dimtags for a boolean operation.\n",
    "        :param object_dimtags: List of dimtags to consider.\n",
    "        :param tools_dimtags: List of tool dimtags to consider.\n",
    "        :return: List of concerned entities dimtags.\n",
    "        \"\"\"\n",
    "        # If we want to reassign everything, we need to get the entities in the model\n",
    "        if reassign_everything:\n",
    "            entities = gmsh.model.getEntities(3) + gmsh.model.getEntities(2)\n",
    "            entities = extract_dimtags_list(entities)\n",
    "            return entities\n",
    "        # If we don't want to reassign everything, we need to get the child entities of the object and tools\n",
    "        object_dimtags = extract_dimtags_list(object_dimtags)\n",
    "        child_objects = get_child_entities(object_dimtags, minimal_dim=2)\n",
    "        concerned_dimtags = object_dimtags + child_objects\n",
    "        if tools_dimtags is not None:\n",
    "            tools_dimtags = extract_dimtags_list(tools_dimtags)\n",
    "            child_tools = get_child_entities(tools_dimtags, minimal_dim=2)\n",
    "            concerned_dimtags = concerned_dimtags + tools_dimtags + child_tools + child_objects\n",
    "        concerned_dimtags = extract_dimtags_list(concerned_dimtags)\n",
    "        return concerned_dimtags      \n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Perform the boolean operation\n",
    "    if operation_type == \"fuse\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.fuse(first_arg, second_arg)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = concerned_entities_dimtags(result[0])\n",
    "    elif operation_type == \"cut\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.cut(first_arg, second_arg)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        boundaries = gmsh.model.getBoundary(result[0], oriented=False)\n",
    "        new_entities_dimtags = concerned_entities_dimtags(boundaries)\n",
    "    elif operation_type == \"rotate\":\n",
    "        # Extract the arguments \n",
    "        dimtags, x, y, z, ax, ay, az, angle = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(dimtags)\n",
    "        # Rotate the entities in the Bible\n",
    "        rotated_entity_to_tag_and_position = rotate_position(arguments)\n",
    "        result = gmsh.model.occ.rotate(dimtags, x, y, z, ax, ay, az, angle)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = old_entities_dimtags\n",
    "    elif operation_type == \"fragment\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg, new_name, fragmenter_prefix = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.fragment(first_arg, second_arg)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = concerned_entities_dimtags(result[0])\n",
    "    elif operation_type == \"dilate\":\n",
    "        # Extract the arguments\n",
    "        dimtags, center_vector, scale_vector = arguments\n",
    "        x, y, z = center_vector\n",
    "        ax, ay, az = scale_vector\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(dimtags)\n",
    "        result = gmsh.model.occ.dilate(dimtags, x, y, z, ax, ay, az)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = old_entities_dimtags\n",
    "    elif operation_type == \"intersect\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.intersect(first_arg, second_arg, removeObject=False, removeTool=True)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = concerned_entities_dimtags(result[0])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operation type. Use 'fuse', 'cut', or 'rotate'. Value used: {operation_type}\")\n",
    "    \n",
    "    \n",
    "    # Debug:\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Operation type: {operation_type}\")\n",
    "        print(f\"[DEBUG] Arguments: {arguments}\")\n",
    "        print(f\"[DEBUG] Result: {result}\")\n",
    "        print(f\"[DEBUG] Old entities dimtags: {old_entities_dimtags}\")\n",
    "        print(f\"[DEBUG] New entities dimtags: {new_entities_dimtags}\")\n",
    "    \n",
    "    # If we need to ignore some dimtags, we need to remove them from the old entities dimtags\n",
    "    if ignore_dimtags is not None:\n",
    "        # Get the dimtags of the entities\n",
    "        ignore_dimtags = extract_dimtags_list(ignore_dimtags)\n",
    "        # Remove the dimtags from the old entities dimtags\n",
    "        old_entities_dimtags = [dimtag for dimtag in old_entities_dimtags if dimtag not in ignore_dimtags]\n",
    "\n",
    "    # We need to recover the group entities and names via positions\n",
    "    recover_group_entities_and_names_via_positions(old_entities_dimtags, new_entities_dimtags, debug=debug)\n",
    "    return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76581721",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Diverse elements creator === ###\n",
    "\n",
    "def create_tube(radius, X_position, thickness, name_prefix=\"tube\", exterior_name=None, debug=False):\n",
    "    \"\"\"\n",
    "    Create only the lateral surface of a tube (no volume, no end caps).\n",
    "    Returns the tag of the lateral surface.\n",
    "    \"\"\"\n",
    "    global start_tag\n",
    "    global Bible\n",
    "\n",
    "    # Create the base disk\n",
    "    disk = gmsh.model.occ.addDisk(X_position, 0, 0, radius, radius)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    # Rotate disk to align with X axis\n",
    "    gmsh.model.occ.rotate([(2, disk)], X_position, 0, 0, 0, 1, 0, np.pi/2)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Extrude to get the lateral surface (returns [top, volume, lateral])\n",
    "    volume = gmsh.model.occ.extrude([(2, disk)], thickness, 0, 0)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # The lateral surface is volume[2][1]\n",
    "    lateral_surface = volume[2][1]\n",
    "    tag = start_tag\n",
    "    if exterior_name is None:\n",
    "        exterior_name = name_prefix + \"_Outer\"\n",
    "\n",
    "    # Create the physical group for the lateral surface\n",
    "    if not create_physical_group(dim=2, tags=[lateral_surface], name=exterior_name, group_tag=1 + start_tag, debug=debug):\n",
    "        raise ValueError(f\"Failed to create physical group {exterior_name} in GMSH\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Tube lateral surface created, tag={lateral_surface}, name={exterior_name}\")\n",
    "\n",
    "    return [(2, lateral_surface)]\n",
    "\n",
    "def create_plane(X, D, name=\"plane\"):\n",
    "    \"\"\"Create a plane using GMSH.\"\"\"\n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create a disk using GMSH\n",
    "    plane = gmsh.model.occ.addDisk(X, 0, 0, D, D)  # Adjusted radius to D_max / 2\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Rotate the disk 90 degrees on the Y axis\n",
    "    gmsh.model.occ.rotate([(2, plane)], X, 0, 0, 0, 1, 0, np.pi/2)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create a physical group for the disk\n",
    "    gmsh.model.addPhysicalGroup(2, [plane], tag=1 + start_tag)\n",
    "    gmsh.model.setPhysicalName(2, 1 + start_tag, name)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Actualize the start tag\n",
    "    start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((2, plane), name_overwrite=name)\n",
    "    \n",
    "    return plane  # Return the tag of the created volume\n",
    "    \n",
    "def fragments_entity_axis_X(entity_to_fragment, X_positions, Diameter, new_name=\"Fragment_\"):\n",
    "    \"\"\"Fragment an entity along the X-axis using GMSH.\"\"\"\n",
    "    global start_tag\n",
    "    \n",
    "    #Get group tag of the entity\n",
    "    group_tag = group_tags_via_entity_tag(entity_to_fragment)[0]\n",
    "    \n",
    "    # Create planes for fragmentation\n",
    "    for n in range(len(X_positions)):\n",
    "        X = X_positions[n]\n",
    "        plane = create_plane(X, Diameter, name=f\"Plane_{n}\")\n",
    "    # Get the tags of the planes via their group\n",
    "    planes = entities_tags_via_group_name(group_name=\"Plane_\")\n",
    "    if DEBUG:\n",
    "        print(f\"Planes for fragmentation: {planes}\")\n",
    "        \n",
    "    # Get the group name of the entity to fragment\n",
    "    concerned_groups = [group_name_via_tags(entity_to_fragment)[0]]\n",
    "    \n",
    "    # Perform the fragmentation\n",
    "    if DEBUG:\n",
    "        print(f\"Entity to fragment: {entity_to_fragment}\")\n",
    "        print(f\"Group tag of the entity to fragment: {group_tag}\")\n",
    "        print(f\"Concerned groups: {concerned_groups}\")\n",
    "    fragments = gmsh_function_preserve_physical_groups(\"fragment\", [[entity_to_fragment], planes, new_name, \"Plane_\"], concerned_entities=\"\") #concerned_groups)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # We need to delete the old group and entities\n",
    "    gmsh.model.removePhysicalGroups([group_tag])    \n",
    "    gmsh.model.occ.synchronize()\n",
    "    delete_entity([entity_to_fragment])\n",
    "    gmsh.model.occ.synchronize()\n",
    "    deleted_entities = delete_entities_without_physical_group()\n",
    "    if DEBUG:\n",
    "        print(f\"Deleted entities: {deleted_entities}\")\n",
    "        \n",
    "    #We delete the planes and their groups\n",
    "    delete_entities_with_physical_group(planes)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # We clean\n",
    "    delete_entities_without_physical_group()\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    return fragments\n",
    "\n",
    "def create_line(A_coord, B_coord, name=\"Line\", create_group=False, A_Tag=None, B_Tag=None):\n",
    "    \"\"\"Create a line using GMSH.\"\"\"\n",
    "    \n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible   \n",
    "    \n",
    "    # Correct the coordinates to be 3D\n",
    "    if len(A_coord) != 3:\n",
    "        A_coord = [A_coord[0], A_coord[1], 0]\n",
    "    if len(B_coord) != 3:\n",
    "        B_coord = [B_coord[0], B_coord[1], 0]\n",
    "        \n",
    "    # Create points using GMSH\n",
    "    if A_Tag is None:\n",
    "        A = gmsh.model.occ.addPoint(A_coord[0], A_coord[1], A_coord[2])\n",
    "        A_Tag = A\n",
    "    if B_Tag is None:\n",
    "        B = gmsh.model.occ.addPoint(B_coord[0], B_coord[1], B_coord[2])\n",
    "        B_Tag = B\n",
    "\n",
    "    # Create a line using GMSH\n",
    "    line = gmsh.model.occ.addLine(A_Tag, B_Tag)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if create_group:\n",
    "        # Create a physical group for the line\n",
    "        gmsh.model.addPhysicalGroup(1, [line], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(1, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "        \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((1, line), name_overwrite=name)\n",
    "    \n",
    "    return line, A_Tag, B_Tag  # Return the tag of the created line\n",
    "\n",
    "def add_volume_by_faces(faces_tags, name=\"Volume_by_Faces\", sewing=False, debug=False):\n",
    "    \"\"\"Add a volume by faces.\"\"\"\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Create the volume by faces\n",
    "    surface_loop = gmsh.model.occ.addSurfaceLoop(faces_tags,start_tag, sewing=sewing)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create the volume\n",
    "    volume = gmsh.model.occ.addVolume([surface_loop], start_tag + 1)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    #Verify the volume\n",
    "    if volume is None:\n",
    "        raise Exception(f\"Failed to create the volume by faces with name {name}.\")\n",
    "    \n",
    "    # Create the physical group for the volume\n",
    "    if not create_physical_group(dim=3, tags=[volume], name=name, debug=debug):\n",
    "        raise Exception(f\"Failed to create the physical group for the volume {name}.\")\n",
    "    \n",
    "    return volume\n",
    "\n",
    "def create_bspline(points, name=\"BSpline\", create_group=False, A_Tag=None, B_Tag=None):\n",
    "    \"\"\"Create a B-spline curve using GMSH.\"\"\"\n",
    "    \n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    #Add the points to the GMSH model\n",
    "    points_tags = []\n",
    "    for i, point in enumerate(points):\n",
    "        if len(point) == 2:\n",
    "            point = [point[0], point[1], 0]\n",
    "        elif len(point) == 3:\n",
    "            point = [point[0], point[1], point[2]]\n",
    "        else:\n",
    "            raise ValueError(\"Each point must have 2 or 3 coordinates.\")\n",
    "        if i == 0:\n",
    "            if A_Tag is not None:\n",
    "                point_tag = A_Tag\n",
    "            else:\n",
    "                point_tag = gmsh.model.occ.addPoint(point[0], point[1], point[2])\n",
    "                A_Tag = point_tag\n",
    "        elif i == len(points) - 1:\n",
    "            if B_Tag is not None:\n",
    "                point_tag = B_Tag\n",
    "            else:\n",
    "                point_tag = gmsh.model.occ.addPoint(point[0], point[1], point[2])\n",
    "                B_Tag = point_tag\n",
    "        else:\n",
    "            point_tag = gmsh.model.occ.addPoint(point[0], point[1], point[2])\n",
    "        points_tags.append(point_tag)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create a B-spline curve using GMSH\n",
    "    bspline = gmsh.model.occ.addBSpline(points_tags)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if create_group:\n",
    "        # Create a physical group for the B-spline\n",
    "        gmsh.model.addPhysicalGroup(2, [bspline], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(2, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((1, bspline), name_overwrite=name)\n",
    "    \n",
    "    return bspline, A_Tag, B_Tag  # Return the tag of the created B-spline\n",
    "\n",
    "def create_curveloop(tags, name=\"CurveLoop\", create_group=False):\n",
    "    \"\"\"Create a curve loop using GMSH.\"\"\"\n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "\n",
    "    # Create a curve loop using GMSH\n",
    "    curve_loop = gmsh.model.occ.addCurveLoop(tags)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if create_group:\n",
    "        # Create a physical group for the curve loop\n",
    "        gmsh.model.addPhysicalGroup(1, [curve_loop], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(1, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((1, curve_loop), name_overwrite=name)\n",
    "    \n",
    "    return curve_loop  # Return the tag of the created curve loop\n",
    "\n",
    "def create_plane_surface(tags, name=\"PlaneSurface\", create_group=False):\n",
    "    \"\"\"Create a plane surface using GMSH.\"\"\"\n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create a plane surface using GMSH\n",
    "    try:\n",
    "        plane_surface = gmsh.model.occ.addPlaneSurface(tags)\n",
    "    except Exception as e:\n",
    "        plane_surface = gmsh.model.occ.addSurfaceFilling(tags[0])\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Verify the plane surface\n",
    "    if plane_surface is None:\n",
    "        raise ValueError(\"Error: Plane surface creation failed. Please check the input tags.\")\n",
    "    \n",
    "    # Create a physical group for the plane surface\n",
    "    if create_group:\n",
    "        # Create a physical group for the plane surface\n",
    "        gmsh.model.addPhysicalGroup(2, [plane_surface], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(2, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((2, plane_surface), name_overwrite=name)\n",
    "    \n",
    "    return plane_surface  # Return the tag of the created plane surface\n",
    "\n",
    "def create_plane_4_points(points, points_tags = None, name=\"PlaneSurface\", debug=False):\n",
    "    \"\"\"Create a plane surface using 4 points in GMSH.\"\"\"\n",
    "    \n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    if len(points) != 4:\n",
    "        raise ValueError(\"Error: You must provide exactly 4 points to create a plane surface.\")\n",
    "    if points_tags is not None:\n",
    "        if len(points) != len(points_tags) and points_tags:\n",
    "            raise ValueError(\"Error: The number of points must match the number of point tags.\")\n",
    "    \n",
    "    # Create lines between the points\n",
    "    lines = []\n",
    "    for i in range(4):\n",
    "        if points_tags is not None:\n",
    "            A_Tag = points_tags[i]\n",
    "            B_Tag = points_tags[(i + 1) % 4]\n",
    "        else:\n",
    "            A_Tag = None\n",
    "            B_Tag = None\n",
    "        A_coord = points[i]\n",
    "        B_coord = points[(i + 1) % 4]  # Connect to the next point, wrapping around\n",
    "        line, _, _ = create_line(A_coord, B_coord, name=f\"Line_{i}\", create_group=False, A_Tag=A_Tag, B_Tag=B_Tag)\n",
    "        lines.append(line)\n",
    "    \n",
    "    # Create a curve loop from the lines\n",
    "    curve_loop = create_curveloop(lines, name=\"CurveLoop\", create_group=False)\n",
    "    \n",
    "    # Create a plane surface from the curve loop\n",
    "    plane_surface = create_plane_surface([curve_loop], name=name, create_group=True)\n",
    "    \n",
    "    return plane_surface  # Return the tag of the created plane surface\n",
    "    \n",
    "    \n",
    "def profile_gmsh_instruction(profile, reinforcement=False, name=None, create_group=False, A_Tag=None, B_Tag=None, debug=False):\n",
    "    \"\"\"This function will create the instruction to generate the profile in GMSH.\"\"\"\n",
    "        \n",
    "    # In case of a reinforcement, this is more complicated and need to be done in a different way\n",
    "    if reinforcement:\n",
    "        global number_of_points_profile\n",
    "        instructions = create_reinforcement_instructions(number_of_points_profile, debug=debug)\n",
    "        if debug:\n",
    "            print(f\"Instructions for reinforcement: {instructions}\")\n",
    "        return instructions\n",
    "    \n",
    "    # If the profile as 2 points, we can create a line, if it has at least 3 points, we can create a B-spline\n",
    "    if len(profile) == 2:\n",
    "        #create_line(A_coord, B_coord, name=\"Line\", create_group=False, A_Tag=None, B_Tag=None):\n",
    "        return [[\"line\", name, profile[0], profile[1], name, create_group, A_Tag, B_Tag]]\n",
    "    elif len(profile) >= 3:\n",
    "        #create_bspline(points, name=\"BSpline\", create_group=False, A_Tag=None, B_Tag=None)\n",
    "        return [[\"bspline\", name, profile, name, create_group, A_Tag, B_Tag]]\n",
    "    else:\n",
    "        print(\"Error: The profile must have at least 2 points.\")\n",
    "        return None\n",
    "\n",
    "def verify_instructions(instructions, proximity_tol=1e-5, debug=False):\n",
    "    '''\n",
    "    This function will verify the instructions to create the geometry.\n",
    "    It will check if the instructions are valid and if the points are in the right order.\n",
    "    It will also check their is no duplicate points.\n",
    "    '''\n",
    "    # Create a list of all the points\n",
    "    all_points = []\n",
    "    \n",
    "    # Check if instructions is a list and not empty\n",
    "    if not isinstance(instructions, list) or len(instructions) == 0:\n",
    "        raise ValueError(\"Instructions must be a non-empty list.\")\n",
    "\n",
    "    prev_end = None\n",
    "    start_points = []\n",
    "    for idx, instr in enumerate(instructions):\n",
    "        # Check instruction type\n",
    "        if not isinstance(instr, list) or len(instr) < 2:\n",
    "            raise ValueError(f\"Instruction at index {idx} is not valid: {instr}\")\n",
    "\n",
    "        instr_type = instr[0]\n",
    "        if instr_type not in [\"line\", \"bspline\"]:\n",
    "            raise ValueError(f\"Unknown instruction type '{instr_type}' at index {idx}.\")\n",
    "\n",
    "        # Check points for line\n",
    "        if instr_type == \"line\":\n",
    "            if len(instr) < 4:\n",
    "                raise ValueError(f\"Line instruction at index {idx} does not have enough arguments.\")\n",
    "            A, B = np.array(instr[2]), np.array(instr[3])\n",
    "            start_points.append(tuple(A))\n",
    "            all_points.append(tuple(A))\n",
    "            all_points.append(tuple(B))\n",
    "            if np.allclose(A, B, atol=proximity_tol):\n",
    "                raise ValueError(f\"Duplicate points in line at index {idx}: {A} and {B}\")\n",
    "            # Check consecutive instructions\n",
    "            if prev_end is not None and not np.allclose(prev_end, A, atol=proximity_tol):\n",
    "                raise ValueError(f\"Consecutive instructions at index {idx-1} and {idx} do not have matching points: {prev_end} != {A}\")\n",
    "            prev_end = B\n",
    "\n",
    "        # Check points for bspline\n",
    "        if instr_type == \"bspline\":\n",
    "            if len(instr) < 3:\n",
    "                raise ValueError(f\"BSpline instruction at index {idx} does not have enough arguments.\")\n",
    "            points = np.array(instr[2])\n",
    "            if len(points) < 3:\n",
    "                raise ValueError(f\"BSpline at index {idx} must have at least 3 points.\")\n",
    "            # Check for duplicate consecutive points\n",
    "            for i in range(1, len(points)):\n",
    "                if np.allclose(points[i], points[i-1], atol=proximity_tol):\n",
    "                    warning_text = f\"Duplicate consecutive points in bspline at index {idx}: {points[i-1]} and {points[i]}\"\n",
    "                    warnings.warn(warning_text, UserWarning)\n",
    "            start_points.append(tuple(points[0]))\n",
    "            all_points.extend([tuple(pt) for pt in points])\n",
    "            # Check consecutive instructions\n",
    "            if prev_end is not None and not np.allclose(prev_end, points[0], atol=proximity_tol):\n",
    "                raise ValueError(f\"Consecutive instructions at index {idx-1} and {idx} do not have matching points: {prev_end} != {points[0]}\")\n",
    "            prev_end = points[-1]\n",
    "\n",
    "    # Check for duplicate start points\n",
    "    seen = set()\n",
    "    for pt in start_points:\n",
    "        for seen_pt in seen:\n",
    "            if np.allclose(pt, seen_pt, atol=proximity_tol):\n",
    "                raise ValueError(f\"Duplicate start points found: {pt} and {seen_pt}\")\n",
    "        seen.add(pt)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Instructions verified: all checks passed.\")\n",
    "    return True\n",
    "    \n",
    "     \n",
    "def create_from_instructions(instructions, debug=False):\n",
    "    \"\"\"\n",
    "    Create a geometry from a list of instructions.\n",
    "    A list of instructions is always a continuity. \n",
    "    \n",
    "    :param instructions: List of instructions to create the geometry.\n",
    "    :return: list of outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify the instructions\n",
    "    verify_instructions(instructions, debug=debug)\n",
    "    \n",
    "    entities_tags = []\n",
    "    points_tags = []\n",
    "    entities_names = []\n",
    "    \n",
    "    # Loop through the instructions\n",
    "    for i, instruction in enumerate(instructions):\n",
    "        type_instruction = instruction[0]\n",
    "        entity_name = instruction[1]\n",
    "        entities_names.append(entity_name)\n",
    "        arguments = instruction[2:]\n",
    "        \n",
    "        # We need to adapt the arguments to get a continuity of the tags\n",
    "        if i > 0 :\n",
    "            arguments[-2] = points_tags[-1] # Last point of the previous instruction for the first point of the current instruction            \n",
    "        if type_instruction == \"line\":\n",
    "            # Create a line\n",
    "            line, A_Tag, B_Tag = create_line(*arguments)\n",
    "            entities_tags.append(line)\n",
    "        elif type_instruction == \"bspline\":\n",
    "            # Create a B-spline\n",
    "            bspline, A_Tag, B_Tag = create_bspline(*arguments)\n",
    "            entities_tags.append(bspline)\n",
    "        else:\n",
    "            print(f\"Unknown instruction type: {type_instruction}\")\n",
    "            continue\n",
    "        \n",
    "        if i == 0:\n",
    "            # Add the first point to the list\n",
    "            points_tags.append(A_Tag)\n",
    "        else: \n",
    "            # Check if the first point of the current instruction is the same as the last point of the previous instruction\n",
    "            if points_tags[-1] != A_Tag:\n",
    "                print(f\"Warning: The first point of the current instruction is not the same as the last point of the previous instruction. {points_tags[-1]} != {A_Tag}\")\n",
    "        # Add the last point to the list\n",
    "        points_tags.append(B_Tag)\n",
    "    \n",
    "    return entities_tags, points_tags, entities_names\n",
    "\n",
    "def create_revolved_line(A, B, angle_revolution, surface_name=\"Revolved_Line\", debug=False):\n",
    "    \"\"\"Create a revolved line around the X-axis.\"\"\"\n",
    "    \n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Create the line\n",
    "    line = create_line(A, B, name=surface_name, create_group=False)\n",
    "    \n",
    "    # Revolve the line\n",
    "    revolved_line = gmsh.model.occ.revolve([(1, line[0])], 0, 0, 0, 1, 0, 0, angle_revolution)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Get the tag of the surface\n",
    "    surface_tag = [tag[1] for tag in revolved_line if isinstance(tag, tuple) and tag[0] == 2]\n",
    "\n",
    "    # Create the physical group for the revolved line\n",
    "    start_tag += 1\n",
    "    if revolved_line is None:\n",
    "        raise Exception(f\"Failed to create the revolved line {surface_name}.\")\n",
    "    if not create_physical_group(dim=2, tags=surface_tag, name=surface_name, debug=debug):\n",
    "        raise Exception(f\"Failed to create the physical group for the revolved line {surface_name}.\")\n",
    "    \n",
    "    return surface_tag\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Define the different profiles === ###\n",
    "\n",
    "def define_profiles_from_CSV():\n",
    "    global geometry_data\n",
    "    # We define the different profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Channel_Angle_Size, Channel_Number\n",
    "    global Channel_Angle_Size_Mean\n",
    "    global Angle_Size\n",
    "    global Radius_Study_Margin\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    global Channel_Width\n",
    "    global Channel_Number\n",
    "    \n",
    "    # Get the data\n",
    "    x = geometry_data[\"x\"]\n",
    "    y_nozzle_inner = geometry_data[\"nozzle inner wall\"].astype(float).values\n",
    "    y_nozzle_outer = geometry_data[\"nozzle outer wall\"].astype(float).values\n",
    "    y_channel_inner = geometry_data[\"channel inner wall\"].astype(float).values\n",
    "    y_channel_outer = geometry_data[\"channel outer wall\"].astype(float).values\n",
    "    y_channel_width = geometry_data[\"channel width\"].astype(float).values\n",
    "    y_channel_number = geometry_data[\"number channels\"].astype(float).values\n",
    "    \n",
    "    # We create the exterior limit profile via the max outside profile and the Radius Study Margin\n",
    "    y_exterior = np.full_like(x, np.max(y_nozzle_outer) + Radius_Study_Margin)\n",
    "    \n",
    "    #We create the center profile as a profile of height 0\n",
    "    y_center= np.zeros_like(x)\n",
    "    \n",
    "    # Create the profiles\n",
    "    Nozzle_Profile_Inner = np.array([x[::-1], y_nozzle_inner[::-1]]).T\n",
    "    Nozzle_Profile_Outer = np.array([x, y_nozzle_outer]).T\n",
    "    Channel_Profile_Inner = np.array([x[::-1], y_channel_inner[::-1]]).T\n",
    "    Channel_Profile_Outer = np.array([x, y_channel_outer]).T\n",
    "    Center_Profile = np.array([x, y_center]).T\n",
    "    Exterior_Profile = np.array([x, y_exterior]).T\n",
    "    \n",
    "    # Define the channel angle size and channel number\n",
    "    Channel_Angle_Size = [y_channel_width[i] / np.mean([y_channel_inner[i], y_channel_outer[i]]) for i in range(len(x))]\n",
    "    Channel_Angle_Size_Mean = np.mean(Channel_Angle_Size)\n",
    "    Channel_Number = int(np.mean(y_channel_number))\n",
    "    Channel_Width = np.array([x, y_channel_width]).T\n",
    "    Channel_Angle_Size = np.mean(Channel_Angle_Size)  # Use the mean value for the channel angle size    \n",
    "    \n",
    "    # Define other variables\n",
    "    Angle_Size = Nozzle_Angle_Revolution\n",
    "    \n",
    "    return True\n",
    "\n",
    "def plot_profiles(nozzle=False, channel=False):\n",
    "\n",
    "    # Get the profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    \n",
    "    # Plot the profiles\n",
    "    plt.figure()\n",
    "    plt.plot(Nozzle_Profile_Inner[:, 0], Nozzle_Profile_Inner[:, 1], label=\"Nozzle Inner Profile\", color='blue')\n",
    "    plt.plot(Nozzle_Profile_Outer[:, 0], Nozzle_Profile_Outer[:, 1], label=\"Nozzle Outer Profile\", color='red')\n",
    "    plt.plot(Channel_Profile_Inner[:, 0], Channel_Profile_Inner[:, 1], label=\"Channel Inner Profile\", color='green')\n",
    "    plt.plot(Channel_Profile_Outer[:, 0], Channel_Profile_Outer[:, 1], label=\"Channel Outer Profile\", color='orange')\n",
    "    plt.plot(Center_Profile[:, 0], Center_Profile[:, 1], label=\"Center Profile\", color='black', linestyle='--')\n",
    "    plt.plot(Exterior_Profile[:, 0], Exterior_Profile[:, 1], label=\"Exterior Profile\", color='gray', linestyle='--')\n",
    "    plt.title(\"Profiles of the Rocket Engine\")\n",
    "    plt.xlabel(\"X-axis\")\n",
    "    plt.ylabel(\"Y-axis\")\n",
    "    plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "    plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Add independent plots for nozzle and channel\n",
    "    if nozzle:\n",
    "        plt.figure()\n",
    "        plt.plot(Nozzle_Profile_Inner[:, 0], Nozzle_Profile_Inner[:, 1], label=\"Nozzle Inner Profile\", color='blue')\n",
    "        plt.plot(Nozzle_Profile_Outer[:, 0], Nozzle_Profile_Outer[:, 1], label=\"Nozzle Outer Profile\", color='red')\n",
    "        plt.plot(Center_Profile[:, 0], Center_Profile[:, 1], label=\"Center Profile\", color='black', linestyle='--')\n",
    "        plt.plot(Exterior_Profile[:, 0], Exterior_Profile[:, 1], label=\"Exterior Profile\", color='gray', linestyle='--')\n",
    "        plt.title(\"Nozzle Profiles\")\n",
    "        plt.xlabel(\"X-axis\")\n",
    "        plt.ylabel(\"Y-axis\")\n",
    "        plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    if channel:\n",
    "        plt.figure()\n",
    "        plt.plot(Channel_Profile_Inner[:, 0], Channel_Profile_Inner[:, 1], label=\"Channel Inner Profile\", color='green')\n",
    "        plt.plot(Channel_Profile_Outer[:, 0], Channel_Profile_Outer[:, 1], label=\"Channel Outer Profile\", color='orange')\n",
    "        plt.title(\"Channel Profiles\")\n",
    "        plt.xlabel(\"X-axis\")\n",
    "        plt.ylabel(\"Y-axis\")\n",
    "        plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "        # Add a circular plot showing all the possible channels with the angle size\n",
    "        plt.figure()\n",
    "        angle_positions = np.linspace(0, 2 * np.pi, Channel_Number, endpoint=False)\n",
    "        for i in range(Channel_Number):\n",
    "            start_angle = angle_positions[i]\n",
    "            # Draw the sector for each channel\n",
    "            points = np.array([\n",
    "                (np.cos(start_angle + a), np.sin(start_angle + a))\n",
    "                for a in np.linspace(0, Channel_Angle_Size_Mean, 100)\n",
    "            ])\n",
    "            plt.plot(points[:, 0], points[:, 1], color='green', alpha=0.5)\n",
    "        plt.title(\"Channel Angle Positions\")\n",
    "        plt.xlabel(\"X-axis\")\n",
    "        plt.ylabel(\"Y-axis\")\n",
    "        plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.grid()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def treat_the_profiles():\n",
    "    \n",
    "    # Get the profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    \n",
    "    # Get the information of the reinforcements\n",
    "    global Radial_Reinforcement_Density, Radial_Reinforcement_Number\n",
    "    global Radial_Reinforcement_Thickness, Radial_Reinforcement_Width\n",
    "    \n",
    "    # Get the information of the treatement\n",
    "    global number_of_points_profile, reduce_points_method, ratio_for_accel_points\n",
    "    global Cooling_Channel_Extension\n",
    "    global Nozzle_Modificator_Inner, Nozzle_Modificator_Outer\n",
    "    global Cooling_Channel_Modificator_Inner, Cooling_Channel_Modificator_Outer\n",
    "    \n",
    "    # Treat the cooling profiles by adding extensions at each end\n",
    "    Inner_Start_Cooling_Channel_Point = np.array([Channel_Profile_Inner[0][0] + Cooling_Channel_Extension, Channel_Profile_Inner[0][1]])\n",
    "    Inner_End_Cooling_Channel_Point = np.array([Channel_Profile_Inner[-1][0] - Cooling_Channel_Extension, Channel_Profile_Inner[-1][1]])\n",
    "    Outer_Start_Cooling_Channel_Point = np.array([Channel_Profile_Outer[0][0] - Cooling_Channel_Extension, Channel_Profile_Outer[0][1]])\n",
    "    Outer_End_Cooling_Channel_Point = np.array([Channel_Profile_Outer[-1][0] + Cooling_Channel_Extension, Channel_Profile_Outer[-1][1]])\n",
    "    Channel_Profile_Inner = np.vstack((Inner_Start_Cooling_Channel_Point, Channel_Profile_Inner, Inner_End_Cooling_Channel_Point))\n",
    "    Channel_Profile_Outer = np.vstack((Outer_Start_Cooling_Channel_Point, Channel_Profile_Outer, Outer_End_Cooling_Channel_Point))\n",
    "    \n",
    "    # Application of the potential modificators\n",
    "    Nozzle_Profile_Inner = profile_points_modificator(Nozzle_Profile_Inner, Nozzle_Modificator_Inner)\n",
    "    Nozzle_Profile_Outer = profile_points_modificator(Nozzle_Profile_Outer, Nozzle_Modificator_Outer)\n",
    "    Channel_Profile_Inner = profile_points_modificator(Channel_Profile_Inner, Cooling_Channel_Modificator_Inner)\n",
    "    Channel_Profile_Outer = profile_points_modificator(Channel_Profile_Outer, Cooling_Channel_Modificator_Outer)\n",
    "    Center_Profile = profile_points_modificator(Center_Profile, lambda x: 0*x)  # No modification for the center profile\n",
    "    Exterior_Profile = profile_points_modificator(Exterior_Profile, lambda x: 0*x)  # No modification for the exterior profile\n",
    "    \n",
    "    # Remove duplicates\n",
    "    Nozzle_Profile_Inner = remove_duplicate_points(Nozzle_Profile_Inner)\n",
    "    Nozzle_Profile_Outer = remove_duplicate_points(Nozzle_Profile_Outer)\n",
    "    Channel_Profile_Inner = remove_duplicate_points(Channel_Profile_Inner)\n",
    "    Channel_Profile_Outer = remove_duplicate_points(Channel_Profile_Outer)\n",
    "    Center_Profile = remove_duplicate_points(Center_Profile)\n",
    "    Exterior_Profile = remove_duplicate_points(Exterior_Profile)\n",
    "    \n",
    "    # Reduce the number of points\n",
    "    Nozzle_Profile_Inner = reduce_number_points_list(Nozzle_Profile_Inner, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Nozzle_Profile_Outer = reduce_number_points_list(Nozzle_Profile_Outer, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Channel_Profile_Inner = reduce_number_points_list(Channel_Profile_Inner, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Channel_Profile_Outer = reduce_number_points_list(Channel_Profile_Outer, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Center_Profile = reduce_number_points_list(Center_Profile, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Exterior_Profile = reduce_number_points_list(Exterior_Profile, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    \n",
    "    # Debug: plot all the profiles\n",
    "    if DEBUG:\n",
    "        plot_profiles()\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def generate_profiles(debug=False):\n",
    "    \"\"\"Create the profiles of the rocket engine.\"\"\"\n",
    "    \n",
    "\n",
    "    # Define the profiles from the CSV file\n",
    "    define_profiles_from_CSV()\n",
    "    print(\"Profiles defined from CSV file.\")\n",
    "    \n",
    "    # Debug: plot the profiles\n",
    "    if debug:\n",
    "        plot_profiles(nozzle=True, channel=True)\n",
    "    \n",
    "    # Treat the profiles\n",
    "    treat_the_profiles()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58362e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Create the reinforcement === ###\n",
    "\n",
    "def create_positions_reinforcement(debug=False, tol_factor=0.1):\n",
    "    \"\"\"Create the positions of the reinforcements.\"\"\"\n",
    "    # Get the parameters from the user\n",
    "    global X_Parameters_Nozzle\n",
    "    global Radial_Reinforcement_Number, Radial_Reinforcement_Density\n",
    "    global Radial_Reinforcement_Width\n",
    "    global Radial_Reinforcement_Margin_Entry, Radial_Reinforcement_Margin_Exit\n",
    "    \n",
    "    # Get the positions from the density\n",
    "    normalized_positions = positions_from_density(Radial_Reinforcement_Density, Radial_Reinforcement_Number, debug=debug)\n",
    "    # Unnormalize the positions\n",
    "    start_positions = X_Parameters_Nozzle[0] + Radial_Reinforcement_Margin_Entry\n",
    "    end_positions = X_Parameters_Nozzle[2] - Radial_Reinforcement_Margin_Exit - Radial_Reinforcement_Width # The noramlized positions are the start positions\n",
    "    reinforcement_start_positions = normalized_positions * (end_positions - start_positions) + start_positions\n",
    "    reinforcement_end_positions = reinforcement_start_positions + Radial_Reinforcement_Width\n",
    "    \n",
    "    # Verify and correct any overlaps\n",
    "    for i in range(len(reinforcement_start_positions) - 1):\n",
    "        if reinforcement_end_positions[i] > reinforcement_start_positions[i + 1]:\n",
    "            # Overlap detected, adjust the end position of the current reinforcement\n",
    "            reinforcement_end_positions[i] = reinforcement_start_positions[i + 1] - Radial_Reinforcement_Width * tol_factor\n",
    "    \n",
    "    # Create the list of start, end for the reinforcements\n",
    "    reinforcement_positions = [(reinforcement_start_positions[i], reinforcement_end_positions[i]) for i in range(len(reinforcement_start_positions))]\n",
    "    \n",
    "    return reinforcement_positions\n",
    "\n",
    "def profile_to_bspline_instruction(profile_func, start, end, points_number, name=None, create_group=False):\n",
    "    \"\"\"Create the instruction to generate the profile in GMSH.\"\"\"\n",
    "    \n",
    "    # Get the list of points\n",
    "    x = np.linspace(start, end, points_number)\n",
    "    y = profile_func(x)\n",
    "    points = np.array([x, y]).T\n",
    "    \n",
    "    # Remove duplicates\n",
    "    points = remove_duplicate_points(points)\n",
    "    \n",
    "    # Create the instruction for the profile\n",
    "    instructions = profile_gmsh_instruction(points, reinforcement=False, name=name, create_group=create_group)\n",
    "    \n",
    "    return instructions\n",
    "\n",
    "def create_instruction_one_reinforcement(reinforcement_position, reinforcement_number, number_points, profile_func, debug=False):\n",
    "    \"\"\"Create the instruction for one reinforcement.\"\"\"\n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Outer\n",
    "    global Radial_Reinforcement_Height\n",
    "    \n",
    "    # Get the start and end positions of the reinforcement\n",
    "    start_position = reinforcement_position[0]\n",
    "    end_position = reinforcement_position[1]\n",
    "    \n",
    "    # Create the four points for the reinforcement\n",
    "    A = np.array([start_position, profile_func(start_position)])\n",
    "    B = np.array([start_position, profile_func(start_position) + Radial_Reinforcement_Height])\n",
    "    C = np.array([end_position, profile_func(end_position) + Radial_Reinforcement_Height])    \n",
    "    D = np.array([end_position, profile_func(end_position)])\n",
    "    \n",
    "    # Create the profile function for the outer part\n",
    "    profile_func_outer = lambda x: profile_func(x) + Radial_Reinforcement_Height\n",
    "    \n",
    "    # Create the instruction for the start line of the reinforcement\n",
    "    instruction_front = profile_gmsh_instruction([A, B], reinforcement=False, name=f\"Reinforcement_{reinforcement_number}_Front\", create_group=False)\n",
    "    instruction_outer = profile_to_bspline_instruction(profile_func_outer, start_position, end_position, number_points, name=f\"Reinforcement_{reinforcement_number}_Outer\", create_group=False)\n",
    "    instruction_back = profile_gmsh_instruction([C, D], reinforcement=False, name=f\"Reinforcement_{reinforcement_number}_Back\", create_group=False)\n",
    "    \n",
    "    # We create the list of instructions\n",
    "    instructions_reinforcement = [instruction_front, instruction_outer, instruction_back]\n",
    "\n",
    "    # Debug: print the instructions\n",
    "    if debug:\n",
    "        print(f\"Reinforcement {reinforcement_number}:\")\n",
    "        print(f\"Start position: {A}\")\n",
    "        print(f\"End position: {D}\")\n",
    "        print(f\"Instructions: {instructions_reinforcement}\")\n",
    "    return instructions_reinforcement\n",
    "\n",
    "\n",
    "def create_reinforcement_instructions(number_of_points, debug=False):\n",
    "    \"\"\"Create the instructions for all the reinforcements.\"\"\"\n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Outer\n",
    "    global X_Parameters_Nozzle\n",
    "    global Radial_Reinforcement_Height, Radial_Reinforcement_Width\n",
    "    global Radial_Reinforcement_Margin_Entry, Radial_Reinforcement_Margin_Exit\n",
    "    global Radial_Reinforcement_Number, Radial_Reinforcement_Density\n",
    "    \n",
    "    # Get the positions of the reinforcements\n",
    "    reinforcement_positions = create_positions_reinforcement(debug=debug)\n",
    "    \n",
    "    # Create the profile function\n",
    "    profile_func = scipy.interpolate.interp1d(Nozzle_Profile_Outer[:, 0], Nozzle_Profile_Outer[:, 1], fill_value=\"extrapolate\")\n",
    "    \n",
    "    # Create the list of instructions\n",
    "    instructions_reinforcements = []\n",
    "    counter_outer = 1 # To name the sections of the Outer profile\n",
    "    \n",
    "    # We first create the instruction in case of entry margin\n",
    "    if Radial_Reinforcement_Margin_Entry > 0:\n",
    "        # Get the first point of the Nozzle profile\n",
    "        start_point = Nozzle_Profile_Outer[0]\n",
    "        first_reinforcement_position = reinforcement_positions[0]\n",
    "        # Create the instruction for the first reinforcement\n",
    "        instruction_entry_margin = profile_to_bspline_instruction(profile_func, start_point[0], first_reinforcement_position[0], number_of_points, name=\"Nozzle_Outer_Wall_\" + str(counter_outer), create_group=False)\n",
    "        instructions_reinforcements.append(instruction_entry_margin)\n",
    "        counter_outer += 1\n",
    "        \n",
    "    # Loop through the reinforcements\n",
    "    for i, reinforcement_position in enumerate(reinforcement_positions):\n",
    "        # Create the instruction for one reinforcement\n",
    "        instruction = create_instruction_one_reinforcement(reinforcement_position, i + 1, number_of_points, profile_func, debug=debug)\n",
    "        for inst in instruction:\n",
    "                instructions_reinforcements.append(inst)\n",
    "        # Create the instruction for inner sections if it is not the last one\n",
    "        if i < len(reinforcement_positions) - 1:\n",
    "            # Get the start and end positions of the next reinforcement\n",
    "            next_reinforcement_position = reinforcement_positions[i + 1]\n",
    "            # Create the instruction for the inner section\n",
    "            instruction_inner = profile_to_bspline_instruction(profile_func, reinforcement_position[1], next_reinforcement_position[0], number_of_points, name=\"Nozzle_Outer_Wall_\" + str(counter_outer), create_group=False)\n",
    "            instructions_reinforcements.append(instruction_inner)\n",
    "            counter_outer += 1\n",
    "    \n",
    "    # We create the instruction in case of exit margin\n",
    "    if Radial_Reinforcement_Margin_Exit > 0:\n",
    "        # Get the last point of the Nozzle profile\n",
    "        end_point = Nozzle_Profile_Outer[-1]\n",
    "        last_reinforcement_position = reinforcement_positions[-1]\n",
    "        # Create the instruction for the last reinforcement\n",
    "        instruction_exit_margin = profile_to_bspline_instruction(profile_func, last_reinforcement_position[1], end_point[0], number_of_points, name=\"Nozzle_Outer_Wall_\" + str(counter_outer), create_group=False)\n",
    "        instructions_reinforcements.append(instruction_exit_margin)\n",
    "        \n",
    "    # Flatten the list of instructions\n",
    "    instructions_reinforcements = [item for sublist in instructions_reinforcements for item in sublist]\n",
    "    \n",
    "    # Debug: print the instructions\n",
    "    if debug:\n",
    "        print(f\"Reinforcement positions: {reinforcement_positions}\")\n",
    "        print(f\"Instructions for reinforcements: {instructions_reinforcements}\")\n",
    "        \n",
    "    return instructions_reinforcements\n",
    "   \n",
    "if False:\n",
    "    create_reinforcement_instructions(10, debug=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Create the curved element (GMSH)=== ###\n",
    "    \n",
    "def generate_minimal_curved_element(Type = \"Nozzle\", overwrite_start_tag=None, channel_number=None, \n",
    "                                    custom_inner = None, custom_outer = None, custom_angle = None, custom_name = None,\n",
    "                                    debug=False):\n",
    "    \"\"\"Generate the rocket engine geometry using GMSH.\"\"\"\n",
    "    \n",
    "    # Get the profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    \n",
    "    # Get the information of the reinforcements\n",
    "    global Radial_Reinforcement_Number\n",
    "    \n",
    "    # Get the angle size\n",
    "    global Nozzle_Angle_Revolution, Channel_Angle_Size\n",
    "    \n",
    "    \n",
    "    # We choose the datas according to the type of element\n",
    "    if Type == \"Nozzle\":\n",
    "        profile_inner = Nozzle_Profile_Inner\n",
    "        profile_outer = Nozzle_Profile_Outer\n",
    "        physical_group_prefix = \"Nozzle\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Cooling_Channel\":\n",
    "        profile_inner = Channel_Profile_Inner\n",
    "        profile_outer = Channel_Profile_Outer\n",
    "        physical_group_prefix = \"Cooling_Channel_\" + str(channel_number)\n",
    "        angle_revolution = Channel_Angle_Size\n",
    "    elif Type == \"Inner_Fluid\":\n",
    "        profile_inner = Center_Profile\n",
    "        profile_outer = Nozzle_Profile_Inner\n",
    "        physical_group_prefix = \"Inner_Fluid\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Outer_Fluid\":\n",
    "        profile_inner = Nozzle_Profile_Outer  # Reverse the outer profile for the inner volume\n",
    "        profile_outer = Exterior_Profile[::-1]\n",
    "        physical_group_prefix = \"Outer_Fluid\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Study_Volume\":\n",
    "        profile_inner = Center_Profile #  Nozzle_Profile_Inner[::-1]\n",
    "        profile_outer = Exterior_Profile[::-1]\n",
    "        physical_group_prefix = \"Study_Volume\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Custom\":\n",
    "        if custom_inner is None or custom_outer is None or custom_angle is None or custom_name is None:\n",
    "            print(\"Error: Custom profiles must be provided for 'Custom' type.\")\n",
    "            return False\n",
    "        profile_inner = custom_inner\n",
    "        profile_outer = custom_outer\n",
    "        physical_group_prefix = custom_name\n",
    "        angle_revolution = custom_angle\n",
    "    else:\n",
    "        print(\"Error: Invalid Type specified. Please choose from 'Nozzle', 'Cooling_Channel', 'Inner_Fluid', 'Outer_Fluid', 'Study_Volume', or 'Custom'.\")\n",
    "        print(\"By default, the Nozzle is used.\")\n",
    "        profile_inner = Nozzle_Profile_Inner\n",
    "        profile_outer = Nozzle_Profile_Outer\n",
    "        physical_group_prefix = \"Nozzle\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    \n",
    "    \n",
    "    #Get the start tag\n",
    "    if overwrite_start_tag is None:\n",
    "        global start_tag\n",
    "    else:\n",
    "        start_tag = overwrite_start_tag\n",
    "    \n",
    "    # If their is a reinforcement, we do not need to use gmsh to create the outer profile for a nozzle type\n",
    "    if Type in [\"Nozzle\", \"Outer_Fluid\"]and Radial_Reinforcement_Number > 0:\n",
    "        reinforcement_to_create = True\n",
    "    else:\n",
    "        reinforcement_to_create = False\n",
    "    \n",
    "    # We create the list of instructions to create the profiles\n",
    "    if Type == \"Outer_Fluid\":\n",
    "        instructions_inner = profile_gmsh_instruction(profile_inner, reinforcement=reinforcement_to_create, name=physical_group_prefix + \"_Inner_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "        instructions_outer = profile_gmsh_instruction(profile_outer, reinforcement=False, name=physical_group_prefix + \"_Outer_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "    else:\n",
    "        instructions_inner = profile_gmsh_instruction(profile_inner, reinforcement=False, name=physical_group_prefix + \"_Inner_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "        instructions_outer = profile_gmsh_instruction(profile_outer, reinforcement=reinforcement_to_create, name=physical_group_prefix + \"_Outer_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "    \n",
    "    # We follow the instructions to create the profiles\n",
    "    inner_entities_tags, inner_points_tags, inner_entities_names = create_from_instructions(instructions_inner, debug=debug)\n",
    "    outer_entities_tags, outer_points_tags, outer_entities_names = create_from_instructions(instructions_outer, debug=debug)\n",
    "    \n",
    "    # Get the tags of the first and last points of the inner and outer profiles\n",
    "    First_Inner_Tag = inner_points_tags[0]\n",
    "    Last_Inner_Tag = inner_points_tags[-1]\n",
    "    First_Outer_Tag = outer_points_tags[0]\n",
    "    Last_Outer_Tag = outer_points_tags[-1]\n",
    "\n",
    "    # Create the instructions to create the lines without forgetting that the inner profile is reversed\n",
    "    instructions_line_entry = [[\"line\", physical_group_prefix + \"_Entry_Wall\", profile_inner[-1], profile_outer[0], physical_group_prefix + \"_Entry_Wall\", False, Last_Inner_Tag, First_Outer_Tag]]\n",
    "    instructions_line_exit = [[\"line\", physical_group_prefix + \"_Exit_Wall\", profile_outer[-1], profile_inner[0], physical_group_prefix + \"_Exit_Wall\", False, Last_Outer_Tag, First_Inner_Tag]]\n",
    "    \n",
    "    # We follow the instructions to create the lines\n",
    "    line_entry_tags, line_entry_points_tags, line_entry_entities_names = create_from_instructions(instructions_line_entry, debug=debug)\n",
    "    line_exit_tags, line_exit_points_tags, line_exit_entities_names = create_from_instructions(instructions_line_exit, debug=debug)\n",
    "    \n",
    "    # Create the arrays of tags and names\n",
    "    inner_entities_tag_name = np.array([(inner_entities_tags[n], inner_entities_names[n]) for n in range(len(inner_entities_tags))])\n",
    "    outer_entities_tag_name = np.array([(outer_entities_tags[n], outer_entities_names[n]) for n in range(len(outer_entities_tags))])\n",
    "    line_entry_tag_name = np.array([(line_entry_tags[n], line_entry_entities_names[n]) for n in range(len(line_entry_tags))])\n",
    "    line_exit_tag_name = np.array([(line_exit_tags[n], line_exit_entities_names[n]) for n in range(len(line_exit_tags))])\n",
    "    \n",
    "    # Create a closed loop for the profile\n",
    "    profile_loop_tags_names = np.concatenate((outer_entities_tag_name, line_exit_tag_name, inner_entities_tag_name, line_entry_tag_name))\n",
    "    profile_loop_tags = [tag if isinstance(tag, int) else tag[0] if isinstance(tag, (tuple, list)) and isinstance(tag[0], int) else int(tag) for tag, name in profile_loop_tags_names]\n",
    "    profile_loop = create_curveloop(profile_loop_tags, name=physical_group_prefix + \"_Profile_Loop\", create_group=False)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Profile loop tags: {profile_loop_tags}\")\n",
    "        print(f\"Profile loop names: {profile_loop_tags_names}\")\n",
    "    \n",
    "    # Debug: Check the created loop\n",
    "    if not profile_loop is not None:\n",
    "        raise Exception(\"Failed to create the profile loop.\")\n",
    "    \n",
    "    # Create a surface loop from the profile loop\n",
    "    surface_loop = create_plane_surface([profile_loop], name=physical_group_prefix + \"_Initial_Wall\", create_group=False)\n",
    "    initial_tag_name = [(surface_loop, physical_group_prefix + \"_Initial_Wall\")]\n",
    "    revolved_tag_name = [(None, physical_group_prefix + \"_Revolved_Wall\")]\n",
    "    volume_tag_name = np.concatenate((initial_tag_name, revolved_tag_name, profile_loop_tags_names))\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Debug: Check the created surface loop and print the tag_name\n",
    "    if surface_loop is None:\n",
    "        raise Exception(\"Failed to create the surface loop.\")\n",
    "    \n",
    "    \n",
    "    # Revolve the profile to create the 3D nozzle geometry using OCC\n",
    "    axis_origin = [0, 0, 0]  # Origin of the axis of revolution\n",
    "    axis_direction = [1, 0, 0]\n",
    "    ax, ay, az = axis_direction\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Axis of revolution: {axis_direction}\")\n",
    "        print(f\"Angle of revolution: {angle_revolution}\")\n",
    "        \n",
    "    # Revolve inner and outer curves\n",
    "    revolved_volume = gmsh.model.occ.revolve([(2, surface_loop)], *axis_origin, ax, ay, az, angle_revolution)\n",
    "    gmsh.model.occ.synchronize()    \n",
    "    \n",
    "    # Debug: Check the created volume\n",
    "    if not revolved_volume:\n",
    "        raise Exception(\"Failed to create the profile volume.\")\n",
    "    profile_volume = np.concatenate((np.array([(2, surface_loop)]), np.array(revolved_volume)))\n",
    "\n",
    "    # Create the different physical groups for the different walls\n",
    "    counter = 0\n",
    "    for i in range(len(profile_volume)):\n",
    "        # Get the tag and name of the surfaces of the volume\n",
    "        dim, tag = profile_volume[i]\n",
    "\n",
    "        if dim == 3:\n",
    "            \n",
    "            # Create a physical group for the volume\n",
    "            create_physical_group(dim=dim, tags=[tag], name=physical_group_prefix + \"_Volume\", debug=debug)\n",
    "            # Correct the bible\n",
    "            correct_bible_gmsh_by_entity((dim, tag), name_overwrite=physical_group_prefix + \"_Volume\")\n",
    "        elif dim == 2:\n",
    "            tag_surface, name_surface = volume_tag_name[counter]\n",
    "            counter += 1\n",
    "            if angle_revolution >=2*np.pi and (\"_Revolved_Wall\" in name_surface or \"_Initial_Wall\" in name_surface):\n",
    "                delete_entity([(2,tag_surface)])\n",
    "            else:\n",
    "                # Create a physical group for the surface\n",
    "                create_physical_group(dim=dim, tags=[tag], name=name_surface, debug=debug)\n",
    "                # Correct the bible\n",
    "                #correct_bible_gmsh_by_entity((dim, tag), name_overwrite=name_surface)\n",
    "                add_to_bible(dimtag_entity=(dim, tag), entity_name=name_surface)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Physical groups created: {gmsh.model.getPhysicalGroups(2)}\")\n",
    "    \n",
    "    return profile_volume\n",
    "    \n",
    "if False:\n",
    "    #Get rid of a past gmsh instance\n",
    "    try:\n",
    "        gmsh.finalize()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Initialize GMSH\n",
    "    GMSH_initialise()\n",
    "    # Initialize the Bible\n",
    "    global Bible\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Set the debug mode\n",
    "    DEBUG = True\n",
    "    # Define the start tag\n",
    "    start_tag = 1\n",
    "    \n",
    "    # Generate the profiles\n",
    "    generate_profiles()\n",
    "    \n",
    "    # Generate the curved element\n",
    "    generate_minimal_curved_element(Type=\"Nozzle\", overwrite_start_tag=1, debug=DEBUG)\n",
    "    \n",
    "    # Bible\n",
    "    #correct_bible_gmsh(debug=DEBUG)\n",
    "    save_bible(debug=DEBUG)\n",
    "    # Save in a file\n",
    "    gmsh.model.mesh.generate(3)\n",
    "    gmsh.write(\"test_curved_element.msh\")    \n",
    "    \n",
    "    # Finalize GMSH\n",
    "    gmsh.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb404c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Cooling channels positions === ###\n",
    "\n",
    "def create_cooling_channel_positions(debug=False):\n",
    "    \"\"\"Create the positions of the cooling channels.\"\"\"\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Channel_Number\n",
    "    global Cooling_Channel_Angle_Offset\n",
    "    global Channel_Angle_Size\n",
    "    global Channel_Angle_Size_Mean\n",
    "    global Nozzle_Angle_Revolution\n",
    "\n",
    "    # Create all the possible positions and consider the offset due to the angle size\n",
    "    angle_between_channels = 2 * np.pi / Channel_Number\n",
    "    possible_positions = np.array([i * angle_between_channels + Channel_Angle_Size_Mean / 2 - Nozzle_Angle_Revolution / 2 for i in range(Channel_Number)])\n",
    "\n",
    "    # Offset the positions to center them\n",
    "    cooling_channel_offset = Channel_Angle_Size / 2\n",
    "    possible_positions = (possible_positions - cooling_channel_offset) % (2 * np.pi)\n",
    "\n",
    "    # Offset the positions as the user wants\n",
    "    angle_between_channels = 2 * np.pi / Channel_Number\n",
    "    user_offset = Cooling_Channel_Angle_Offset * angle_between_channels\n",
    "    channel_positions = (possible_positions + user_offset) % (2 * np.pi)\n",
    "    \n",
    "    # Debug: print the positions\n",
    "    if DEBUG:\n",
    "        print(f\"Cooling channel positions: {channel_positions}\")\n",
    "        print(f\"Angle size: {Channel_Angle_Size}\")\n",
    "        print(f\"User offset: {user_offset}\")\n",
    "    return channel_positions\n",
    "\n",
    "def test_channel_positions(channel_positions, debug=False):\n",
    "    # Get the paramters from the user\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Channel_Angle_Size\n",
    "    \n",
    "    # Create the possible interval\n",
    "    total_angle_size = Nozzle_Angle_Revolution + Channel_Angle_Size\n",
    "    start_interval = - total_angle_size / 2 % (2 * np.pi)\n",
    "    end_interval = total_angle_size / 2 % (2 * np.pi)\n",
    "    \n",
    "    # Create the interval for the nozzle\n",
    "    if start_interval > end_interval:\n",
    "        interval_nozzle = [[start_interval, 2 * np.pi], [0, end_interval]]\n",
    "    else:\n",
    "        interval_nozzle = [[start_interval, end_interval]]\n",
    "    \n",
    "    # Create the overlap intervals\n",
    "    overlap_initial_interval = [float(start_interval - 2*Channel_Angle_Size/2), float(start_interval + 2*Channel_Angle_Size/2)]\n",
    "    overlap_revolved_interval = [float(end_interval - 2*Channel_Angle_Size/2), float(end_interval + 2*Channel_Angle_Size/2)]\n",
    "\n",
    "    # Debug: print the interval\n",
    "    if debug:\n",
    "        print(f\"Interval for the cooling channels: {interval_nozzle}\")\n",
    "        print(f\"Overlap initial interval: {overlap_initial_interval}\")\n",
    "        print(f\"Overlap revolved interval: {overlap_revolved_interval}\")\n",
    "        print(f\"Positions of the cooling channels: {channel_positions}\")\n",
    "        \n",
    "    # Create the list of indicators\n",
    "    indicators = []\n",
    "    overlap_initial = None ; overlap_revolved = None\n",
    "    for i in range(len(channel_positions)):\n",
    "        position = channel_positions[i]\n",
    "        # Check if the position is in the interval\n",
    "        for interval in interval_nozzle:\n",
    "            if interval[0] <= position <= interval[1]:\n",
    "                boolean = True\n",
    "                break\n",
    "            else:\n",
    "                boolean = False\n",
    "        indicators.append(boolean)\n",
    "        \n",
    "    # Get the number of cooling channels possible\n",
    "    number_channels_possible = sum(indicators)\n",
    "    \n",
    "    # Check each possible solution for overlaps\n",
    "    counter = 1\n",
    "    for i, position in enumerate(channel_positions):\n",
    "        # If the position is not possible, continue\n",
    "        if not indicators[i]:\n",
    "            continue\n",
    "        # Check if the position is in the overlap intervals\n",
    "        if (position >= overlap_initial_interval[0] and position <= overlap_initial_interval[1]):\n",
    "            overlap_initial = counter\n",
    "        if (position >= overlap_revolved_interval[0] and position <= overlap_revolved_interval[1]):\n",
    "            overlap_revolved = counter\n",
    "        counter += 1\n",
    "    \n",
    "    return indicators, overlap_initial, overlap_revolved\n",
    "\n",
    "\n",
    "def overlap_manager(channel_tag, type_overlap, debug=False):\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "\n",
    "    #Create the name of the face to change\n",
    "    if type_overlap == \"Revolved\":\n",
    "        old_face_name = str(f\"Cooling_Channel_{channel_tag}_Revolved_Wall\")\n",
    "        new_face_name = str(f\"Nozzle_Revolved_Wall_Alt\")\n",
    "    elif type_overlap == \"Initial\":\n",
    "        old_face_name = str(f\"Cooling_Channel_{channel_tag}_Initial_Wall\")\n",
    "        new_face_name = str(f\"Nozzle_Initial_Wall_Alt\")\n",
    "    else:\n",
    "        raise ValueError(\"Type of overlap must be 'Revolved' or 'Initial'.\")\n",
    "    \n",
    "    #Find the index of the face in the Bible\n",
    "    index = Bible[Bible[\"entity_name\"] == old_face_name].index\n",
    "    if index.empty:\n",
    "        raise ValueError(f\"Face {old_face_name} not found in the Bible.\")\n",
    "    \n",
    "    #Change the name of the face in the Bible\n",
    "    Bible.at[index[0], \"entity_name\"] = new_face_name\n",
    "    Bible.at[index[0], \"group_name\"] = new_face_name\n",
    "     \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Create Cooling Channels === ###\n",
    "\n",
    "def create_exact_cooling_channel(channel_number=1, angle_position=None, debug=False):\n",
    "    \"\"\"\n",
    "    Create an exact 3D cooling channel using addThruSections.\n",
    "    Each section is made of 4 B-splines: outer, entry, inner, exit.\n",
    "    \"\"\"\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer, Channel_Width\n",
    "\n",
    "    prefix = f\"Cooling_Channel_{channel_number+1}\"\n",
    "\n",
    "    # Generate 3D profiles (z = +/- width/2)\n",
    "    def place_to_position(point, angle):\n",
    "        if angle is None:\n",
    "            return point\n",
    "        point_polar = cartesian_to_polar_x_axis(point, 0)\n",
    "        point_polar_placed = [point_polar[0], point_polar[1] + angle, point_polar[2]]\n",
    "        return polar_to_cartesian(point_polar_placed, 0)\n",
    "    \n",
    "    inner_profile_1 = []\n",
    "    inner_profile_2 = []\n",
    "    outer_profile_1 = []\n",
    "    outer_profile_2 = []\n",
    "    for i in range(len(Channel_Profile_Inner)):\n",
    "        x_inner = Channel_Profile_Inner[i][0]\n",
    "        x_outer = Channel_Profile_Outer[i][0]\n",
    "        y_inner = Channel_Profile_Inner[i][1]\n",
    "        y_outer = Channel_Profile_Outer[i][1]\n",
    "        width = Channel_Width[i][1] / 2\n",
    "        \n",
    "        # Calculate the inner and outer widths\n",
    "        mean_radius = (y_outer + y_inner) / 2\n",
    "        thales_factor_inner = y_inner / mean_radius - 1\n",
    "        thales_factor_outer = y_outer / mean_radius - 1\n",
    "        inner_width = width * (1 + thales_factor_inner)  #y_outer * thales_factor\n",
    "        outer_width = width * (1 + thales_factor_outer) #y_inner * thales_factor\n",
    "        \n",
    "        # Create the points for the profiles\n",
    "        inner_1_point = [x_inner, y_inner, -inner_width]\n",
    "        inner_2_point = [x_inner, y_inner, inner_width]\n",
    "        outer_1_point = [x_outer, y_outer, -outer_width]\n",
    "        outer_2_point = [x_outer, y_outer, outer_width]\n",
    "            \n",
    "        # Append points for the profiles\n",
    "        inner_profile_1.append(place_to_position(inner_1_point, angle_position))\n",
    "        inner_profile_2.append(place_to_position(inner_2_point, angle_position))\n",
    "        outer_profile_1.append(place_to_position(outer_1_point, angle_position))\n",
    "        outer_profile_2.append(place_to_position(outer_2_point, angle_position))\n",
    "\n",
    "    # Remove duplicates\n",
    "    def dedup(pts, tol=1e-8):\n",
    "        out = [pts[0]]\n",
    "        for p in pts[1:]:\n",
    "            if not np.allclose(p, out[-1], atol=tol):\n",
    "                out.append(p)\n",
    "        return out\n",
    "\n",
    "    inner_profile_1 = dedup(inner_profile_1)[::-1]  # Reverse inner profile for correct orientation\n",
    "    inner_profile_2 = dedup(inner_profile_2)[::-1]  # Reverse inner profile for correct orientation\n",
    "    outer_profile_1 = dedup(outer_profile_1)\n",
    "    outer_profile_2 = dedup(outer_profile_2)\n",
    "\n",
    "    # Helper to split a profile into 4 segments\n",
    "    def split_profile(outer, inner):\n",
    "        # Outer: 0..n-1, Entry: outer[n-1] to inner[n-1], Inner: n-1..0, Exit: inner[0] to outer[0]\n",
    "        outer_pts = outer\n",
    "        entry_pts = [outer[-1], inner[-1]]\n",
    "        inner_pts = inner[::-1]\n",
    "        exit_pts = [inner[0], outer[0]]\n",
    "        return outer_pts, entry_pts, inner_pts, exit_pts\n",
    "    s1_outer, s1_entry, s1_inner, s1_exit = split_profile(outer_profile_1, inner_profile_1)\n",
    "    s2_outer, s2_entry, s2_inner, s2_exit = split_profile(outer_profile_2, inner_profile_2)\n",
    "\n",
    "    # Create points and B-splines for each segment\n",
    "    def make_loop(outer, entry, inner, exit):\n",
    "        bs_outer = create_bspline(outer, name=f\"{prefix}_Outer_Wall\", create_group=False)\n",
    "        bs_entry = create_bspline(entry, name=f\"{prefix}_Entry_Wall\", create_group=False)\n",
    "        bs_inner = create_bspline(inner, name=f\"{prefix}_Inner_Wall\", create_group=False)\n",
    "        bs_exit = create_bspline(exit, name=f\"{prefix}_Exit_Wall\", create_group=False)\n",
    "        return [bs_outer[0], bs_entry[0], bs_inner[0], bs_exit[0]]\n",
    "\n",
    "    loop1_curves = make_loop(s1_outer, s1_entry, s1_inner, s1_exit)\n",
    "    loop2_curves = make_loop(s2_outer, s2_entry, s2_inner, s2_exit)\n",
    "    loop1 = gmsh.model.occ.addCurveLoop(loop1_curves)\n",
    "    loop2 = gmsh.model.occ.addCurveLoop(loop2_curves)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Debug: plot the section if needed\n",
    "    if debug:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for seg in [s1_outer, s1_entry, s1_inner, s1_exit]:\n",
    "            seg = np.array(seg)\n",
    "            ax.plot(seg[:,0], seg[:,1], seg[:,2])\n",
    "        for seg in [s2_outer, s2_entry, s2_inner, s2_exit]:\n",
    "            seg = np.array(seg)\n",
    "            ax.plot(seg[:,0], seg[:,1], seg[:,2])\n",
    "        plt.show()\n",
    "\n",
    "    #Create surfaces from the loops to ensure that the volume is created correctly\n",
    "    surface1 = gmsh.model.occ.addSurfaceFilling(loop1)  #create_plane_surface([loop1], name=f\"{prefix}_Initial_Wall\", create_group=False)\n",
    "    surface2 = gmsh.model.occ.addSurfaceFilling(loop2)  #create_plane_surface([loop2], name=f\"{prefix}_Revolved_Wall\", create_group=False)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    # Use addThruSections to generate the solid\n",
    "    volume = gmsh.model.occ.addThruSections([loop1, loop2], makeSolid=True)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create the group for the volume\n",
    "    create_physical_group(dim=3, tags=[volume[0][1]], name=f\"{prefix}_Volume\", debug=debug)\n",
    "    add_to_bible(dimtag_entity=(3, volume[0][1]), entity_name=f\"{prefix}_Volume\")\n",
    "    # Verify that the group is created\n",
    "    if not volume:\n",
    "        raise Exception(\"Failed to create the volume for the cooling channel.\")\n",
    "    if group_tags_via_group_name(f\"{prefix}_Volume\") is None:\n",
    "        raise Exception(f\"Failed to create the physical group for the cooling channel volume: {prefix}_Volume.\")\n",
    "    \n",
    "    # Create physical groups\n",
    "    volume_entities = get_child_entities(volume, minimal_dim=2, debug=debug)    \n",
    "    # Get the position of each entity of dim 2\n",
    "    entities_dimtag_position = [(dimtag, cartesian_to_polar_x_axis(entity_position(dimtag, use_gmsh=True), Angle=-angle_position)) for dimtag in volume_entities]\n",
    "    \n",
    "    # Now we manually chose the name for the groups\n",
    "    # THe entity with the lowest x is the entry wall, the one with the highest x is the exit wall\n",
    "    entities_dimtag_position = sorted(entities_dimtag_position, key=lambda x: x[1][0])\n",
    "    entry_dimtag = entities_dimtag_position[0][0]  # Entry wall\n",
    "    exit_dimtag = entities_dimtag_position[-1][0]  # Exit wall\n",
    "    # Delete the entry and exit from the list\n",
    "    entities_dimtag_position = [entry for entry in entities_dimtag_position if entry[0] not in (entry_dimtag, exit_dimtag)]\n",
    "    # The entity with the lowest theta is the initial wall, the one with the highest theta is the revolved wall\n",
    "    entities_dimtag_position = sorted(entities_dimtag_position, key=lambda x: x[1][1])\n",
    "    initial_dimtag = entities_dimtag_position[0][0]  # Initial wall\n",
    "    revolved_dimtag = entities_dimtag_position[-1][0]  # Revolved wall\n",
    "    # Delete the initial and revolved from the list\n",
    "    entities_dimtag_position = [entry for entry in entities_dimtag_position if entry[0] not in (initial_dimtag, revolved_dimtag)]\n",
    "    #The entity with the lowest r is the inner wall, the one with the highest r is the outer wall\n",
    "    entities_dimtag_position = sorted(entities_dimtag_position, key=lambda x: x[1][2])\n",
    "    outer_dimtag = entities_dimtag_position[0][0]  # Inner wall\n",
    "    inner_dimtag = entities_dimtag_position[-1][0]  # Outer wall\n",
    "    # Create the list of entities dimtag\n",
    "    volume_entities_dimtag = [\n",
    "        (entry_dimtag, f\"{prefix}_Entry_Wall\"),\n",
    "        (exit_dimtag, f\"{prefix}_Exit_Wall\"),\n",
    "        (outer_dimtag, f\"{prefix}_Outer_Wall\"),\n",
    "        (initial_dimtag, f\"{prefix}_Initial_Wall\"),\n",
    "        (inner_dimtag, f\"{prefix}_Inner_Wall\"),\n",
    "        (revolved_dimtag, f\"{prefix}_Revolved_Wall\")\n",
    "    ]\n",
    "\n",
    "    # Create the physical groups for each entity\n",
    "    for dimtag, name in volume_entities_dimtag:\n",
    "        create_physical_group(dim=dimtag[0], tags=[dimtag[1]], name=name, debug=debug)\n",
    "        #Actualize the Bible\n",
    "        add_to_bible(dimtag_entity=dimtag, entity_name=name)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Entities dimtag position: {entities_dimtag_position}\")    \n",
    "        \n",
    "    return volume\n",
    "\n",
    "def create_cooling_channels(debug=False, indicators_for_possible_channels = None):\n",
    "    \"\"\"Create the cooling channels.\"\"\"\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Channel_Number\n",
    "    global Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Create the positions of the cooling channels\n",
    "    channel_positions = create_cooling_channel_positions()\n",
    "    \n",
    "    # If we want to keep only the possible positions, we need to verify the positions\n",
    "    if indicators_for_possible_channels is None:\n",
    "        indicators = [True] * Channel_Number\n",
    "    else:\n",
    "        indicators = indicators_for_possible_channels\n",
    "    \n",
    "    # Get the current time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create the cooling channels\n",
    "    cooling_channels = []\n",
    "    channel_number = 0\n",
    "    for i in range(Channel_Number):\n",
    "        # Check if the position is possible\n",
    "        if not indicators[i]:\n",
    "            print(f\"Cooling channel {i} is not possible. Skipping.\")\n",
    "            continue     \n",
    "        \n",
    "        channel_position = channel_positions[i]\n",
    "        channel_tag = create_exact_cooling_channel(channel_number, channel_position, debug=debug)\n",
    "        channel_number += 1\n",
    "        # Check if the channel tag is valid\n",
    "        if channel_tag is None:\n",
    "            raise ValueError(f\"Failed to create cooling channel {i} with position {channel_position}.\")\n",
    "        # Add the channel tag to the list\n",
    "        for n in range(len(channel_tag)):\n",
    "            cooling_channels.append(channel_tag[n])\n",
    "        \n",
    "        print(f\"=== Cooling channel {i} out of {Channel_Number} created with tag: {channel_tag}===\")\n",
    "        # Debug: calculate remaining time\n",
    "        if debug:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            remaining_time = (elapsed_time / (i + 1)) * (Channel_Number - i - 1)\n",
    "            print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Estimated remaining time: {remaining_time:.2f} seconds\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    return cooling_channels\n",
    "   \n",
    "def add_cooling_channels(nozzle_tag, cooling_channels_tags, overlap_initial_id = None, overlap_revolved_id = None, debug=False):\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Extract the tag of the nozzle\n",
    "    nozzle_volume_tags = extract_dimtags_list(nozzle_tag, dim=3)\n",
    "    print(f\"Nozzle volume tags: {nozzle_volume_tags}\")\n",
    "        \n",
    "    # Extract from the cooling channels tags the volume tags\n",
    "    cooling_channels_tags = extract_dimtags_list(cooling_channels_tags, dim=3)\n",
    "    print(f\"Cooling channels tags: {cooling_channels_tags}\")\n",
    "    \n",
    "    # Verify that their is at least one tag\n",
    "    if not cooling_channels_tags:\n",
    "        print(\"No cooling channels tags found ! Adding cooling channels failed.\")\n",
    "        return None\n",
    "    \n",
    "    # Recover the dimtags of entry and exit of cooling channels\n",
    "    number_cooling_channels = len(extract_dimtags_list(cooling_channels_tags, dim=3))\n",
    "    ignore_tags = []\n",
    "    filtered = Bible[\n",
    "        Bible[\"entity_name\"].str.contains(\"Cooling\", na=False) &\n",
    "        Bible[\"entity_name\"].str.contains(\"Entry|Exit\", na=False)\n",
    "    ]\n",
    "    ignore_tags = filtered[\"dimtag_entity\"].tolist()\n",
    "    \n",
    "    # Manage the overlap\n",
    "    if overlap_initial_id is not None:\n",
    "        # Add the faces to the Bible\n",
    "        if not overlap_manager(overlap_initial_id,\"Initial\", debug=debug):\n",
    "            print(\"Failed to add the Initial Wall faces to the Bible. Cannot add cooling channels.\")\n",
    "            return None\n",
    "    \n",
    "    if overlap_revolved_id is not None:\n",
    "        # Add the faces to the Bible\n",
    "        if not overlap_manager(overlap_revolved_id,\"Revolved\", debug=debug):\n",
    "            print(\"Failed to add the Revolved Wall faces to the Bible. Cannot add cooling channels.\")\n",
    "            return None\n",
    "    \n",
    "    ignore_tags = extract_dimtags_list(ignore_tags)\n",
    "    # Debug: print the ignore tags\n",
    "    if debug:\n",
    "        print(f\"Ignore tags for the boolean operation: {ignore_tags}\")\n",
    "    # Do the boolean operation\n",
    "    nozzle_with_cooling_channels = gmsh_function_preserve_physical_groups(\"cut\", [[(3, 1)], cooling_channels_tags], ignore_dimtags=ignore_tags, debug=debug)\n",
    "\n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Verify the result\n",
    "    if nozzle_with_cooling_channels is not None:\n",
    "        print(f\"Cooling channels added to the nozzle with the resulting tag: {nozzle_with_cooling_channels}\")\n",
    "    else:\n",
    "        print(\"Failed to add cooling channels to the nozzle.\")\n",
    "    \n",
    "    return nozzle_with_cooling_channels\n",
    "   \n",
    "if False:\n",
    "    # We debug the creation of a cooling channel\n",
    "    try:\n",
    "        gmsh.finalize()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Initialize GMSH\n",
    "    GMSH_initialise(caracteristic_length_min= min_carac_length/10)\n",
    "    # Initialize the Bible\n",
    "    global Bible\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Initialize profiles\n",
    "    generate_profiles()\n",
    "    \n",
    "    # Initialize start_tag\n",
    "    global start_tag\n",
    "    start_tag = 1\n",
    "    \n",
    "    # Set the debug mode\n",
    "    debug = True\n",
    "    \n",
    "    #create_exact_cooling_channel(channel_number=1, angle_position=0, debug=debug)\n",
    "    create_cooling_channels(debug=False, indicators_for_possible_channels=None)\n",
    "    \n",
    "    # Save in a file\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    gmsh.model.occ.synchronize()   \n",
    "    gmsh.model.mesh.generate(3)\n",
    "    gmsh.write(\"test_exact_channel.msh\")\n",
    "    # Finalize GMSH\n",
    "    gmsh.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73d8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Creators of the different volumes === ###  \n",
    "\n",
    "def create_inner_volume_via_revolution(debug=False):\n",
    "    \"\"\"Create the inner volume of the Nozzle via the same method as the creation of the Nozzle.\"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Inner, Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Create the inner volume\n",
    "    inner_volume = generate_minimal_curved_element(Type=\"Inner_Fluid\", overwrite_start_tag=None, debug=debug)\n",
    "    \n",
    "    #Extract the volume tag\n",
    "    inner_volume = extract_dimtags_list(inner_volume, dim=3)\n",
    "    \n",
    "    # Verify the result\n",
    "    if inner_volume is None:\n",
    "        raise Exception(\"Failed to create the inner volume of the Nozzle.\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    return inner_volume\n",
    "\n",
    "def create_exterior_volume_via_revolution(debug=False):\n",
    "    \"\"\"Create the outer volume of the Nozzle via the same method as the creation of the Nozzle.\"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Outer, Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Create the outer volume\n",
    "    outer_volume = generate_minimal_curved_element(Type=\"Outer_Fluid\", overwrite_start_tag=None, debug=debug)\n",
    "    \n",
    "    #Extract the volume tag\n",
    "    outer_volume = extract_dimtags_list(outer_volume, dim=3)\n",
    "    \n",
    "    # Verify the result\n",
    "    if outer_volume is None:\n",
    "        raise Exception(\"Failed to create the outer volume of the Nozzle.\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    return outer_volume\n",
    "\n",
    "def create_cooling_channels_boolean_tool(debug=False):\n",
    "    \"\"\"Create the volume that will cut the cooling chanels to get their volume.\"\"\"\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the varaibles\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Cooling_Channel_Extension\n",
    "    global Exterior_Profile\n",
    "    global X_Parameters_Nozzle\n",
    "    \n",
    "    # Create the study volume\n",
    "    study_volume = generate_minimal_curved_element(Type=\"Study_Volume\", debug=debug)\n",
    "    if study_volume is None: # or tube is None:\n",
    "        raise Exception(\"Failed to create the cooling channels boolean tool or the study volume.\")\n",
    "    \n",
    "    # Extract the tags\n",
    "    study_volume_tag = extract_dimtags_list(study_volume, dim=3)\n",
    "    \n",
    "    #Rotate the study volume to align it with the cooling channels\n",
    "    study_volume_rotated = gmsh_function_preserve_physical_groups(\"rotate\",[study_volume_tag, 0, 0, 0, 1, 0, 0, - Nozzle_Angle_Revolution / 2], debug=debug)\n",
    "    \n",
    "    return study_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1927df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Mesh generator === ###\n",
    "\n",
    "def create_solid_mesh(debug=False):\n",
    "    # Get the variables\n",
    "    global Bible\n",
    "    global start_tag\n",
    "    global Channel_Number\n",
    "    global Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Generate the nozzle\n",
    "    print(\"=== GENERATING NOZZLE ===\")\n",
    "    nozzle_tag = generate_minimal_curved_element(Type=\"Nozzle\", debug=debug)\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Rotate the nozzle\n",
    "    print(\"=== ROTATING NOZZLE ===\")\n",
    "    nozzle_tag = extract_dimtags_list(nozzle_tag, dim=3)\n",
    "    nozzle_tag = gmsh_function_preserve_physical_groups(\"rotate\",[nozzle_tag, 0, 0, 0, 1, 0, 0, - Nozzle_Angle_Revolution / 2], debug=debug)\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Create the cooling channels\n",
    "    if Channel_Number > 0:\n",
    "        print(\"=== CALCULATING COOLING CHANNELS POSITIONS ===\")\n",
    "        indicators, overlap_initial_id, overlap_revolved_id = test_channel_positions(create_cooling_channel_positions(), debug=debug)\n",
    "\n",
    "        channels_to_create = sum(indicators)\n",
    "        \n",
    "        if sum(indicators) == 0:\n",
    "            print(\"=== NO COOLING CHANNELS TO CREATE ===\")\n",
    "            return nozzle_tag\n",
    "        else:\n",
    "            print(\"=== CREATING COOLING CHANNELS ===\")\n",
    "            cooling_channels_tags = create_cooling_channels(debug=debug, indicators_for_possible_channels=indicators)\n",
    "            \n",
    "            # Add the cooling channels to the nozzle\n",
    "            print(\"=== ADDING COOLING CHANNELS TO NOZZLE ===\")\n",
    "            nozzle_with_cooling_channels = add_cooling_channels(nozzle_tag, cooling_channels_tags, overlap_initial_id=overlap_initial_id, overlap_revolved_id=overlap_revolved_id, debug=debug)\n",
    "    else:\n",
    "        print(\"=== NO COOLING CHANNELS TO ADD ===\")\n",
    "        return nozzle_tag\n",
    "    \n",
    "    # Verify the result\n",
    "    if nozzle_with_cooling_channels is None:\n",
    "        raise Exception(\"Failed to create the solid mesh of the Nozzle.\")\n",
    "    return nozzle_with_cooling_channels\n",
    "\n",
    "def create_inner_fluid_mesh(debug=False):\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create the inner volume\n",
    "    print(\"=== CREATING INNER VOLUME ===\")\n",
    "    inner_volume = create_inner_volume_via_revolution(debug=debug)\n",
    "    \n",
    "    # Verify the result\n",
    "    if inner_volume is None:\n",
    "        raise Exception(\"Failed to create the inner volume of the Nozzle.\")\n",
    "    return inner_volume\n",
    "\n",
    "def create_outer_fluid_mesh(debug=False):\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create the outer volume\n",
    "    print(\"=== CREATING OUTER VOLUME ===\")\n",
    "    outer_volume = create_exterior_volume_via_revolution(debug=debug)\n",
    "    \n",
    "    # Verify the result\n",
    "    if outer_volume is None:\n",
    "        raise Exception(\"Failed to create the outer volume of the Nozzle.\")\n",
    "    return outer_volume\n",
    "\n",
    "def create_cooling_channels_mesh(debug=False):\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    print(\"=== CALCULATING COOLING CHANNELS POSITIONS ===\")\n",
    "    indicators, overlap_initial_id, overlap_revolved_id = test_channel_positions(create_cooling_channel_positions(), debug=debug)\n",
    "    \n",
    "    print(\"=== CREATING COOLING CHANNELS BOOLEAN TOOL ===\")\n",
    "    cooling_channels_boolean_tool = create_cooling_channels_boolean_tool(debug=debug)\n",
    "    boolean_tool_dimtags = extract_dimtags_list(cooling_channels_boolean_tool, dim=3)\n",
    "    \n",
    "    print(\"=== CREATING COOLING CHANNELS ===\")\n",
    "    cooling_channels_tags = create_cooling_channels(debug=debug, indicators_for_possible_channels=indicators)\n",
    "    if cooling_channels_tags is None:\n",
    "        raise Exception(\"Failed to create the cooling channels.\")\n",
    "    cooling_channels_dimtags = extract_dimtags_list(cooling_channels_tags, dim=3)\n",
    "\n",
    "    # Correct the bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Intersect the cooling channels with the tool\n",
    "    print(\"=== INTERSECTING COOLING CHANNELS WITH TOOL ===\")\n",
    "    cooling_channels_tags = gmsh_function_preserve_physical_groups(\"intersect\", [boolean_tool_dimtags, cooling_channels_dimtags], debug=debug)\n",
    "    if cooling_channels_tags is None:\n",
    "        raise Exception(\"Failed to cut the cooling channels from the tool.\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "def mesh_generator(mesh_to_generate, path_for_save=None, debug=False):\n",
    "    \"\"\"Generate the mesh for the rocket engine.\"\"\"\n",
    "    \n",
    "    # Choose the generator\n",
    "    if mesh_to_generate == \"Solid\":\n",
    "        generator_used = create_solid_mesh\n",
    "    elif mesh_to_generate == \"Inner_Fluid\":\n",
    "        generator_used = create_inner_fluid_mesh\n",
    "    elif mesh_to_generate == \"Outer_Fluid\":\n",
    "        generator_used = create_outer_fluid_mesh\n",
    "    elif mesh_to_generate == \"Cooling_Channels\":\n",
    "        generator_used = create_cooling_channels_mesh\n",
    "    else:\n",
    "        raise ValueError(\"Mesh generator not recognized. Use 'Solid', 'Inner_Fluid', 'Outer_Fluid' or 'Cooling_Channels'.\")\n",
    "    \n",
    "    print(f\"%%%%%%% ========= CREATING MESH {mesh_to_generate} ========== %%%%%%%\")\n",
    "    \n",
    "    # Get the variables\n",
    "    global Bible\n",
    "    global start_tag\n",
    "    global Channel_Number\n",
    "    global start_tag\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Cooling_Channel_Angle_Offset\n",
    "    global Radial_Reinforcement_Number\n",
    "    global Radial_Reinforcement_Density\n",
    "    global DEBUG\n",
    "    global MULTITHREADING\n",
    "    \n",
    "    # Overwrite and define some parameters\n",
    "    DEBUG = debug\n",
    "    start_tag = 1\n",
    "    \n",
    "    if MULTITHREADING is not None:\n",
    "        thread_number = MULTITHREADING\n",
    "    else:\n",
    "        thread_number = 1\n",
    "        \n",
    "    try:\n",
    "        if Channel_Number is not None:\n",
    "            channel_number_temp = Channel_Number # It needs to be saved because the profile generator will overwrite it\n",
    "        else:\n",
    "            channel_number_temp = None\n",
    "    except NameError:\n",
    "        channel_number_temp = None\n",
    "    \n",
    "    #Get rid of a past gmsh instance\n",
    "    try:\n",
    "        gmsh.finalize()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Initialize GMSH\n",
    "    print(\"=== INITIALIZING GMSH ===\")\n",
    "    GMSH_initialise(caracteristic_length_min=min_carac_length/5, thread_number=thread_number)\n",
    "    \n",
    "    # Initialize the Bible\n",
    "    print(\"=== INITIALIZING BIBLE ===\")\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Generate the profiles\n",
    "    print(\"=== GENERATING PROFILES ===\")\n",
    "    generate_profiles(debug=debug)\n",
    "    if channel_number_temp is not None:\n",
    "        Channel_Number = channel_number_temp  # Restore the channel number\n",
    "    \n",
    "    # Use the generator to create the mesh\n",
    "    result = generator_used(debug=debug)\n",
    "        \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "\n",
    "    # Save in a file\n",
    "    print(\"=== SAVING MESH ===\")\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    gmsh.model.occ.synchronize()    \n",
    "    gmsh.model.occ.synchronize()\n",
    "    gmsh.model.mesh.generate(DIM_MESH)\n",
    "    complete_path = path_for_save + f\"{mesh_to_generate}_mesh\" if path_for_save else f\"{mesh_to_generate}_mesh.msh\"\n",
    "    if output_in_msh:\n",
    "        gmsh.write(complete_path+ \".msh\")\n",
    "        print(f\"Mesh saved in {complete_path}.msh\")\n",
    "    if output_in_stl:\n",
    "        gmsh.write(complete_path + \".stl\")\n",
    "        print(f\"Mesh saved in {complete_path}.stl\")\n",
    "    if other_type_output is not None:\n",
    "        gmsh.write(complete_path + f\"{other_type_output}\")\n",
    "        print(f\"Mesh saved in {complete_path}{other_type_output}\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Finalize GMSH\n",
    "    gmsh.finalize()\n",
    "    print(\"=== MESH DONE ===\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Main function === ###\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Get the parameters from the user\n",
    "    global Channel_Number\n",
    "    global start_tag\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Cooling_Channel_Angle_Offset\n",
    "    global Radial_Reinforcement_Number\n",
    "    global Radial_Reinforcement_Density\n",
    "    global DEBUG\n",
    "    global output_folder\n",
    "    \n",
    "    # Overwrite data for debug \n",
    "    Cooling_Channel_Angle_Offset = 0.0\n",
    "    Nozzle_Angle_Revolution = 2*np.pi /20\n",
    "    #Channel_Number = 0\n",
    "    Radial_Reinforcement_Number = 0\n",
    "    Radial_Reinforcement_Density = lambda x:  1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    # Generate all the meshes in a local folder in the current directory \n",
    "    mesh_folder = output_folder\n",
    "    if not os.path.exists(mesh_folder):\n",
    "        os.makedirs(mesh_folder)\n",
    "    \n",
    "    # Generate the meshes\n",
    "    mesh_generator(\"Solid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"Inner_Fluid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"Outer_Fluid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"Cooling_Channels\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    print(\"All meshes generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
