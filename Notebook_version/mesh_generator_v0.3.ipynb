{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a37f25d",
   "metadata": {},
   "source": [
    "# Rocket Engine Nozzle Mesh Generator (Beginner-Friendly Guide)\n",
    "\n",
    "This Jupyter Notebook helps you **generate 2D and 3D mesh geometries** for rocket engine nozzles, focusing on real datas (not included), but also allowing for custom designs. It uses the [GMSH](https://gmsh.info/) Python API for geometry creation and meshing, and supports advanced features like cooling channels and reinforcement ribs.\n",
    "\n",
    "---\n",
    "\n",
    "## What Does This Notebook Do?\n",
    "\n",
    "- **Loads real or custom nozzle geometry data** (from CSV or parameters)\n",
    "- **Builds the nozzle shape** using mathematical curves or real data\n",
    "- **Adds cooling channels and reinforcements** to the nozzle wall\n",
    "- **Creates 3D geometry** by revolving 2D profiles around the nozzle axis\n",
    "- **Generates a mesh** suitable for simulation (CFD, FEA, etc.)\n",
    "- **Exports the mesh** to standard formats (`.msh`, `.stl`) for use in other tools\n",
    "\n",
    "---\n",
    "\n",
    "## Main Features\n",
    "\n",
    "- **Real Data Integration:** Use real rocket engine data for accurate geometry.\n",
    "- **Custom Geometry:** Easily switch to your own nozzle parameters.\n",
    "- **Profile Generation:** Supports BÃ©zier and de Laval curves for smooth shapes.\n",
    "- **Cooling Channels:** Automatically create and subtract cooling circuits from the nozzle wall.\n",
    "- **Radial Reinforcements:** Add reinforcement ribs at specified positions.\n",
    "- **Physical Group Management:** Keeps track of different parts of the geometry for easy simulation setup.\n",
    "- **Visualization:** Plots profiles and geometry for easy verification.\n",
    "\n",
    "---\n",
    "\n",
    "## How to Use This Notebook\n",
    "\n",
    "### 1. **Dependencies**\n",
    "\n",
    "The notebook uses these Python packages:\n",
    "- `gmsh`\n",
    "- `numpy`\n",
    "- `matplotlib`\n",
    "- `scipy`\n",
    "- `pandas`\n",
    "- `math`\n",
    "\n",
    "If any are missing, the notebook will try to install them automatically.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Workflow Overview**\n",
    "\n",
    "1. **Imports & Checks:**  \n",
    "   Ensures all required packages are available.\n",
    "\n",
    "2. **Load Geometry Data:**  \n",
    "   - Use real Vulcain 2.1 data (from CSV) or\n",
    "   - Define your own nozzle parameters.\n",
    "\n",
    "3. **Set Parameters:**  \n",
    "   - Wall thickness, number of cooling channels, mesh resolution, etc.\n",
    "\n",
    "4. **Initialize GMSH:**  \n",
    "   - Set mesh size and options.\n",
    "\n",
    "5. **Geometry Creation:**  \n",
    "   - Build 2D profiles for the nozzle and channels.\n",
    "   - Revolve profiles to create 3D geometry.\n",
    "\n",
    "6. **Add Features:**  \n",
    "   - Add cooling channels and reinforcements.\n",
    "\n",
    "7. **Mesh Generation:**  \n",
    "   - Generate and export the mesh.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Basic Example**\n",
    "\n",
    "To generate a nozzle with a cooling circuit, run:\n",
    "\n",
    "```python\n",
    "mesh_generator(\"Solid\", path_for_save=\"Rocket_Engine_Meshes/\", debug=True)\n",
    "```\n",
    "\n",
    "You can also generate just the inner fluid, outer fluid, or only the cooling channels by changing the argument to `\"Inner_Fluid\"`, `\"Outer_Fluid\"`, or `\"Cooling_Channels\"`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Visualization**\n",
    "\n",
    "- The notebook plots the nozzle and channel profiles so you can check the geometry before meshing.\n",
    "- You can open the generated `.msh` or `.stl` files in the GMSH GUI for 3D inspection.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Customization Tips**\n",
    "\n",
    "- **Change Geometry:**  \n",
    "  Edit the parameters or CSV files to use your own nozzle shape.\n",
    "- **Adjust Mesh Quality:**  \n",
    "  Change mesh size parameters for finer or coarser meshes.\n",
    "- **Add/Remove Features:**  \n",
    "  Set the number of cooling channels or reinforcements as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "- **No Elements in Volume Error:**  \n",
    "  This means the geometry is not closed or valid. Check your parameters and input data.\n",
    "- **Mesh Not Exported:**  \n",
    "  Make sure all geometry steps complete without errors before meshing.\n",
    "\n",
    "---\n",
    "\n",
    "**Tip:**  \n",
    "If you are new to GMSH or mesh generation, start by running the notebook as-is, then gradually change parameters and observe the effects on the geometry and mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7a58d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import gmsh\n",
    "except ImportError:\n",
    "    print(\"gmsh is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install gmsh\")\n",
    "    import gmsh\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ImportError:\n",
    "    print(\"matplotlib is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install matplotlib\")\n",
    "    import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    print(\"numpy is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install numpy\")\n",
    "    import numpy as np\n",
    "    \n",
    "try: \n",
    "    import scipy\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "except ImportError:\n",
    "    print(\"scipy is not installed. Trying to install it...\")\n",
    "    os.system(\"pip install scipy\")\n",
    "    import scipy\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    print(\"pandas is not installed. Trying to install it...\")\n",
    "    %pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "try:\n",
    "    import math\n",
    "except ImportError:\n",
    "    print(\"math is not installed. Trying to install it...\")\n",
    "    %pip install math\n",
    "    import math\n",
    "    \n",
    "try:\n",
    "    import scipy.interpolate\n",
    "except ImportError:\n",
    "    print(\"scipy.interpolate is not installed. Trying to install it...\")\n",
    "    %pip install scipy\n",
    "    import scipy.interpolate\n",
    "\n",
    "try: \n",
    "    import threading\n",
    "except ImportError:\n",
    "    print(\"threading is not installed. Trying to install it...\")\n",
    "    %pip install threading\n",
    "    import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "766aed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === CSV data extractor === ###\n",
    "\n",
    "def csv_extractor(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls):\n",
    "    \"\"\"\n",
    "    This function extracts the geometry from a CSV file and returns the values as a dataframe.\n",
    "    input: \n",
    "    file_name: names of the CSV files\n",
    "    columns_names: list of column names to extract\n",
    "    output: values: dataframes containing the values from the CSV file \n",
    "    \"\"\"\n",
    "    # Read the CSV file with specified column names\n",
    "    # The first row is the header, so we need to skip it\n",
    "    df_interior = pd.read_csv(file_name_interior, names=columns_names_interior, header=0)\n",
    "    df_walls = pd.read_csv(file_name_walls, names=columns_names_walls, header=0)\n",
    "    \n",
    "    return df_interior, df_walls\n",
    "\n",
    "def width_by_method(x, method, function, derivative, debug = False):\n",
    "    if method == \"ortho\":\n",
    "        return function(x)\n",
    "    if method == \"angle\":\n",
    "        # Calculate the angle using the derivative\n",
    "        angle = math.atan(derivative(x))\n",
    "        # Calculate the width using the angle\n",
    "        y_factor = math.cos(angle)\n",
    "        initial_width = function(x) * y_factor\n",
    "        x_factor = math.sin(angle)\n",
    "        x_used = x + x_factor* initial_width\n",
    "        width = function(x_used) * y_factor\n",
    "        if debug:\n",
    "            return width, x_factor * initial_width\n",
    "        return width\n",
    "\n",
    "def geometry_creator(dataframe_interior, dataframe_wall, method, debug = False):\n",
    "    \"\"\"\n",
    "    This function creates the geometry from the dataframe and returns the values as a list.\n",
    "    input: \n",
    "    dataframe: dataframe containing the values from the CSV file\n",
    "    method: method for the extraction of the geometry for the angle : \"ortho\" or \"angle\"\n",
    "    output: values: list containing the values from the CSV file \n",
    "    \"\"\"\n",
    "    # Extract the values from the dataframe\n",
    "    x_interior = dataframe_interior[\"x\"].values\n",
    "    y_interior = dataframe_interior[\"y\"].values\n",
    "    x_walls = dataframe_wall[\"x\"].values\n",
    "    channel_height = dataframe_wall[\"channel height\"].values\n",
    "    channel_width = dataframe_wall[\"channel width\"].values\n",
    "    hot_gas_wall = dataframe_wall[\"hot gas wall\"].values\n",
    "    outer_thickness = dataframe_wall[\"outer thickness\"].values\n",
    "    number_channels = dataframe_wall[\"number channels\"].values\n",
    "\n",
    "    # Interpolate functions for the different values\n",
    "    interior_func = scipy.interpolate.interp1d(x_interior, y_interior, kind='linear', fill_value=\"extrapolate\")\n",
    "    channel_height_func = scipy.interpolate.interp1d(x_walls, channel_height, kind='linear', fill_value=\"extrapolate\")\n",
    "    channel_width_func = scipy.interpolate.interp1d(x_walls, channel_width, kind='linear', fill_value=\"extrapolate\")\n",
    "    hot_gas_wall_func = scipy.interpolate.interp1d(x_walls, hot_gas_wall, kind='linear', fill_value=\"extrapolate\")\n",
    "    outer_thickness_func = scipy.interpolate.interp1d(x_walls, outer_thickness, kind='linear', fill_value=\"extrapolate\")\n",
    "    number_channels_func = scipy.interpolate.interp1d(x_walls, number_channels, kind='linear', fill_value=\"extrapolate\")\n",
    "        \n",
    "    # Calculate the derivatives of the functions to get their angles\n",
    "    interior_derivative = np.gradient(interior_func(x_interior), x_interior)\n",
    "    channel_height_derivative = np.gradient(channel_height_func(x_walls), x_walls)\n",
    "    hot_gas_wall_derivative = np.gradient(hot_gas_wall_func(x_walls), x_walls)\n",
    "    outer_thickness_derivative = np.gradient(outer_thickness_func(x_walls), x_walls)\n",
    "\n",
    "    # Interpolate the derivatives to get the values at the same points as the functions\n",
    "    interior_derivative = scipy.interpolate.interp1d(x_interior, interior_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "    channel_height_derivative = scipy.interpolate.interp1d(x_walls, channel_height_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "    hot_gas_wall_derivative = scipy.interpolate.interp1d(x_walls, hot_gas_wall_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "    outer_thickness_derivative = scipy.interpolate.interp1d(x_walls, outer_thickness_derivative, kind='linear', fill_value=\"extrapolate\")\n",
    "        \n",
    "    # Create a new dataframe with the new values\n",
    "    new_dataframe = pd.DataFrame(columns=[\"x\", \"nozzle inner wall\", \"nozzle outer wall\", \"channel inner wall\", \"channel outer wall\", \"channel width\", \"number channels\"])\n",
    "    for i,x in enumerate(x_interior):\n",
    "        # We push x\n",
    "        new_dataframe.loc[i, \"x\"] = x\n",
    "        # First layer : the interior wall which is the first so the derivative is 0. We will jsut use the ortho method\n",
    "        current_width = width_by_method(x, \"ortho\", interior_func, lambda x: 0)\n",
    "        new_dataframe.loc[i, \"nozzle inner wall\"] = current_width\n",
    "        # Second layer : the inner wall of the channel\n",
    "        current_width = current_width +  width_by_method(x, method, hot_gas_wall_func, interior_derivative)\n",
    "        new_dataframe.loc[i, \"channel inner wall\"] = current_width\n",
    "        # Third layer : the outer wall of the channel\n",
    "        current_width = current_width + width_by_method(x, method, channel_height_func, hot_gas_wall_derivative)\n",
    "        new_dataframe.loc[i, \"channel outer wall\"] = current_width\n",
    "        # Fourth layer : the outer wall of the channel\n",
    "        current_width = current_width + width_by_method(x, method, outer_thickness_func, channel_height_derivative)\n",
    "        new_dataframe.loc[i, \"nozzle outer wall\"] = current_width\n",
    "        \n",
    "        # Other values\n",
    "        new_dataframe.loc[i, \"channel width\"] = channel_width_func(x)\n",
    "        new_dataframe.loc[i, \"number channels\"] = int(number_channels_func(x))\n",
    "    \n",
    "    # Debug: plot the new values\n",
    "    if debug:\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"nozzle inner wall\"], label=\"nozzle inner wall\")\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"nozzle outer wall\"], label=\"nozzle outer wall\")\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"channel inner wall\"], label=\"channel inner wall\")\n",
    "        plt.plot(new_dataframe[\"x\"], new_dataframe[\"channel outer wall\"], label=\"channel outer wall\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"values\")\n",
    "        plt.title(\"New geometry values\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(new_dataframe)\n",
    "    \n",
    "    return new_dataframe\n",
    "\n",
    "def geometry_dataframe(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls, method, debug = False, minimum_caracteristic_length = False):\n",
    "    \"\"\"\n",
    "    This function creates the geometry from the dataframe and returns the values as a list.\n",
    "    input: \n",
    "    file_name: names of the CSV files\n",
    "    columns_names: list of column names to extract\n",
    "    method: method for the extraction of the geometry for the angle : \"ortho\" or \"angle\"\n",
    "    output: values: list containing the values from the CSV file \n",
    "    \"\"\"\n",
    "    # Extract the geometry from the CSV file\n",
    "    values = csv_extractor(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls)\n",
    "    # Create the geometry\n",
    "    geometry = geometry_creator(values[0], values[1], method)\n",
    "    # Get the minimum caracteristic length\n",
    "    if minimum_caracteristic_length:\n",
    "        min_carac_length = min(min(values[1][\"channel width\"]), \n",
    "                               min(values[1][\"channel height\"]), \n",
    "                               min(values[1][\"outer thickness\"]), \n",
    "                               min(values[1][\"hot gas wall\"]))\n",
    "        return geometry, min_carac_length\n",
    "    return geometry\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "26c61f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### === Parameters for the rocket engine geometry === ###\n",
    "\n",
    "DEBUG = False\n",
    "proximity_tol = 0.0001\n",
    "MULTITHREADING = 10\n",
    "DIM_MESH = 3 # Dimension of mesh generation (2 will give you a 3D mesh but possibly with false positive)\n",
    "\n",
    "# Parameters for extracting the data from the CSV files\n",
    "current_directory = os.getcwd()\n",
    "file_name_interior = \"nozzle_curve.csv\"   #\"hgw_input_placeholder.csv\"\n",
    "file_name_walls = \"nozzle_layers.csv\" #\"geometry_input_placeholder_alt.csv\"\n",
    "columns_names_interior = [\"x\",\"y\"]\n",
    "columns_names_walls = [\"x\",\"channel height\",\"channel width\",\"hot gas wall\",\"outer thickness\",\"number channels\"]\n",
    "extracting_method=\"angle\" # Method for the extraction of the geometry for the angle : \"ortho\" or \"angle\"\n",
    "Multiplicator_X_CSV = 1.0\n",
    "\n",
    "# Extract the geometry from the CSV file\n",
    "geometry_data, min_carac_length = geometry_dataframe(file_name_interior, file_name_walls, columns_names_interior, columns_names_walls, extracting_method, debug = False, minimum_caracteristic_length = True) \n",
    "\n",
    "# Multiply the length by N\n",
    "geometry_data[\"x\"] = geometry_data[\"x\"] * Multiplicator_X_CSV\n",
    "\n",
    "# We create a basic geometry with only X and Y in case of a need of simplicity\n",
    "X_CSV = geometry_data[\"x\"].values\n",
    "Y_CSV = geometry_data[\"nozzle inner wall\"].values\n",
    "\n",
    "# Adapt X_Parameters and D_Parameters\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(X_CSV, Y_CSV, 'r-', label='CSV Basic Profile')\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "plt.axis('equal')\n",
    "plt.title('Basic geometry')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Parameters direclty from the CSV data\n",
    "X_Start = X_CSV[0]  # Starting point of the nozzle\n",
    "X_Exit = X_CSV[-1]  # Exit point\n",
    "length = X_CSV[-1] - X_CSV[0]  # Length of the engine\n",
    "chamber_length = X_CSV[np.where(Y_CSV == Y_CSV.min())[0][0]] - X_CSV[0]\n",
    "nozzle_length = length - chamber_length\n",
    "X_Throat = X_Start + chamber_length  # Adjust the throat position based on the chamber length\n",
    "D_Start = Y_CSV[0] * 2 # Diameter at the start of the nozzle\n",
    "D_Throat = Y_CSV.min() * 2  # Diameter at the throat\n",
    "D_Exit = Y_CSV[-1] * 2 # Diameter at the exit\n",
    "\n",
    "# Define the nozzle parameters\n",
    "X_Parameters_Nozzle = [X_Start, X_Throat, X_Exit]  # X coordinates of the nozzle\n",
    "D_Parameters_Nozzle = [D_Start, D_Throat, D_Exit]  # Diameter parameters of the nozzle\n",
    "Nozzle_Angle_Revolution = np.pi / 4  # Angle of revolution for the nozzle\n",
    "Nozzle_Modificator_Inner = lambda x: 0.\n",
    "Nozzle_Modificator_Outer = lambda x: 0.\n",
    "\n",
    "# Define the cooling circuit parameters\n",
    "X_Cooling_Start = X_Start  # Starting point of the cooling circuit\n",
    "X_Cooling_Throat = X_Throat  # Throat position of the cooling circuit\n",
    "X_Cooling_Exit = X_Exit  # Exit position of the cooling circuit\n",
    "X_Cooling_Parameters = [X_Cooling_Start, X_Cooling_Throat, X_Cooling_Exit]  # X coordinates of the cooling circuit\n",
    "Cooling_Channel_Angle_Size = - np.pi / 16  # Deprecated: The width is defned by the CSV file\n",
    "Cooling_Channel_Extension = chamber_length * 0.1  # Extension of the cooling channel\n",
    "Cooling_Channel_Modificator_Inner = lambda x: 0.\n",
    "Cooling_Channel_Modificator_Outer = lambda x: 0.\n",
    "Cooling_Channel_Angle_Offset = 0.0 # Angle offset of the cooling channel as a multiplier between two channels. By default at 0.0 the first channel intersect with the side. ATTENTION, it could lead to topological problems if not used properly.\n",
    "\n",
    "# Define the reinforcement parameters\n",
    "Radial_Reinforcement_Width = 0.003  # Width of the radial reinforcement\n",
    "Radial_Reinforcement_Height = 0.01  # Height of the radial reinforcement\n",
    "Radial_Reinforcement_Number = 20 # Number of radial reinforcements\n",
    "Radial_Reinforcement_Density = lambda x: x * 0  # Density of the radial reinforcement (x*0 to get a uniform distribution) It needs to return a numpy array !!\n",
    "Radial_Reinforcement_Margin_Entry = 0.01  # Margin of the radial reinforcement at the entry\n",
    "Radial_Reinforcement_Margin_Exit = 0.01  # Margin of the radial reinforcement at the exit\n",
    "\n",
    "# Profile treatment Parameters\n",
    "number_of_points_profile = 150  # Number of points for the nozzle profile\n",
    "ratio_for_accel_points = 0.5  # Ratio of points selected for the acceleration in a reduction of points. The rest is uniformly distributed\n",
    "reduce_points_method = 'density' # Method to reduce points: 'density' or 'accel' \n",
    "\n",
    "# Output parameters\n",
    "Radius_Study_Margin = 0.1 # Added space for the exterior radius\n",
    "\n",
    "# Initialize some variables\n",
    "Angle_Revolution = Nozzle_Angle_Revolution\n",
    "start_tag = 1\n",
    "\n",
    "# Output files parameters\n",
    "output_folder = os.path.join(current_directory, \"Rocket_Engine_Meshes/\")\n",
    "output_in_stl = False\n",
    "output_in_msh = True\n",
    "other_type_output = None # Specify a .[type] to output the geometry in this format. If None, no other output is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ba2ae13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Parameters for GMSH === ###\n",
    "def GMSH_initialise(caracteristic_length_min=0.0001, caracteristic_length_max=None, thread_number = 1):\n",
    "    \"\"\"\n",
    "    Initialize GMSH with specific options.\n",
    "    \"\"\"\n",
    "    # Check if caracteristic_length_max is None. If it is, set it to 100 times caracteristic_length_min\n",
    "    if caracteristic_length_max is None:\n",
    "        caracteristic_length_max = 1000*caracteristic_length_min\n",
    "        \n",
    "    # Initialize GMSH\n",
    "    gmsh.initialize()\n",
    "    \n",
    "    gmsh.option.setNumber(\"General.Verbosity\", 5)  # 2=Warning, 3=Info, 4=Debug, 5=Trace\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthMax\", caracteristic_length_max)  # maille max de 0.05\n",
    "    gmsh.option.setNumber(\"Mesh.MeshSizeFromCurvature\", 1)  # Adapt mesh size to curvature\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthFromCurvature\", 1)  # Enable mesh size adaptation based on curvature\n",
    "    gmsh.option.setNumber(\"Mesh.CharacteristicLengthMin\", caracteristic_length_min/10)  # maille min de 0.0005\n",
    "    gmsh.option.setNumber(\"Mesh.Algorithm\", 6)  # 6 = use the Frontal-Delaunay algorithm for mesh generation\n",
    "    #gmsh.option.setNumber(\"Mesh.Algorithm3D\", 10)  # 6 = use the Frontal-Delaunay algorithm for 3D mesh generation\n",
    "    gmsh.option.setNumber(\"Mesh.MinimumElementsPerTwoPi\", 100)  # Minimum number of mesh elements per 2*pi radians (for circular features)\n",
    "    gmsh.option.setNumber(\"Geometry.Tolerance\", caracteristic_length_min / 10000)\n",
    "    gmsh.option.setNumber(\"Mesh.Smoothing\", 5)\n",
    "    gmsh.option.setNumber(\"Mesh.OptimizeNetgen\", 1)  # Netgen mesh optimization\n",
    "    #gmsh.option.setNumber(\"Mesh.Optimize\", 1)\n",
    "    #gmsh.option.setNumber(\"Mesh.SecondOrderLinear\", 0)\n",
    "    #gmsh.option.setNumber(\"Mesh.CharacteristicLengthExtendFromBoundary\", 0)  # Do not extend mesh size from boundary\n",
    "    gmsh.option.setNumber(\"General.NumThreads\", thread_number)# for parallel 3D meshing\n",
    "    gmsh.option.setNumber(\"Mesh.SubdivisionAlgorithm\", 1)\n",
    "    # Options to prevent geometry simplification by the OCC kernel\n",
    "    #gmsh.option.setNumber(\"Geometry.OCCFixDegenerated\", 0)\n",
    "    #gmsh.option.setNumber(\"Geometry.OCCFixSmallEdges\", 0)\n",
    "    #gmsh.option.setNumber(\"Geometry.OCCFixSmallFaces\", 0)\n",
    "\n",
    "    \n",
    "    print(\"=== GMSH initialized ===\")\n",
    "    print(f\"Minumum caracterist length used : {caracteristic_length_min} \")\n",
    "    print(f\"Maximum caracterist length used : {caracteristic_length_max} \")\n",
    "    print(f\"Number of threads used : {thread_number}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "363f7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Bible of the geometry === ###\n",
    "\n",
    "def create_bible():\n",
    "    \"\"\"\n",
    "    This function creates the bible of the geometry.\n",
    "    The Bible contains all the data of the geometry in a dataframe.\n",
    "    The columns are:\n",
    "    - dimtag_entity: the tag of the geometry in the format [(dim, tag)]\n",
    "    - entity_name: the name of the geometry (not used by GMSH), theoretically the name of the physical group in the format [name]\n",
    "    - entity_coordinates: the coordinates of the geometry in the format [x, y, z]\n",
    "    - entity_dimension: the dimension of the geometry in the format [x_length, y_length, z_length]\n",
    "    - dimtag_group: the tag of the physical group of the entity in the format [(dim, tag)]\n",
    "    - group_name: the name of the physical group of the entity ine format [name]\n",
    "    - dimtag_parent: the tag of the parent entity in the format [(dim, tag)] (usually a volume)\n",
    "    \"\"\"\n",
    "    # Create the bible\n",
    "    bible = pd.DataFrame(columns=[\"dimtag_entity\", \"entity_name\", \"entity_coordinates\", \"entity_dimension\", \"dimtag_group\", \"group_name\", \"dimtag_parent\"])\n",
    "    return bible\n",
    "\n",
    "def print_bible(bible):\n",
    "    \"\"\"\n",
    "    This function prints the bible of the geometry.\n",
    "    \"\"\"\n",
    "    print(\"=== Bible of the geometry: ===\")\n",
    "    print(bible)\n",
    "\n",
    "def dimtag_to_tuple(dimtag, debug=False):\n",
    "    \"\"\"\n",
    "    This function converts a dimtag to a tuple. \n",
    "    It will also convert the element to int.\n",
    "    \"\"\"\n",
    "    if dimtag is None or len(dimtag) == 0:\n",
    "        return None\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Converting dimtag {dimtag} to tuple\")\n",
    "    dim = int(dimtag[0])\n",
    "    tag = int(dimtag[1])\n",
    "    return (dim, tag)\n",
    "    \n",
    "def write_data_to_bible(data, column, bible_index, overwrite, debug=False):\n",
    "    # Get Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Get the values at the index\n",
    "    values = Bible.loc[bible_index, column]\n",
    "    # Check if the values are None\n",
    "    if values is None or overwrite:\n",
    "        # If they are None or we want to overwrite, we write the data\n",
    "        Bible.loc[bible_index, column] = data\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Writing {data} to {column} at index {bible_index}\")\n",
    "    return None  \n",
    "\n",
    "def add_to_bible(dimtag_entity=None, entity_name=None, entity_coordinates=None, entity_dimension=None, dimtag_group=None, group_name=None, dimtag_parent=None, overwrite=False, debug=False):\n",
    "    \"\"\"\n",
    "    Add a new element to the bible of the geometry.\n",
    "    It will automatically try to find corresponding existing elements in the bible via dimtags and compelte the data or overwrite them.\n",
    "    If it doesn't find any, it will create a new element.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    \n",
    "    # Convert dimtag_entity and dimtag_group to tuples if they are not None\n",
    "    dimtag_entity = dimtag_to_tuple(dimtag_entity, debug=debug)\n",
    "    dimtag_group = [dimtag_to_tuple(dimtag, debug=debug) for dimtag in dimtag_group] if dimtag_group is not None else None\n",
    "    \n",
    "    # Check dimension\n",
    "    if dimtag_entity is not None and dimtag_entity[0] < 2:\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Skipping entity {dimtag_entity} because its dimension is lower than 2\")\n",
    "        return Bible\n",
    "    \n",
    "    \n",
    "    # Define the data to write\n",
    "    Data_to_write = {\n",
    "        \"dimtag_entity\": dimtag_entity,\n",
    "        \"entity_name\": entity_name,\n",
    "        \"entity_coordinates\": entity_coordinates,\n",
    "        \"entity_dimension\": entity_dimension,\n",
    "        \"dimtag_group\": dimtag_group,\n",
    "        \"group_name\": group_name,\n",
    "        \"dimtag_parent\": dimtag_parent\n",
    "    }\n",
    "    \n",
    "    # Check if the element already exists in the bible by dimtag_entity\n",
    "    index = None\n",
    "    if dimtag_entity is not None:\n",
    "        existing_element = filter_bible(dimtag_entity=dimtag_entity)\n",
    "        if not existing_element.empty:\n",
    "            index = existing_element.index[0]\n",
    "    elif dimtag_group is not None and index is None:\n",
    "        # If the element does not exist, we check if it exists by dimtag_group\n",
    "        existing_element = filter_bible(dimtag_group=dimtag_group)\n",
    "        if not existing_element.empty:\n",
    "                index = existing_element.index[0]\n",
    "    if index is not None:\n",
    "        # If the element exists, we update the data\n",
    "        for col, val in Data_to_write.items():\n",
    "            if val is not None:\n",
    "                # If the value is None and we have a new value, we write it\n",
    "                write_data_to_bible(val, col, index, overwrite, debug)\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] Updated {col} for dimtag_entity={dimtag_entity}\")\n",
    "            elif debug:\n",
    "                print(f\"[DEBUG] No update for {col} for dimtag_entity={dimtag_entity} because value is None\")\n",
    "        \n",
    "    else:\n",
    "        # If the element does not exist, we create a new element with the right data\n",
    "        Bible = pd.concat([Bible, pd.DataFrame([Data_to_write], columns=Bible.columns)], ignore_index=True)\n",
    "        index = Bible.index[-1]\n",
    "    \n",
    "    return Bible\n",
    "\n",
    "def correct_bible_gmsh_by_entity(dimtag_entity, debug=False, child_correction=True, name_overwrite=None):\n",
    "    \"\"\"\n",
    "    This function corrects the bible of the geometry for a single specified entity using the gmsh API.\n",
    "    It will update the bible entry for the given dimtag_entity with the latest data from gmsh.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Get the information for the specified entity\n",
    "    dim, tag = int(dimtag_entity[0]), int(dimtag_entity[1])\n",
    "    # Check if the entity is a valid entity from the gmsh API\n",
    "    if gmsh.model.getType(dim, tag) == \"Unknown\":\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Entity {dimtag_entity} is not valid in gmsh API\")\n",
    "        \n",
    "        # If the entity is in the bible, remove it (robust tuple comparison)\n",
    "        mask = Bible[\"dimtag_entity\"].apply(lambda x: tuple(x) != tuple(dimtag_entity) if x is not None else True)\n",
    "        if len(Bible) != mask.sum():\n",
    "            Bible = Bible[mask]\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] Removed invalid entity {dimtag_entity} from bible\")\n",
    "        return Bible\n",
    "    \n",
    "    # Get the coordinates, dimension, group dimtag, group name and parent dimtag\n",
    "    entity_coordinates = gmsh.model.occ.getCenterOfMass(dim, tag)\n",
    "    bounding_box = gmsh.model.occ.getBoundingBox(dim, tag)\n",
    "    entity_dimension = [bounding_box[3] - bounding_box[0], bounding_box[4] - bounding_box[1], bounding_box[5] - bounding_box[2]]\n",
    "    group_tags = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "    dimtag_group = [(dim, int(group_tag)) for group_tag in group_tags]\n",
    "    group_name = [gmsh.model.getPhysicalName(dg[0], dg[1]) for dg in dimtag_group] if dimtag_group else []\n",
    "    upward_adjacencies = gmsh.model.getAdjacencies(dim, tag)[0]\n",
    "    dimtag_parent = [(int(dim+1), int(tag)) for tag in upward_adjacencies]\n",
    "    name = None\n",
    "    if name_overwrite is not None:\n",
    "        name = name_overwrite\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Overwriting name for entity {dimtag_entity} to {name}\")\n",
    "        \n",
    "    # Add or update the entry in the bible\n",
    "    add_to_bible(\n",
    "        dimtag_entity=dimtag_entity,\n",
    "        entity_name=name,\n",
    "        entity_coordinates=entity_coordinates,\n",
    "        entity_dimension=entity_dimension,\n",
    "        dimtag_group=dimtag_group,\n",
    "        group_name=group_name,\n",
    "        dimtag_parent=dimtag_parent,\n",
    "        overwrite=True,\n",
    "        debug=debug\n",
    "    )\n",
    "    \n",
    "    # We also need to check for child entities\n",
    "    \n",
    "    if child_correction:\n",
    "        child_entities = gmsh.model.getBoundary([dimtag_entity], oriented=False)\n",
    "        for child_entity in child_entities:\n",
    "            if child_entity[0] < dimtag_entity[0] and child_entity[0] > 0:\n",
    "                # If the child entity is a lower dimension, we need to correct it\n",
    "                if debug:\n",
    "                    print(f\"[DEBUG] Correcting child entity {child_entity} for parent {dimtag_entity}\")\n",
    "                # Recursively correct the child entity\n",
    "                correct_bible_gmsh_by_entity(child_entity, debug=debug)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Corrected bible entry for entity {dimtag_entity}\")\n",
    "\n",
    "    return Bible\n",
    "    \n",
    "def correct_bible_gmsh(minimum_dimension=2, debug=False):\n",
    "    \"\"\"\n",
    "    This function corrects the bible of the geometry using the gmsh API.\n",
    "    It will get from a dimtag the coordinates, dimension, group dimtag, group name and parent dimtag.\n",
    "    For that, it will first get the list of all the entities in the gmsh API and then it will get the information for each entity and verify the bible.\n",
    "    Then, it will delete bible elements that are not in the gmsh API.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    # Get the list of all the entities in the gmsh API\n",
    "    gmsh.model.occ.synchronize()\n",
    "    entities = gmsh.model.getEntities()\n",
    "    \n",
    "    # Loop over all the entities and get their information\n",
    "    for entity in entities:\n",
    "        if entity[0] >= minimum_dimension:\n",
    "            # If the entity is a volume or a surface, we need to correct it\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] Correcting bible for entity {entity}\")\n",
    "            # Get the dimtag of the entity\n",
    "            dimtag_entity = (entity[0], entity[1])\n",
    "            # Correct the bible for the entity\n",
    "            Bible = correct_bible_gmsh_by_entity(dimtag_entity, child_correction=False, debug=debug)\n",
    "        else:\n",
    "            if False:\n",
    "                print(f\"[DEBUG] Skipping entity {entity} because its dimension is lower than {minimum_dimension}\")\n",
    "    return Bible\n",
    "    \n",
    "def save_bible(file_name=\"bible.csv\", debug=False):\n",
    "    \"\"\"\n",
    "    This function saves the bible of the geometry to a CSV file.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    Bible.to_csv(file_name, index=False)\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Saved bible to {file_name}\")\n",
    "\n",
    "def filter_element(value, name, filtered_bible):\n",
    "    \"\"\"\n",
    "    This function filters the bible of the geometry by a specific element.\n",
    "    It will return a new dataframe with only the elements that match the criteria.\n",
    "    \"\"\"\n",
    "    if value is not None:\n",
    "        # Handle list/tuple/np.ndarray of values (for \"in\" or exact match)\n",
    "        if isinstance(value, (list, tuple, np.ndarray)):\n",
    "            # If the column contains lists/tuples, check if any element matches\n",
    "            def match_func(x):\n",
    "                # If both are lists/tuples/arrays, check for intersection or exact match\n",
    "                if isinstance(x, (list, tuple, np.ndarray)):\n",
    "                    # Exact match\n",
    "                    if list(x) == list(value):\n",
    "                        return True\n",
    "                    # Any element in value matches any element in x\n",
    "                    return any(\n",
    "                        (v == x or (isinstance(v, (list, tuple, np.ndarray)) and list(v) == list(x)))\n",
    "                        or (isinstance(xi, (list, tuple, np.ndarray)) and xi == v)\n",
    "                        for v in value for xi in (x if isinstance(x, (list, tuple, np.ndarray)) else [x])\n",
    "                    )\n",
    "                else:\n",
    "                    # x is scalar, value is list: check if x in value\n",
    "                    return x in value\n",
    "            filtered_bible = filtered_bible[filtered_bible[name].apply(match_func)]\n",
    "        else:\n",
    "            # Scalar value: check for equality or membership in list/tuple/array\n",
    "            def match_func(x):\n",
    "                if isinstance(x, (list, tuple, np.ndarray)):\n",
    "                    return value in x or any(\n",
    "                        (isinstance(xi, (list, tuple, np.ndarray)) and list(xi) == list(value))\n",
    "                        for xi in x\n",
    "                    )\n",
    "                else:\n",
    "                    return x == value\n",
    "            filtered_bible = filtered_bible[filtered_bible[name].apply(match_func)]\n",
    "    return filtered_bible\n",
    "\n",
    "def filter_bible(dimtag_entity=None, dimtag_group=None, group_name=None, group_tag=None, dimtag_parent=None, debug=False):\n",
    "    \"\"\"\n",
    "    This function filters the bible of the geometry.\n",
    "    It will return a new dataframe with only the elements that match the criteria.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    filtered_bible = Bible.copy()\n",
    "    \n",
    "    # Create a list of (value, name) tuples to filter\n",
    "    filter_list = [\n",
    "        (dimtag_entity, \"dimtag_entity\"),\n",
    "        (dimtag_group, \"dimtag_group\"),\n",
    "        (group_name, \"group_name\"),\n",
    "        (group_tag, \"dimtag_group\"),\n",
    "        (dimtag_parent, \"dimtag_parent\")\n",
    "    ]\n",
    "    \n",
    "    # Loop over the filter list and filter the elements\n",
    "    for value, name in filter_list:\n",
    "        if value is not None:\n",
    "            if debug:\n",
    "                print(f\"[DEBUG] Filtering by {name} with value {value}\")\n",
    "            filtered_bible = filter_element(value, name, filtered_bible)\n",
    "    \n",
    "\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Filtered bible with {len(filtered_bible)} elements\")\n",
    "    \n",
    "    return filtered_bible\n",
    "\n",
    "if False:\n",
    "    \n",
    "    global Bible\n",
    "    \n",
    "    # Create the bible\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Print the bible\n",
    "    print_bible(Bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a991bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Lists and positions functions === ###\n",
    "\n",
    "def positions_from_density(density, number_positions, debug=False):\n",
    "    \"\"\"Generate positions based on a density function.\n",
    "    Args:\n",
    "        density (function): A function that takes a single argument and returns a density value.\n",
    "        number_positions (int): The number of positions to generate.\n",
    "        debug (bool): If True, plot the density function and the generated positions.\n",
    "    Returns:\n",
    "        np.ndarray: An array of positions generated based on the density function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a fine grid for integration and inversion\n",
    "    x = np.linspace(0, 1, 1000)\n",
    "    y_density = density(x)\n",
    "    # Avoid negative or zero densities\n",
    "    y_density = np.clip(y_density, 1e-12, None)\n",
    "    # Compute cumulative density (numerical integration)\n",
    "    y_cum_density = np.cumsum(y_density)\n",
    "    y_cum_density = y_cum_density / y_cum_density[-1]  # Normalize to [0,1]\n",
    "\n",
    "    # Invert the cumulative density to get positions\n",
    "    target_cum = np.linspace(0, 1, number_positions)\n",
    "    positions = np.interp(target_cum, y_cum_density, x)\n",
    "\n",
    "    # For plotting/debugging\n",
    "    if debug:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x, y_density, label='Density Function')\n",
    "        plt.title('Density Function and Generated Positions')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    if debug:\n",
    "        plt.plot(x, y_cum_density, label='Cumulative Density Function')\n",
    "        for pos in positions:\n",
    "            plt.axvline(x=pos, color='g', linestyle='--')\n",
    "        plt.axhline(y=0, color='k', linestyle='--')\n",
    "        plt.axhline(y=1, color='k', linestyle='--')\n",
    "        plt.axvline(x=0, color='k', linestyle='--')\n",
    "        plt.axvline(x=1, color='k', linestyle='--')\n",
    "        plt.title('Density Function')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def reduce_number_points_list(initial_list, number_points_target, accel_ratio=ratio_for_accel_points, mode=reduce_points_method, debug=False):\n",
    "    \"\"\"\n",
    "    Reduce dynamically the number of points in a list to a specified number.\n",
    "    Keeps points of most importance via acceleration, but also distributes points uniformly.\n",
    "    The first and last points are always preserved.\n",
    "    :param initial_list: List of points to reduce.\n",
    "    :param number_points: Number of points to keep.\n",
    "    :param accel_ratio: Ratio of points to select by acceleration (0-1).\n",
    "    :return: Reduced list of points.\n",
    "    \"\"\"\n",
    "\n",
    "    # For the number of points we need at least 2 points\n",
    "    number_points = max(2, number_points_target)\n",
    "    if number_points >= len(initial_list):\n",
    "        return np.array(initial_list)\n",
    "    initial_list_np = np.array(initial_list)\n",
    "    \n",
    "    # We need to choose between the distribution by acceleration and by density\n",
    "    if mode == 'density':\n",
    "        # Calculate normalized x for density mapping\n",
    "        initial_start = initial_list_np[0, 0]\n",
    "        initial_end = initial_list_np[-1, 0]\n",
    "        initial_length = initial_end - initial_start\n",
    "\n",
    "        # Interpolate y-values and smooth acceleration for density\n",
    "        initial_function = scipy.interpolate.interp1d(initial_list_np[:, 0], initial_list_np[:, 1], kind='linear', fill_value=\"extrapolate\")\n",
    "        derivative = np.gradient(initial_list_np, axis=0)\n",
    "        acceleration = np.gradient(derivative, axis=0)\n",
    "        acceleration_magnitude = np.linalg.norm(acceleration, axis=1)\n",
    "        # Smooth acceleration to avoid spurious peaks\n",
    "        window = 7 if len(acceleration_magnitude) > 7 else max(3, len(acceleration_magnitude)//2*2+1)\n",
    "        acceleration_smoothed = np.convolve(acceleration_magnitude, np.ones(window)/window, mode='same')\n",
    "        # Avoid zero density\n",
    "        acceleration_smoothed = np.clip(acceleration_smoothed, 1e-8, None)\n",
    "        acceleration_function = scipy.interpolate.interp1d(initial_list_np[:, 0], acceleration_smoothed, kind='linear', fill_value=\"extrapolate\")\n",
    "        # Add a cosntant to avoid zero density and get points everywhere\n",
    "        mean_acceleration = np.mean(acceleration_smoothed)\n",
    "        # Density function normalized to [0, 1]\n",
    "        density_func = lambda x: acceleration_function(x * initial_length + initial_start) + 0.1 * mean_acceleration\n",
    "        # Generate new x positions based on density\n",
    "        new_x_positions = positions_from_density(density_func, number_points, debug=debug) * initial_length + initial_start\n",
    "        new_y_positions = initial_function(new_x_positions)\n",
    "        new_positions = np.column_stack((new_x_positions, new_y_positions))\n",
    "        if debug:\n",
    "            plt.plot(initial_list_np[:, 0], initial_list_np[:, 1], label='Initial Points')\n",
    "            plt.plot(new_positions[:, 0], new_positions[:, 1], label='Reduced Points')\n",
    "            plt.plot(initial_list_np[:, 0], acceleration_magnitude, label='Acceleration Magnitude')\n",
    "            plt.plot(derivative[:, 0], derivative[:, 1], label='Derivative')\n",
    "            plt.plot(new_x_positions, new_y_positions, label='New Positions')\n",
    "            plt.title('Density Function')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('Density')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "        # Replace the first and last points with the original ones\n",
    "        new_positions[0] = initial_list_np[0]\n",
    "        new_positions[-1] = initial_list_np[-1]\n",
    "        \n",
    "        # We do not want use non valid points (nan, inf)\n",
    "        reduced_positions = new_positions[~np.isnan(new_positions).any(axis=1)]\n",
    "    \n",
    "    elif mode == 'accel':\n",
    "        derivative = np.gradient(initial_list_np, axis=0)\n",
    "        acceleration = np.gradient(derivative, axis=0)\n",
    "        acceleration_magnitude = np.linalg.norm(acceleration[1:-1], axis=1)\n",
    "        n_to_select = number_points - 2  # Exclude first and last\n",
    "        # Split between acceleration-based and uniform\n",
    "        n_accel = int(np.round(n_to_select * accel_ratio))\n",
    "        n_uniform = n_to_select - n_accel\n",
    "        # Always keep the first and last points\n",
    "        keep_indices = {0, len(initial_list) - 1}\n",
    "        # Acceleration-based selection\n",
    "        candidate_indices = np.arange(1, len(initial_list) - 1)\n",
    "        sorted_indices = candidate_indices[np.argsort(acceleration_magnitude)]\n",
    "        accel_indices = sorted_indices[-n_accel:] if n_accel > 0 else np.array([], dtype=int)\n",
    "        # Uniform selection (excluding already chosen)\n",
    "        remaining_indices = sorted(set(candidate_indices) - set(accel_indices))\n",
    "        if n_uniform > 0 and len(remaining_indices) > 0:\n",
    "            uniform_indices = np.linspace(0, len(remaining_indices) - 1, n_uniform, dtype=int)\n",
    "            uniform_indices = np.array(remaining_indices)[uniform_indices]\n",
    "        else:\n",
    "            uniform_indices = np.array([], dtype=int)\n",
    "        # Combine all indices and sort\n",
    "        all_indices = np.sort(np.concatenate((np.array(list(keep_indices)), accel_indices, uniform_indices)))\n",
    "        reduced_positions = initial_list_np[all_indices]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Use 'density' or 'accel'.\")\n",
    "    \n",
    "    return reduced_positions\n",
    "\n",
    "def profile_points_modificator(initial_profile, modificator, interpolate=True, smooth=True):\n",
    "    \"\"\"\n",
    "    Modifies the profile points based on a given modificator function.\n",
    "    \n",
    "    :param initial_profile: Initial profile points.\n",
    "    :param modificator: Function to modify the profile points.\n",
    "    :return: Modified profile points.\n",
    "    \"\"\"\n",
    "    if modificator is None:\n",
    "        return initial_profile\n",
    "    \n",
    "    if interpolate:\n",
    "        # Number of points\n",
    "        number_points = len(initial_profile)\n",
    "        # Curve fitting \n",
    "        initial_function = scipy.interpolate.interp1d(initial_profile[:, 0], initial_profile[:, 1], kind='linear', fill_value=\"extrapolate\")\n",
    "        # Modify the function\n",
    "        modified_function = lambda x: initial_function(x) + modificator(x)\n",
    "        # Generate x values for the modified function\n",
    "        x_values = np.linspace(initial_profile[0, 0], initial_profile[-1, 0], number_points)        \n",
    "        # Calculate the modified Y values using the modified function\n",
    "        modified_profile = []\n",
    "        for x in x_values:\n",
    "            modified_profile.append([x, modified_function(x)])\n",
    "        # Convert the modified profile to a numpy array\n",
    "        modified_profile = np.array(modified_profile)\n",
    "    else:\n",
    "        # Apply the modificator function to each point in the initial profile\n",
    "        modified_profile = []\n",
    "        for point in initial_profile:\n",
    "            X_initial = point[0]\n",
    "            Y_initial = point[1]\n",
    "            X_modified = X_initial\n",
    "            Y_modified = Y_initial + modificator(X_initial)\n",
    "            modified_profile.append([X_modified, Y_modified])\n",
    "        # Convert the modified profile to a numpy array\n",
    "        modified_profile = np.array(modified_profile)\n",
    "        \n",
    "    return modified_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c17e76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Entities positions functions === ###\n",
    "\n",
    "def cartesian_to_polar_x_axis(position, Angle):\n",
    "    \"\"\"\n",
    "    Convert a 3D position to polar coordinates around the X axis.\n",
    "    \n",
    "    :param position: 3D position (x, y, z).\n",
    "    :return: Polar coordinates (r, theta, z).\n",
    "    \"\"\"\n",
    "    x, y, z = position\n",
    "    r = math.sqrt(y**2 + z**2)\n",
    "    theta = math.atan2(z, y) + Angle\n",
    "    return r, theta, x\n",
    "\n",
    "def polar_to_cartesian(polar_position, Angle):\n",
    "    \"\"\"\n",
    "    Convert polar coordinates around the X axis to a 3D position.\n",
    "    \n",
    "    :param polar_position: Polar coordinates (r, theta, z).\n",
    "    :return: 3D position (x, y, z).\n",
    "    \"\"\"\n",
    "    r, theta, x = polar_position\n",
    "    y = r * math.cos(theta - Angle)\n",
    "    z = r * math.sin(theta - Angle)\n",
    "    return x, y, z    \n",
    "    \n",
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def entity_position(entity, use_gmsh=False, debug=DEBUG):\n",
    "    \"\"\"\n",
    "    Get the position of a GMSH entity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    if not use_gmsh:\n",
    "        # Compare each row as tuple\n",
    "        mask = Bible[\"dimtag_entity\"].apply(lambda x: tuple(x) == tuple(entity))\n",
    "        filtered = Bible[mask]\n",
    "        if filtered.empty:\n",
    "            #raise ValueError(f\"Entity {entity} not found in bible.\")\n",
    "            print(f\"[DEBUG] Entity {entity} not found in bible.\")\n",
    "            return None\n",
    "        pos = filtered[\"entity_coordinates\"].values[0]\n",
    "    \n",
    "    else:\n",
    "        pos = gmsh.model.occ.getCenterOfMass(entity[0], entity[1])\n",
    "    \n",
    "    #Convert to float list and not np.ndarray\n",
    "    pos = [float(coord) for coord in pos] if isinstance(pos, (list, tuple, np.ndarray)) else [float(pos)]\n",
    "    return pos\n",
    "\n",
    "def entity_dimension(entity, use_gmsh=False, debug=DEBUG):\n",
    "    \"\"\"\n",
    "    Get the length of a GMSH entity.\n",
    "    \n",
    "    :param entity: The entity to get the length of.\n",
    "    :param use_gmsh: If True, use the GMSH API to get the length.\n",
    "    :param debug: If True, print debug information.\n",
    "    :return: The length of the entity.\n",
    "    \"\"\"\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    # Compare each row as tuple\n",
    "    if not use_gmsh:\n",
    "        mask = Bible[\"dimtag_entity\"].apply(lambda x: tuple(x) == tuple(entity))\n",
    "        filtered = Bible[mask]\n",
    "    else:\n",
    "        filtered = None\n",
    "    \n",
    "    # If the entity is not found in the bible, use the GMSH API\n",
    "    if (filtered is None or filtered.empty) or use_gmsh:\n",
    "        # Debug:\n",
    "        if debug and not use_gmsh:\n",
    "            print(f\"[DEBUG] Entity {entity} not found in bible, using GMSH API\")\n",
    "        # Get the bounding box from GMSH\n",
    "        bounding_box = gmsh.model.occ.getBoundingBox(entity[0], entity[1])\n",
    "        entity_dimension = [\n",
    "            bounding_box[3] - bounding_box[0],\n",
    "            bounding_box[4] - bounding_box[1],\n",
    "            bounding_box[5] - bounding_box[2]\n",
    "        ]\n",
    "        # Add the dimension to the bible\n",
    "        if not use_gmsh:\n",
    "            add_to_bible(dimtag_entity=entity, entity_dimension=entity_dimension, overwrite=True)\n",
    "    else:\n",
    "        # Get the dimension from the bible\n",
    "        entity_dimension = filtered[\"entity_dimension\"].values[0]\n",
    "        if isinstance(entity_dimension, (list, tuple, np.ndarray)) and len(entity_dimension) == 3:\n",
    "            entity_dimension = np.array(entity_dimension, dtype=float)\n",
    "        else:\n",
    "            print(f\"[DEBUG] Invalid format for dimension of entity {entity}: {entity_dimension} Using GMSH API instead.\")\n",
    "            bounding_box = gmsh.model.occ.getBoundingBox(entity[0], entity[1])\n",
    "            entity_dimension = [bounding_box[3] - bounding_box[0], bounding_box[4] - bounding_box[1], bounding_box[5] - bounding_box[2]]\n",
    "    \n",
    "    # Return the dimension\n",
    "    return entity_dimension\n",
    "\n",
    "def angles_close(a, b, tol=1e-6):\n",
    "    return np.isclose(np.mod(a - b + np.pi, 2 * np.pi) - np.pi, 0, atol=tol)\n",
    "\n",
    "def rotate_position(arguments, debug=False):\n",
    "    \"\"\"\n",
    "    Rotate a position around the Z axis.\n",
    "    \n",
    "    :param args: Arguments for rotation (x, y, z, ax, ay, az, angle).\n",
    "    :return: Rotated position.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the angle of the Nozzle\n",
    "    global Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Get the arguments of the rotation\n",
    "    dimTags, x, y, z, ax, ay, az, angle = arguments\n",
    "    \n",
    "    # Get the tag and position of each entity\n",
    "    rotated_entity_to_tag_and_position = {}\n",
    "    for dim, tag in dimTags:\n",
    "        # Try to get the position from the bible\n",
    "        try:\n",
    "            position = entity_position([dim, tag])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not get position for entity {(dim, tag)}: {e}\")        \n",
    "        \n",
    "        # Simple method to rotate the position around the X axis\n",
    "        polar_position = cartesian_to_polar_x_axis(position, -Nozzle_Angle_Revolution)\n",
    "        rotated_polar_position = (polar_position[0], polar_position[1] + np.pi, polar_position[2])\n",
    "        rotated_position = polar_to_cartesian(rotated_polar_position, -Nozzle_Angle_Revolution)\n",
    "        \n",
    "        if True:\n",
    "            if angle!=0 and rotated_position[0] == position[0] and rotated_position[1] == position[1] and rotated_position[2] == position[2]:\n",
    "                raise ValueError(f\"Position of entity {(dim, tag)} has not been correctly rotated. Expected different position, got {rotated_position}.\")\n",
    "            \n",
    "        # Correct the format of the rotated position\n",
    "        if isinstance(rotated_position, (list, tuple, np.ndarray)) and len(rotated_position) == 3:\n",
    "            rotated_position = np.array(rotated_position, dtype=float)\n",
    "        \n",
    "        # Save the tag and rotated position in a dictionary\n",
    "        rotated_entity_to_tag_and_position[tag] = {\"tag\": tag, \"position\": rotated_position}\n",
    " \n",
    "        # Actualize the bible with the new position\n",
    "        dimtag_entity = dimtag_to_tuple((dim, tag))\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Adding : dimtag {dimtag_entity}, position {rotated_position}\")\n",
    "        add_to_bible(dimtag_entity=dimtag_entity, entity_coordinates=rotated_position, overwrite=True)\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Rotated entity {tag} to position {rotated_position}\")\n",
    "            \n",
    "        # Debug: Verify that the position has been correctly rotated\n",
    "        if True:\n",
    "            new_position = entity_position((dim, tag), use_gmsh=False)\n",
    "            if new_position[0] == position[0] and new_position[1] == position[1] and new_position[2] == position[2]:\n",
    "                raise ValueError(f\"Position of entity {(dim, tag)} has not been correctly rotated. Expected {rotated_position}, got {new_position}.\")\n",
    "            new_position_polar = cartesian_to_polar_x_axis(new_position, -Nozzle_Angle_Revolution)\n",
    "            if not (\n",
    "                np.isclose(new_position_polar[0], rotated_polar_position[0], atol=1e-8)\n",
    "                and angles_close(new_position_polar[1], rotated_polar_position[1])\n",
    "                and np.isclose(new_position_polar[2], rotated_polar_position[2], atol=1e-8)\n",
    "                ):\n",
    "                raise ValueError(\n",
    "                    f\"Polar position of entity {(dim, tag)} has not been correctly rotated. \"\n",
    "                    f\"Expected {rotated_polar_position}, got {new_position_polar}.\"\n",
    "                )\n",
    "    return rotated_entity_to_tag_and_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4bdb3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Delete something === ###\n",
    "\n",
    "def delete_entity(dimTags, debug=False):\n",
    "    \"\"\"\n",
    "    Delete entities from a specified list.\n",
    "    :param dimTags: List of tuples (dim, tag) to delete.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    deleted = []\n",
    "    for dim, tag in dimTags:\n",
    "        try:\n",
    "            gmsh.model.occ.remove([(dim, tag)], recursive=True)\n",
    "            gmsh.model.occ.synchronize()\n",
    "            \n",
    "            # Also remove the physical group\n",
    "            physical_groups = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "            for physical_group in physical_groups:\n",
    "                if debug:\n",
    "                    print(f\"Removing physical group: {physical_group}\")\n",
    "                try:\n",
    "                    gmsh.model.removePhysicalGroups([(dim, physical_group)])\n",
    "                    gmsh.model.occ.synchronize()\n",
    "                    deleted.append((dim, physical_group))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing physical group {physical_group}: {e}\")\n",
    "                # Verify that the physical group is deleted\n",
    "                try:\n",
    "                    gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "                except Exception as e:\n",
    "                    if debug:\n",
    "                        print(f\"Physical group {physical_group} is deleted.\")\n",
    "                else:\n",
    "                    print(f\"ATTENTION : Physical group {physical_group} is not deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing entity {tag}: {e}\")\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Verify that the entity is deleted\n",
    "    for dim, tag in deleted:\n",
    "        if (dim, tag) not in gmsh.model.getEntities(dim):\n",
    "            if debug:\n",
    "                print(f\"Entity {tag} is deleted.\")\n",
    "        else:\n",
    "            print(f\"ATTENTION : Entity {tag} is not deleted.\")\n",
    "\n",
    "    return deleted\n",
    "\n",
    "def delete_entities_without_physical_group(dimDeletion=2, debug=False):\n",
    "    \"\"\"\n",
    "    Delete entities without a physical group.\n",
    "    \"\"\"\n",
    "    # Get all entities\n",
    "    entities = gmsh.model.getEntities(dimDeletion)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    removed_entities = []\n",
    "    # Loop through all entities\n",
    "    for dim, tag in entities:\n",
    "        # Check if the entity has a physical group\n",
    "        physical_groups = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "        if len(physical_groups) == 0:\n",
    "            # Delete the entity\n",
    "            try:\n",
    "                deleted = delete_entity([(dim, tag)])\n",
    "                if len(deleted) > 0:\n",
    "                    removed_entities.append((dim, tag))\n",
    "                    print(f\"Entity {tag} is deleted.\")\n",
    "                else:\n",
    "                    if DEBUG:\n",
    "                        name = group_name_via_tags([(dim, tag)])\n",
    "                        print(f\"Entity {tag} is not deleted. It is in the group {name}.\")\n",
    "                    else:\n",
    "                        print(f\"Entity {tag} is not deleted.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing entity {tag}: {e}\")\n",
    "       \n",
    "    return removed_entities\n",
    "\n",
    "def delete_entities_with_physical_group(dimtags, debug=False):\n",
    "    \"\"\"\n",
    "    Delete entities and their groups from a specified list.\n",
    "    :param dimtags: List of tuples (dim, tag) to delete.\n",
    "    \n",
    "    \"\"\"\n",
    "    removed_entities = []\n",
    "    for dim, tag in dimtags:\n",
    "        try:\n",
    "            physical_groups = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "            for physical_group in physical_groups:\n",
    "                if DEBUG:\n",
    "                    print(f\"Removing physical group: {physical_group}\")\n",
    "                try:\n",
    "                    gmsh.model.removePhysicalGroups([(dim, physical_group)])\n",
    "                    gmsh.model.occ.synchronize()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing physical group {physical_group}: {e}\")\n",
    "            try:\n",
    "                deleted = delete_entity([(dim, tag)])\n",
    "                if len(deleted) > 0:\n",
    "                    removed_entities.append((dim, tag))\n",
    "                    print(f\"Entity {tag} is deleted.\")\n",
    "                else:\n",
    "                    print(f\"Entity {tag} is not deleted.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error removing entity {tag}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing entity {tag}: {e}\")\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    return removed_entities\n",
    "\n",
    "def delete_physical_groups(dim, tag, debug=False):\n",
    "    \"\"\"\n",
    "    Delete physical groups from a specified list.\n",
    "    :param dim: Dimension of the group to delete.\n",
    "    :param tag: Tag of the group to delete.\n",
    "    \n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    try:\n",
    "        gmsh.model.removePhysicalGroups([(dim, tag)])\n",
    "        gmsh.model.occ.synchronize()\n",
    "        if debug:\n",
    "            print(f\"Group {tag} (dim={dim}) deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing group {tag}: {e}\")\n",
    "        return False\n",
    "    \n",
    "    '''\n",
    "    # Actualize the bible by deleting the line with the group\n",
    "    index = Bible[Bible[\"dimtag_group\"].apply(lambda x: x == [(dim, tag)])].index\n",
    "    if len(index) > 0:\n",
    "        Bible = Bible.drop(index)\n",
    "        if debug:\n",
    "            print(f\"Group {tag} (dim={dim}) deleted from bible.\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Group {tag} (dim={dim}) not found in bible.\")\n",
    "    '''\n",
    "    return True\n",
    "\n",
    "def delete_groups_by_prefix(prefix, debug=False):\n",
    "    \"\"\"\n",
    "    Delete groups with a specific prefix.\n",
    "    :param prefix: Prefix of the groups to delete.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    \n",
    "    for dim, tag in physical_groups:\n",
    "        try:\n",
    "            name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        except Exception:\n",
    "            name = \"\"\n",
    "        if name.startswith(prefix):\n",
    "            result = delete_physical_groups(dim, tag, debug=debug)\n",
    "            if debug:\n",
    "                if result:\n",
    "                    print(f\"Group {name} is deleted.\")\n",
    "                else:\n",
    "                    print(f\"Group {name} is not deleted.\")\n",
    "    return True\n",
    "\n",
    "def remove_duplicate_points(points, tol=1e-8):\n",
    "    unique = []\n",
    "    for p in points:\n",
    "        if not any(np.allclose(p, q, atol=tol) for q in unique):\n",
    "            unique.append(p)\n",
    "    return np.array(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b2682af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Entities, groups and tags functions === ###\n",
    "\n",
    "def print_everything():\n",
    "    \"\"\"\n",
    "    Print physical entities, their name, tags and entities via a dataframe.\n",
    "    After that, it shows entities with their tags, physical groups (names and tags)\n",
    "    \"\"\"\n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    \n",
    "    # Create a list to store the data\n",
    "    data = []\n",
    "    \n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        # Get the tags in the group\n",
    "        tags = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "        # Append the data to the list\n",
    "        data.append([dim, tag, name, tags])\n",
    "    \n",
    "    # Create a dataframe from the data\n",
    "    df = pd.DataFrame(data, columns=[\"dim\", \"tag\", \"name\", \"tags\"])\n",
    "    \n",
    "    # Print the dataframe\n",
    "    print(f\"%%%% === Physical groups === %%% {physical_groups}\")\n",
    "    print(df)\n",
    "\n",
    "    # Print entities without physical groups\n",
    "    entities = gmsh.model.getEntities(2)\n",
    "    data = []\n",
    "    for dim, tag in entities:\n",
    "        # Get the name of the group\n",
    "        try:\n",
    "            group = gmsh.model.getPhysicalGroupsForEntity(dim, tag)\n",
    "            name = gmsh.model.getPhysicalName(dim, group[0])\n",
    "        except Exception as e:\n",
    "            group = []\n",
    "            name = \"No group\"\n",
    "        # Append the data to the list\n",
    "        data.append([dim, tag, name])\n",
    "    \n",
    "    # Create a dataframe from the data\n",
    "    df = pd.DataFrame(data, columns=[\"dim\", \"tag\", \"name\"])\n",
    "    # Print the dataframe\n",
    "    print(f\"%%%% === Entities === %%% {entities}\")\n",
    "    print(df)\n",
    "    return None\n",
    " \n",
    "def entities_tags_via_group_name(group_name=\"\", debug=False):\n",
    "    \"\"\"\n",
    "    Get the tags of a group by its name.\n",
    "    \n",
    "    :param group_name: Name of the group.\n",
    "    :return: List of tags in the group.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=None, group_name=group_name, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the tags\n",
    "    if not filtered.empty:\n",
    "        # Get the tags from the filtered Bible\n",
    "        tags_list = filtered[\"dimtag_entity\"].values[0]\n",
    "        return tags_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Group name {group_name} not found in Bible, using GMSH API\")\n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Initiate the list of tags\n",
    "    tags_list = []\n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        if group_name in name:\n",
    "            # Get the tags in the group\n",
    "            tags = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "            for found_tag in tags:\n",
    "                tags_list.append((dim, found_tag))\n",
    "    return tags_list\n",
    "\n",
    "def group_tags_via_group_name(group_name=\"\", debug=False):\n",
    "    \"\"\"\n",
    "    Get the tags of a group by its name.\n",
    "    \n",
    "    :param group_name: Name of the group.\n",
    "    :return: List of tags in the group.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=None, group_name=group_name, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the tags\n",
    "    if not filtered.empty:\n",
    "        # Get the tags from the filtered Bible\n",
    "        dimtag_list = filtered[\"dimtag_group\"].values[0]\n",
    "        # Ensure the tags are in the correct format\n",
    "        dimtag_list = extract_dimtags_list(dimtag_list)\n",
    "        # Convert to a list of tags\n",
    "        tags_list = [tag for dim, tag in dimtag_list]\n",
    "        return tags_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Group name {group_name} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Initiate the list of tags\n",
    "    tags_list = []\n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        if group_name in name:\n",
    "            tags_list.append((dim,tag))\n",
    "    return tags_list\n",
    "\n",
    "def group_name_via_tags(tags, debug=False):\n",
    "    \"\"\"\n",
    "    Get the names of groups by their tags.\n",
    "    :param tags: Tags of the group.\n",
    "    :return: Names of the group.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    mask = Bible[\"dimtag_group\"].apply(lambda x: any(tag in x for tag in tags))\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=None, group_name=None, group_tag=tags, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the names\n",
    "    if not filtered.empty:\n",
    "        # Get the names from the filtered Bible\n",
    "        names_list = filtered[\"group_name\"].values[0]\n",
    "        # Flatten the list of names\n",
    "        names_list = [name for sublist in names_list for name in sublist]\n",
    "        # Ensure the names are in the correct format\n",
    "        names_list = [name for name in names_list if isinstance(name, str)]\n",
    "        # Remove duplicates\n",
    "        names_list = list(set(names_list))\n",
    "        return names_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Group tags {tags} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Initiate the list of names\n",
    "    names_list = []\n",
    "    # Loop through all physical groups\n",
    "    for dim, tag in physical_groups:\n",
    "        # Get the name of the group\n",
    "        name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        #Get the entities tags in the group\n",
    "        tags_entitites = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "        #Check if one of the entities tags is in the tags\n",
    "        if any(tag in tags_entitites for tag in tags):\n",
    "            # Add the name to the list\n",
    "            names_list.append(name)\n",
    "    return names_list\n",
    "\n",
    "def group_tags_via_entity_tag(dimtag, debug=False):\n",
    "    \"\"\"\n",
    "    Get the tags of a group by its entity tag.\n",
    "    :param dimtag: Tag of the entity.\n",
    "    :return: List of tags in the group.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Filter the Bible to find the group name\n",
    "    filtered = filter_bible(dimtag_entity=dimtag, dimtag_group=None, group_name=None, group_tag=None, debug=debug)\n",
    "    \n",
    "    # If the group name is found in the Bible, return the tags\n",
    "    if not filtered.empty:\n",
    "        # Get the tags from the filtered Bible\n",
    "        group_dimtag_list = filtered[\"dimtag_group\"].values[0]\n",
    "        # Ensure the tags are in the correct format\n",
    "        group_dimtag_list = extract_dimtags_list(group_dimtag_list)\n",
    "        # Convert to a list of tags\n",
    "        tags_list = [tag for dim, tag in group_dimtag_list]\n",
    "        return tags_list\n",
    "    \n",
    "    # If the group name is not found in the Bible, use GMSH API\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Entity tag {dimtag} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get the tags of the entity\n",
    "    group_tags = []\n",
    "    dim, tag = dimtag\n",
    "    \n",
    "    # Get all physical groups\n",
    "    physical_groups = gmsh.model.getPhysicalGroups()\n",
    "    # Loop through all physical groups\n",
    "    for dim_pg, tag_pg in physical_groups:\n",
    "        # Get the tags in the group\n",
    "        tags = gmsh.model.getEntitiesForPhysicalGroup(dim_pg, tag_pg)\n",
    "        if (dim, tag) in tags:\n",
    "            group_tags.append((dim_pg, tag_pg))\n",
    "    return group_tags\n",
    "\n",
    "def change_group_name(dimtag, new_name, debug=False):\n",
    "    \"\"\"\n",
    "    Change the name of a group, using the Bible if available, otherwise fallback to GMSH API.\n",
    "    \n",
    "    :param dimtag: Tag of the group (dim, tag).\n",
    "    :param new_name: New name of the group.\n",
    "    :param debug: Print debug info.\n",
    "    :return: True if the name was changed, False otherwise.\n",
    "    \"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "\n",
    "    # Filter the Bible to the dimtag of the group\n",
    "    filtered = filter_bible(dimtag_entity=None, dimtag_group=dimtag, group_name=None, group_tag=None, debug=debug)\n",
    "    \n",
    "    # Actualize the group name in the Bible\n",
    "    if not filtered.empty:\n",
    "        # Get the group name from the filtered Bible\n",
    "        old_names = filtered[\"group_name\"].values[0]\n",
    "        # Ensure old_names is a list of names by flattening it\n",
    "        old_names = [name for sublist in old_names for name in sublist]\n",
    "        # Take the most present name in the old_names list\n",
    "        old_name = max(set(old_names), key=old_names.count)\n",
    "        # Replace the instances of the old name in the group_name lists of the Bible\n",
    "        Bible[\"group_name\"] = Bible[\"group_name\"].apply(lambda x: [new_name if name == old_name else name for name in x])\n",
    "        # Verify that the group name is updated\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[Bible] Changed group name from {old_name} to {new_name} for (dim, tag)=({dimtag})\")\n",
    "    else:\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[Bible] Group (dim, tag)=({dimtag}) not found in Bible, fallback to GMSH\")            \n",
    "\n",
    "    # Always update in GMSH (fallback or sync)\n",
    "    try:\n",
    "        dim, tag = dimtag\n",
    "        current_name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        tags = gmsh.model.getEntitiesForPhysicalGroup(dim, tag)\n",
    "        gmsh.model.removePhysicalGroups([(dim, tag)])\n",
    "        gmsh.model.occ.synchronize()\n",
    "        gmsh.model.addPhysicalGroup(dim, tags, tag)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        gmsh.model.setPhysicalName(dim, tag, new_name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_real_name = gmsh.model.getPhysicalName(dim, tag)\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[GMSH] Current name: {current_name}\")\n",
    "            print(f\"[GMSH] New name: {new_name}\")\n",
    "            print(f\"[GMSH] New real name: {new_real_name}\")\n",
    "        return new_name != current_name and new_real_name == new_name\n",
    "    except Exception as e:\n",
    "        if debug or DEBUG:\n",
    "            print(f\"[GMSH] Failed to change group name in GMSH: {e}\")\n",
    "        return False\n",
    "\n",
    "def change_group_name_via_entity(dimtag, new_name, debug=False):\n",
    "    \"\"\"\n",
    "    Change the name of a group by its entity tag.\n",
    "    \n",
    "    :param dimtag: Tag of the entity.\n",
    "    :param new_name: New name of the group.\n",
    "    \"\"\"\n",
    "    # Get the group tags of the entity\n",
    "    physical_groups_tags = group_tags_via_entity_tag(dimtag, debug=debug)\n",
    "           \n",
    "    # Get the first physical group\n",
    "    if len(physical_groups_tags) == 0:\n",
    "        print(f\"Entity {dimtag} has no physical group.\")\n",
    "        return False\n",
    "    else:\n",
    "        grouptag = physical_groups_tags[0]\n",
    "    # Rename the group\n",
    "    if change_group_name((dimtag[0], grouptag), new_name):\n",
    "        if debug:\n",
    "            print(f\"Group {grouptag} is renamed to {new_name}.\")\n",
    "    else:\n",
    "        print(f\"Group {grouptag} is not renamed to {new_name}.\")\n",
    "        return False\n",
    "    \n",
    "    #Verify that the entity is in the new group\n",
    "    entities = gmsh.model.getEntitiesForPhysicalGroup(dimtag[0], grouptag)\n",
    "    if dimtag in entities:\n",
    "        if debug:\n",
    "            print(f\"Entity {dimtag} is in the new group {new_name}.\")\n",
    "    else:\n",
    "        print(f\"Entity {dimtag} is not in the new group {new_name}.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_child_entities(dimtag, minimal_dim=2, debug=False):\n",
    "    # We iterate over all entities to get the children of the given entity after that we reiterate over the children to get the children of the children\n",
    "    dimtag = extract_dimtags_list(dimtag)\n",
    "    child_dimtags = []\n",
    "    current_dimtags = dimtag\n",
    "    counter = dimtag[0][0]\n",
    "    while counter > minimal_dim:\n",
    "        counter -= 1\n",
    "        added_dimtags = []\n",
    "        for dim, tag in current_dimtags:\n",
    "            # Get the children of the entity\n",
    "            children_tags = gmsh.model.getAdjacencies(dim, tag)[1]\n",
    "            added_dimtags = [(dim-1,tag) for tag in children_tags]\n",
    "        current_dimtags = added_dimtags\n",
    "        child_dimtags += added_dimtags\n",
    "    # Verify the format\n",
    "    child_dimtags = extract_dimtags_list(child_dimtags)\n",
    "    # Remove duplicates\n",
    "    child_dimtags = list(set(child_dimtags))\n",
    "    return child_dimtags\n",
    "\n",
    "def get_parent_volumes_of_entities(entities, use_bible=False, debug=False):\n",
    "    \"\"\"\n",
    "    Get the parent volumes of a GMSH entity.\n",
    "    \n",
    "    :param entities: The entity to get the parent volumes of.\n",
    "    :param use_bible: If True, use the Bible to get the parent volumes.\n",
    "    :param debug: If True, print debug information.\n",
    "    :return: The parent volumes of the entity.\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_bible:\n",
    "        # Get the Bible\n",
    "        global Bible\n",
    "        \n",
    "        # Filter the Bible to find the entity\n",
    "        filtered = filter_bible(dimtag_entity=entities, dimtag_group=None, group_name=None, group_tag=None)\n",
    "        \n",
    "        # If the entity is found in the Bible, return the parent volumes\n",
    "        if not filtered.empty:\n",
    "            parent_volumes = filtered[\"dimtag_parent\"].values[0]\n",
    "            parent_volumes = extract_dimtags_list(parent_volumes)\n",
    "            return parent_volumes\n",
    "    \n",
    "        # If the entity is not found in the Bible, use GMSH API\n",
    "        if debug:\n",
    "            print(f\"[DEBUG] Entity {entities} not found in Bible, using GMSH API\")\n",
    "    \n",
    "    # Get the parent volumes of the entity\n",
    "    parent_tags = gmsh.model.getAdjacencies(entities[0][0], entities[0][1])[0]\n",
    "    parent_volumes = [(entities[0][0]+1, tag) for tag in parent_tags]\n",
    "    parent_volumes = extract_dimtags_list(parent_volumes)\n",
    "    \n",
    "    return parent_volumes\n",
    "    \n",
    "def replace_entities_from_volume(old_entities, new_entities , debug=False):\n",
    "    \"\"\"\n",
    "    Replace old entities with new entities in a volume.\n",
    "\n",
    "    :param old_entities: List of old entities to replace.\n",
    "    :param new_entities: List of new entities to replace with.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the parent volumes of the old entities\n",
    "    volumes = get_parent_volumes_of_entities(old_entities)\n",
    "    if not volumes:\n",
    "        if DEBUG:\n",
    "            print(\"No parent volumes found for the given old_entities.\")\n",
    "        return None\n",
    "\n",
    "    volume = volumes[0]\n",
    "\n",
    "    # Get the list of entities in the volume\n",
    "    entities_in_volume = gmsh.model.getBoundary([volume], oriented=False)\n",
    "\n",
    "    # New entities for the volume\n",
    "    new_entities_for_volume = [entity for entity in entities_in_volume if entity not in old_entities]\n",
    "    new_entities_for_volume += new_entities\n",
    "\n",
    "    # Remove the old volume\n",
    "    gmsh.model.removeEntities([volume])\n",
    "    gmsh.model.occ.remove([volume])\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Create a new surface loop\n",
    "    surfaceTags = [tag for dim, tag in new_entities_for_volume if dim == 2]\n",
    "    if not surfaceTags:\n",
    "        if DEBUG:\n",
    "            print(\"No surface tags found for the new volume.\")\n",
    "        return None\n",
    "    new_loop = gmsh.model.occ.addSurfaceLoop(surfaceTags)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Create the new volume\n",
    "    new_volume = gmsh.model.occ.addVolume([new_loop])\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Debug : verify the new volume has the right faces and is not empty\n",
    "    if debug:\n",
    "        print(\"New volume: \", new_volume)\n",
    "        new_entities_in_volume = gmsh.model.getBoundary([(3, new_volume)], oriented=False)\n",
    "        print(\"New entities in volume: \", new_entities_in_volume)\n",
    "        if len(new_entities_in_volume) == 0:\n",
    "            print(\"Error: New volume is empty\")\n",
    "            return None\n",
    "        else:\n",
    "            print(\"New volume is not empty\")\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Actualize the Bible with the new volume\n",
    "    for dim, tag in new_entities_for_volume:\n",
    "        add_to_bible(dimtag_entity=(dim, tag), dimtag_parent=(3, new_volume), overwrite=True)\n",
    "    \n",
    "    return new_volume\n",
    "    \n",
    "def extract_dimtags_list(obj, dim=None):\n",
    "    \"\"\"\n",
    "    Extract a list of (dim, tag) tuples with the specified dimension from a possibly nested or mixed list/array.\n",
    "    Handles input as list, tuple, numpy array, or single (dim, tag) tuple.\n",
    "    If dim is None, returns all found (dim, tag) tuples.\n",
    "    :param obj: Input list/array/tuple of tags or dimtags.\n",
    "    :param dim: Dimension to filter for (e.g., 3 for volumes), or None for all.\n",
    "    :return: List of (dim, tag) tuples with the specified dimension or all if dim is None.\n",
    "    \"\"\"\n",
    "\n",
    "    def flatten_dimtags(o):\n",
    "        # Recursively flatten and extract (dim, tag) pairs\n",
    "        if isinstance(o, (list, tuple, np.ndarray)):\n",
    "            # If it's a (dim, tag) pair\n",
    "            if len(o) == 2 and all(isinstance(x, (int, np.integer)) for x in o):\n",
    "                return [tuple(int(x) for x in o)]\n",
    "            # Otherwise, flatten recursively\n",
    "            result = []\n",
    "            for item in o:\n",
    "                result.extend(flatten_dimtags(item))\n",
    "            return result\n",
    "        # If it's a single (dim, tag) pair as a numpy array\n",
    "        if isinstance(o, np.generic) and hasattr(o, 'shape') and o.shape == (2,):\n",
    "            return [tuple(int(x) for x in o)]\n",
    "        return []\n",
    "\n",
    "    all_dimtags = flatten_dimtags(obj)\n",
    "    if dim is None:\n",
    "        return all_dimtags\n",
    "    filtered = [dt for dt in all_dimtags if dt[0] == dim]\n",
    "    return filtered\n",
    "\n",
    "def create_physical_group(dim, tags, name, group_tag=None, debug=False):\n",
    "    \"\"\"\n",
    "    Create a physical group with the specified dimension, tags, and name.\n",
    "    \n",
    "    :param dim: Dimension of the group (e.g., 1 for lines, 2 for surfaces).\n",
    "    :param tags: List of tags to include in the group.\n",
    "    :param name: Name of the group.\n",
    "    :param group_tag: Optional tag for the group.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Verify that the tags exists\n",
    "    entities = gmsh.model.getEntities(dim)\n",
    "    tags_not_ok = all(tag not in [t for d, t in entities] for tag in tags)\n",
    "    if tags_not_ok:\n",
    "        print(f\"ATTENTION : None of the tags {tags} exists in the model\")\n",
    "        return False\n",
    "\n",
    "    # Get the group tag\n",
    "    if group_tag is None:\n",
    "        group_tag_used = start_tag\n",
    "    else:\n",
    "        group_tag_used = group_tag\n",
    "    \n",
    "    # Ensure the name is in the correct format\n",
    "    name = str(name)\n",
    "    \n",
    "    # Create the group\n",
    "    gmsh.model.occ.synchronize()\n",
    "    gmsh.model.addPhysicalGroup(dim=dim, tags=tags, tag=group_tag_used, name=name)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Get the name of the group\n",
    "    name_used = gmsh.model.getPhysicalName(dim, group_tag_used)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    if name_used != str(name):\n",
    "        if debug:\n",
    "            print(f\"ATTENTION : Group name {name_used} is not the same as {name}\")\n",
    "            return False\n",
    "        \n",
    "    # Actualize the start tag\n",
    "    start_tag = group_tag_used + 1\n",
    "    \n",
    "    # Add the group to the Bible\n",
    "    for tag in tags:\n",
    "        add_to_bible(dimtag_entity=(dim, tag), dimtag_group=[(dim, group_tag_used)], group_name=[name], overwrite=True, debug=debug)\n",
    "        \n",
    "    # Verify that the group is created by getting the entities in the group\n",
    "    try:\n",
    "        entities = gmsh.model.getEntitiesForPhysicalGroup(dim, group_tag_used)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting entities for physical group {group_tag_used}: {e}\")\n",
    "        entities = []\n",
    "    \n",
    "    # Check if the group is created\n",
    "    if len(entities) == 0:\n",
    "        print(f\"ATTENTION : Physical group {name} is not created\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Physical group {name} is created with tag {group_tag_used}\")\n",
    "    \n",
    "    #Check if the entities are in the group\n",
    "    if len(tags) > 0:\n",
    "        for tag in tags:\n",
    "            if (dim, tag) not in entities:\n",
    "                return False\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"Entity {tag} is in the group {name}\")\n",
    "    \n",
    "    # Actualize the start tag\n",
    "    start_tag = group_tag_used + 1\n",
    "\n",
    "    return True\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8f22b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === GMSH functions recovering tags and names === ###\n",
    "\n",
    "def cost_function(A_polar, B_polar, r_norm, theta_norm, x_norm):\n",
    "    \"\"\"\n",
    "    Cost function to compute the distance at each coordinate in a polar coordinate system.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Compute the differences for each coordinate\n",
    "    r_diff = abs(A_polar[0] - B_polar[0]) / r_norm\n",
    "    theta_diff = (A_polar[1] - B_polar[1]) / theta_norm\n",
    "    x_diff = abs(A_polar[2] - B_polar[2]) / x_norm\n",
    "    \n",
    "    # Weight the differences\n",
    "    r_factor = 0 ; theta_factor = 1/np.pi ; x_factor = 0\n",
    "    \n",
    "    # Compute the cost as a weighted sum of the differences\n",
    "    cost = r_factor * r_diff + theta_factor * theta_diff + x_factor * x_diff\n",
    "    \n",
    "    # Modify the cost to improve the assignment\n",
    "    #cost = cost**2\n",
    "    cost = np.log1p(cost)  # Use log1p to avoid issues with zero cost\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def polar_distance(a, b, r_norm=1, theta_norm=1, x_norm=1):\n",
    "    # Distance euclidienne pondÃ©rÃ©e, angle modulo 2Ï\n",
    "    dr = (a[0] - b[0]) / r_norm\n",
    "    dtheta = np.angle(np.exp(1j * (a[1] - b[1]))) / theta_norm  # distance angulaire [-Ï, Ï]\n",
    "    dx = (a[2] - b[2]) / x_norm\n",
    "    return np.sqrt(dr**2 + dtheta**2 + dx**2)\n",
    "\n",
    "def dimtags_assignment(old_entities_dimtags, new_entities_dimtags, debug=False, distance_weight=1.0, area_weight=0.0, type_weight=2.0, distance_threshold=None):\n",
    "    \"\"\"\n",
    "    Robust assignment of old to new dimtags using a multi-criteria cost matrix.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "    if len(old_entities_dimtags) == 0 or len(new_entities_dimtags) == 0:\n",
    "        return [[], []]\n",
    "\n",
    "    old_entities_dimtags = sorted(old_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "    new_entities_dimtags = sorted(new_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    # Get positions and dimensions\n",
    "    bible_positions = [entity_position(entity, use_gmsh=False) for entity in old_entities_dimtags]\n",
    "    gmsh_positions = [entity_position(entity, use_gmsh=True) for entity in new_entities_dimtags]\n",
    "    bible_dims = [entity_dimension(entity, use_gmsh=False) for entity in old_entities_dimtags]\n",
    "    gmsh_dims = [entity_dimension(entity, use_gmsh=True) for entity in new_entities_dimtags]\n",
    "    bible_types = [entity[0] for entity in old_entities_dimtags]\n",
    "    gmsh_types = [entity[0] for entity in new_entities_dimtags]\n",
    "\n",
    "    # Compute area/volume for each entity (product of dimensions)\n",
    "    def prod(lst): return np.prod(lst) if lst is not None else 0\n",
    "    bible_areas = [prod(dim) for dim in bible_dims]\n",
    "    gmsh_areas = [prod(dim) for dim in gmsh_dims]\n",
    "\n",
    "    # Normalization factors\n",
    "    max_dist = max(np.linalg.norm(np.array(bp) - np.array(gp)) for bp in bible_positions for gp in gmsh_positions)\n",
    "    max_area = max(max(bible_areas), max(gmsh_areas), 1)\n",
    "\n",
    "    # Build cost matrix\n",
    "    cost_matrix = np.full((len(bible_positions), len(gmsh_positions)), np.inf)\n",
    "    for i, (old_pos, old_area, old_type) in enumerate(zip(bible_positions, bible_areas, bible_types)):\n",
    "        for j, (new_pos, new_area, new_type) in enumerate(zip(gmsh_positions, gmsh_areas, gmsh_types)):\n",
    "            # Distance cost\n",
    "            dist = np.linalg.norm(np.array(old_pos) - np.array(new_pos)) / max_dist\n",
    "            # Area/volume cost\n",
    "            area_cost = abs(old_area - new_area) / max_area\n",
    "            # Type cost\n",
    "            type_cost = 0 if old_type == new_type else 1\n",
    "            # Total cost\n",
    "            cost = distance_weight * dist + area_weight * area_cost + type_weight * type_cost\n",
    "            # Optional: threshold on distance\n",
    "            if distance_threshold is not None and dist > distance_threshold:\n",
    "                cost = np.inf\n",
    "            cost_matrix[i, j] = cost\n",
    "\n",
    "    # VÃ©rification de la faisabilitÃ©\n",
    "    if np.all(np.isinf(cost_matrix)):\n",
    "        raise ValueError(\"Aucune correspondance possibleâ¯: toutes les distances sont au-dessus du seuil ou types incompatibles.\")\n",
    "\n",
    "    if np.any(np.all(np.isinf(cost_matrix), axis=1)) or np.any(np.all(np.isinf(cost_matrix), axis=0)):\n",
    "        raise ValueError(\"Matrice de coÃ»t infaisableâ¯: au moins une ligne ou colonne ne contient que des np.inf.\")\n",
    "\n",
    "    if debug:\n",
    "        import pandas as pd\n",
    "        cost_df = pd.DataFrame(cost_matrix, columns=[str(e) for e in new_entities_dimtags], index=[str(e) for e in old_entities_dimtags])\n",
    "        cost_df.to_csv(f\"cost_matrix_dim_{old_entities_dimtags[0][0]}.csv\")\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    return row_ind, col_ind\n",
    "\n",
    "def recover_group_entities_and_names_via_positions(old_entities_dimtags, new_entities_dimtags, debug=False):\n",
    "    \"\"\"\n",
    "    Recover the group entities and names via positions.\n",
    "\n",
    "    This function matches new entities to their corresponding old entities based on their positions.\n",
    "    It uses a tolerance value to determine if two entities are close enough to be considered the same.\n",
    "    The function updates the group-to-entities-and-names mapping to reflect the new entities and their\n",
    "    corresponding physical groups.\n",
    "\n",
    "    :param new_entity_to_tag_and_position: Dictionary mapping new entity tags to their positions.\n",
    "    :param rotated_entity_to_tag_and_position: Dictionary mapping rotated entity tags to their positions.\n",
    "    :param group_to_entities_and_names: Dictionary mapping physical group tags to their entities and names.\n",
    "    :param tol: Tolerance value for matching positions (default is 1e-3).\n",
    "    :return: Updated group-to-entities-and-names mapping.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Specific debug for uneven number of entities\n",
    "    if len(old_entities_dimtags) != len(new_entities_dimtags):\n",
    "        debug_alt = True\n",
    "    else:\n",
    "        debug_alt = False\n",
    "        \n",
    "    # Sort the entities by their dimtag\n",
    "    old_entities_dimtags = extract_dimtags_list(old_entities_dimtags)\n",
    "    new_entities_dimtags = extract_dimtags_list(new_entities_dimtags)\n",
    "    old_entities_dimtags = sorted(old_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "    new_entities_dimtags = sorted(new_entities_dimtags, key=lambda x: (x[0], x[1]))\n",
    "    \n",
    "    # Create a list of lists of dimtags by dimension\n",
    "    old_entities_by_dim = [[] for _ in range(4)]\n",
    "    new_entities_by_dim = [[] for _ in range(4)]\n",
    "    for dimtag in old_entities_dimtags:\n",
    "        old_entities_by_dim[dimtag[0]].append(dimtag)\n",
    "    for dimtag in new_entities_dimtags:\n",
    "        # Verify that the dimtag exists in occ\n",
    "        try:\n",
    "            gmsh.model.getPhysicalGroupsForEntity(dimtag[0], dimtag[1])  # This will raise an error if the entity does not exist\n",
    "            new_entities_by_dim[dimtag[0]].append(dimtag)\n",
    "        except Exception as e:\n",
    "            if debug or DEBUG:\n",
    "                print(f\"[DEBUG] Entity {dimtag} does not exist in GMSH: {e}\")\n",
    "    \n",
    "    # Solve the assignment problem for each dimension\n",
    "    assignment_results = []\n",
    "    for dim in range(4):\n",
    "        assignment_results.append(dimtags_assignment(old_entities_by_dim[dim], new_entities_by_dim[dim], debug=debug_alt))\n",
    "    \n",
    "    # Create the complete solution\n",
    "    row_ind = []\n",
    "    col_ind = []\n",
    "    for dim in range(4):\n",
    "        row_ind += [i + sum(len(old_entities_by_dim[d]) for d in range(dim)) for i in assignment_results[dim][0]]\n",
    "        col_ind += [i + sum(len(new_entities_by_dim[d]) for d in range(dim)) for i in assignment_results[dim][1]]\n",
    "    \n",
    "    # Solve the assignment problem using linear_sum_assignment\n",
    "    old_dimtags = [old_entities_dimtags[i] for i in row_ind]\n",
    "    new_dimtags = [new_entities_dimtags[i] for i in col_ind]\n",
    "    \n",
    "    # Get the index of the old entities in the Bible according to thir dimtags\n",
    "    old_index = []\n",
    "    for old_dimtag in old_dimtags:\n",
    "        # Get the index of the old entity in the Bible\n",
    "        filtered = Bible[Bible[\"dimtag_entity\"] == old_dimtag]\n",
    "        if not filtered.empty:\n",
    "            index = filtered.index[0]\n",
    "            old_index.append(int(index))\n",
    "        else:\n",
    "            raise ValueError(f\"Entity {old_dimtag} not found in Bible\")\n",
    "        \n",
    "    # Create a dataframe from the Bible containing : index, old dimtag, new dimtag, name, group name\n",
    "    df_assignment = pd.DataFrame({\n",
    "        \"old_index\": old_index,\n",
    "        \"old_dimtag\": old_dimtags,\n",
    "        \"new_dimtag\": new_dimtags,\n",
    "        \"old_entity_name\": [Bible.loc[i, \"entity_name\"] if i in Bible.index else None for i in old_index],\n",
    "        \"old_group_name\": [Bible.loc[i, \"group_name\"] if i in Bible.index else None for i in old_index],\n",
    "        \"old_group_dimtag\": [Bible.loc[i, \"dimtag_group\"] if i in Bible.index else None for i in old_index]\n",
    "    })\n",
    "    \n",
    "    # Delete the old groups\n",
    "    for i in range(len(row_ind)):\n",
    "        old_group_dimtag = df_assignment[\"old_group_dimtag\"][i]\n",
    "        if old_group_dimtag is not None:\n",
    "            for dimtag in old_group_dimtag:\n",
    "                if not delete_physical_groups(dimtag[0], dimtag[1], debug=debug):\n",
    "                    raise ValueError(f\"Failed to delete physical group {dimtag[1]} in GMSH\")\n",
    "    \n",
    "    if len(new_entities_dimtags) != len(old_entities_dimtags):\n",
    "        # Print the result of the assignment\n",
    "        print(f\"[DEBUG] Result of the assignment : {[f\"{old_entities_dimtags[i]} -> {new_entities_dimtags[j]}\" for i, j in zip(row_ind, col_ind)]}\")\n",
    "        print(old_index)\n",
    "        if debug:\n",
    "            # Save the old and new dimtags to a CSV file\n",
    "            dimtags_df = pd.DataFrame({\"Old_dimtag\": old_dimtags, \"New_dimtag\": new_dimtags})\n",
    "            dimtags_df.to_csv(\"dimtags.csv\", index=False)\n",
    "            # Save the assignment result to a CSV file\n",
    "            df_assignment.to_csv(\"assignment_result.csv\", index=False)\n",
    "        \n",
    "    # Loop through the assignment result\n",
    "    for i in range(len(row_ind)):\n",
    "        # Get the information from the assignment result\n",
    "        old_index = df_assignment[\"old_index\"][i]\n",
    "        old_dimtag = df_assignment[\"old_dimtag\"][i]\n",
    "        new_dimtag = df_assignment[\"new_dimtag\"][i]\n",
    "        old_entity_name = df_assignment[\"old_entity_name\"][i]\n",
    "        old_group_name = df_assignment[\"old_group_name\"][i]\n",
    "        group_name = None\n",
    "        \n",
    "        # Create the new group\n",
    "        new_group_dimtag = [(old_dimtag[0], start_tag + 1)]\n",
    "        start_tag += 1\n",
    "        \n",
    "        # Create the physical group in GMSH\n",
    "        if old_group_name is not None and old_group_name != []:\n",
    "            # Create the physical group in GMSH\n",
    "            group_name = old_group_name[0] if isinstance(old_group_name, list) else old_group_name\n",
    "            if not create_physical_group(dim=new_dimtag[0], tags=[new_dimtag[1]], name=group_name, group_tag=new_group_dimtag[0][1], debug=debug):\n",
    "                raise ValueError(f\"Failed to create physical group {group_name} in GMSH\")\n",
    "            gmsh.model.occ.synchronize()\n",
    "            \n",
    "        # Add the new entity to the Bible\n",
    "        add_to_bible(dimtag_entity=new_dimtag, dimtag_group=new_group_dimtag, group_name=group_name, entity_name=old_entity_name, overwrite=True, debug=debug)\n",
    "          \n",
    "    return Bible\n",
    "    \n",
    "def gmsh_function_preserve_physical_groups(operation_type, arguments, debug = False, ignore_dimtags=None, reassign_everything=True):\n",
    "    \"\"\"\n",
    "    Preserve physical groups after a boolean operation in GMSH.\n",
    "    \n",
    "    :param operation_type: Type of boolean operation ('union', 'difference', 'rotation').\n",
    "    :param arguments: Arguments for the boolean operation.\n",
    "    :return: Result of the boolean operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def concerned_entities_dimtags(object_dimtags, tools_dimtags=None, reassign_everything=reassign_everything):\n",
    "        \"\"\"\n",
    "        Get the concerned entities dimtags for a boolean operation.\n",
    "        :param object_dimtags: List of dimtags to consider.\n",
    "        :param tools_dimtags: List of tool dimtags to consider.\n",
    "        :return: List of concerned entities dimtags.\n",
    "        \"\"\"\n",
    "        # If we want to reassign everything, we need to get the entities in the model\n",
    "        if reassign_everything:\n",
    "            entities = gmsh.model.getEntities(3) + gmsh.model.getEntities(2)\n",
    "            entities = extract_dimtags_list(entities)\n",
    "            return entities\n",
    "        # If we don't want to reassign everything, we need to get the child entities of the object and tools\n",
    "        object_dimtags = extract_dimtags_list(object_dimtags)\n",
    "        child_objects = get_child_entities(object_dimtags, minimal_dim=2)\n",
    "        concerned_dimtags = object_dimtags + child_objects\n",
    "        if tools_dimtags is not None:\n",
    "            tools_dimtags = extract_dimtags_list(tools_dimtags)\n",
    "            child_tools = get_child_entities(tools_dimtags, minimal_dim=2)\n",
    "            concerned_dimtags = concerned_dimtags + tools_dimtags + child_tools + child_objects\n",
    "        concerned_dimtags = extract_dimtags_list(concerned_dimtags)\n",
    "        return concerned_dimtags      \n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Perform the boolean operation\n",
    "    if operation_type == \"fuse\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.fuse(first_arg, second_arg)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = concerned_entities_dimtags(result[0])\n",
    "    elif operation_type == \"cut\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.cut(first_arg, second_arg)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        boundaries = gmsh.model.getBoundary(result[0], oriented=False)\n",
    "        new_entities_dimtags = concerned_entities_dimtags(boundaries)\n",
    "    elif operation_type == \"rotate\":\n",
    "        # Extract the arguments \n",
    "        dimtags, x, y, z, ax, ay, az, angle = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(dimtags)\n",
    "        # Rotate the entities in the Bible\n",
    "        rotated_entity_to_tag_and_position = rotate_position(arguments)\n",
    "        result = gmsh.model.occ.rotate(dimtags, x, y, z, ax, ay, az, angle)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = old_entities_dimtags\n",
    "    elif operation_type == \"fragment\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.fragment(first_arg, second_arg, removeObject=True, removeTool=True)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = concerned_entities_dimtags(result[0])\n",
    "    elif operation_type == \"dilate\":\n",
    "        # Extract the arguments\n",
    "        dimtags, center_vector, scale_vector = arguments\n",
    "        x, y, z = center_vector\n",
    "        ax, ay, az = scale_vector\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(dimtags)\n",
    "        result = gmsh.model.occ.dilate(dimtags, x, y, z, ax, ay, az)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = old_entities_dimtags\n",
    "    elif operation_type == \"intersect\":\n",
    "        # Extract the arguments\n",
    "        first_arg, second_arg = arguments\n",
    "        # Get the dimtags of the entities\n",
    "        old_entities_dimtags = concerned_entities_dimtags(first_arg, second_arg)\n",
    "        result = gmsh.model.occ.intersect(first_arg, second_arg, removeObject=True, removeTool=True)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        new_entities_dimtags = concerned_entities_dimtags(result[0])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operation type. Use 'fuse', 'cut', or 'rotate'. Value used: {operation_type}\")\n",
    "    \n",
    "    \n",
    "    # Debug:\n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Operation type: {operation_type}\")\n",
    "        print(f\"[DEBUG] Arguments: {arguments}\")\n",
    "        print(f\"[DEBUG] Result: {result}\")\n",
    "        print(f\"[DEBUG] Old entities dimtags: {old_entities_dimtags}\")\n",
    "        print(f\"[DEBUG] New entities dimtags: {new_entities_dimtags}\")\n",
    "    \n",
    "    # If we need to ignore some dimtags, we need to remove them from the old entities dimtags\n",
    "    if ignore_dimtags is not None:\n",
    "        # Get the dimtags of the entities\n",
    "        ignore_dimtags = extract_dimtags_list(ignore_dimtags)\n",
    "        # Remove the dimtags from the old entities dimtags\n",
    "        old_entities_dimtags = [dimtag for dimtag in old_entities_dimtags if dimtag not in ignore_dimtags]\n",
    "\n",
    "    # We need to recover the group entities and names via positions\n",
    "    recover_group_entities_and_names_via_positions(old_entities_dimtags, new_entities_dimtags, debug=debug)\n",
    "    return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "76581721",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Diverse elements creator === ###\n",
    "\n",
    "def create_tube(radius, X_position, thickness, name_prefix=\"tube\", exterior_name=None, debug=False):\n",
    "    \"\"\"\n",
    "    Create only the lateral surface of a tube (no volume, no end caps).\n",
    "    Returns the tag of the lateral surface.\n",
    "    \"\"\"\n",
    "    global start_tag\n",
    "    global Bible\n",
    "\n",
    "    # Create the base disk\n",
    "    disk = gmsh.model.occ.addDisk(X_position, 0, 0, radius, radius)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    # Rotate disk to align with X axis\n",
    "    gmsh.model.occ.rotate([(2, disk)], X_position, 0, 0, 0, 1, 0, np.pi/2)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # Extrude to get the lateral surface (returns [top, volume, lateral])\n",
    "    volume = gmsh.model.occ.extrude([(2, disk)], thickness, 0, 0)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    # The lateral surface is volume[2][1]\n",
    "    lateral_surface = volume[2][1]\n",
    "    tag = start_tag\n",
    "    if exterior_name is None:\n",
    "        exterior_name = name_prefix + \"_Outer\"\n",
    "\n",
    "    # Create the physical group for the lateral surface\n",
    "    if not create_physical_group(dim=2, tags=[lateral_surface], name=exterior_name, group_tag=1 + start_tag, debug=debug):\n",
    "        raise ValueError(f\"Failed to create physical group {exterior_name} in GMSH\")\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"[DEBUG] Tube lateral surface created, tag={lateral_surface}, name={exterior_name}\")\n",
    "\n",
    "    return [(2, lateral_surface)]\n",
    "\n",
    "def create_plane(X, D, name=\"plane\"):\n",
    "    \"\"\"Create a plane using GMSH.\"\"\"\n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create a disk using GMSH\n",
    "    plane = gmsh.model.occ.addDisk(X, 0, 0, D, D)  # Adjusted radius to D_max / 2\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Rotate the disk 90 degrees on the Y axis\n",
    "    gmsh.model.occ.rotate([(2, plane)], X, 0, 0, 0, 1, 0, np.pi/2)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create a physical group for the disk\n",
    "    gmsh.model.addPhysicalGroup(2, [plane], tag=1 + start_tag)\n",
    "    gmsh.model.setPhysicalName(2, 1 + start_tag, name)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Actualize the start tag\n",
    "    start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((2, plane), name_overwrite=name)\n",
    "    \n",
    "    return plane  # Return the tag of the created volume\n",
    "    \n",
    "def fragments_entity_axis_X(entity_to_fragment, X_positions, Diameter, new_name=\"Fragment_\"):\n",
    "    \"\"\"Fragment an entity along the X-axis using GMSH.\"\"\"\n",
    "    global start_tag\n",
    "    \n",
    "    #Get group tag of the entity\n",
    "    group_tag = group_tags_via_entity_tag(entity_to_fragment)[0]\n",
    "    \n",
    "    # Create planes for fragmentation\n",
    "    for n in range(len(X_positions)):\n",
    "        X = X_positions[n]\n",
    "        plane = create_plane(X, Diameter, name=f\"Plane_{n}\")\n",
    "    # Get the tags of the planes via their group\n",
    "    planes = entities_tags_via_group_name(group_name=\"Plane_\")\n",
    "    if DEBUG:\n",
    "        print(f\"Planes for fragmentation: {planes}\")\n",
    "        \n",
    "    # Get the group name of the entity to fragment\n",
    "    concerned_groups = [group_name_via_tags(entity_to_fragment)[0]]\n",
    "    \n",
    "    # Perform the fragmentation\n",
    "    if DEBUG:\n",
    "        print(f\"Entity to fragment: {entity_to_fragment}\")\n",
    "        print(f\"Group tag of the entity to fragment: {group_tag}\")\n",
    "        print(f\"Concerned groups: {concerned_groups}\")\n",
    "    fragments = gmsh_function_preserve_physical_groups(\"fragment\", [[entity_to_fragment], planes, new_name, \"Plane_\"], concerned_entities=\"\") #concerned_groups)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # We need to delete the old group and entities\n",
    "    gmsh.model.removePhysicalGroups([group_tag])    \n",
    "    gmsh.model.occ.synchronize()\n",
    "    delete_entity([entity_to_fragment])\n",
    "    gmsh.model.occ.synchronize()\n",
    "    deleted_entities = delete_entities_without_physical_group()\n",
    "    if DEBUG:\n",
    "        print(f\"Deleted entities: {deleted_entities}\")\n",
    "        \n",
    "    #We delete the planes and their groups\n",
    "    delete_entities_with_physical_group(planes)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # We clean\n",
    "    delete_entities_without_physical_group()\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    return fragments\n",
    "\n",
    "def create_line(A_coord, B_coord, name=\"Line\", create_group=False, A_Tag=None, B_Tag=None):\n",
    "    \"\"\"Create a line using GMSH.\"\"\"\n",
    "    \n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible   \n",
    "    \n",
    "    # Correct the coordinates to be 3D\n",
    "    if len(A_coord) != 3:\n",
    "        A_coord = [A_coord[0], A_coord[1], 0]\n",
    "    if len(B_coord) != 3:\n",
    "        B_coord = [B_coord[0], B_coord[1], 0]\n",
    "        \n",
    "    # Create points using GMSH\n",
    "    if A_Tag is None:\n",
    "        A = gmsh.model.occ.addPoint(A_coord[0], A_coord[1], A_coord[2])\n",
    "        A_Tag = A\n",
    "    if B_Tag is None:\n",
    "        B = gmsh.model.occ.addPoint(B_coord[0], B_coord[1], B_coord[2])\n",
    "        B_Tag = B\n",
    "\n",
    "    # Create a line using GMSH\n",
    "    line = gmsh.model.occ.addLine(A_Tag, B_Tag)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if create_group:\n",
    "        # Create a physical group for the line\n",
    "        gmsh.model.addPhysicalGroup(1, [line], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(1, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "        \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((1, line), name_overwrite=name)\n",
    "    \n",
    "    return line, A_Tag, B_Tag  # Return the tag of the created line\n",
    "\n",
    "def add_volume_by_faces(faces_tags, name=\"Volume_by_Faces\", sewing=False, debug=False):\n",
    "    \"\"\"Add a volume by faces.\"\"\"\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Create the volume by faces\n",
    "    surface_loop = gmsh.model.occ.addSurfaceLoop(faces_tags,start_tag, sewing=sewing)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create the volume\n",
    "    volume = gmsh.model.occ.addVolume([surface_loop], start_tag + 1)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    #Verify the volume\n",
    "    if volume is None:\n",
    "        raise Exception(f\"Failed to create the volume by faces with name {name}.\")\n",
    "    \n",
    "    # Create the physical group for the volume\n",
    "    if not create_physical_group(dim=3, tags=[volume], name=name, debug=debug):\n",
    "        raise Exception(f\"Failed to create the physical group for the volume {name}.\")\n",
    "    \n",
    "    return volume\n",
    "\n",
    "def create_bspline(points, name=\"BSpline\", create_group=False, A_Tag=None, B_Tag=None):\n",
    "    \"\"\"Create a B-spline curve using GMSH.\"\"\"\n",
    "    \n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    #Add the points to the GMSH model\n",
    "    points_tags = []\n",
    "    for i, point in enumerate(points):\n",
    "        if len(point) == 2:\n",
    "            point = [point[0], point[1], 0]\n",
    "        elif len(point) == 3:\n",
    "            point = [point[0], point[1], point[2]]\n",
    "        else:\n",
    "            raise ValueError(\"Each point must have 2 or 3 coordinates.\")\n",
    "        if i == 0:\n",
    "            if A_Tag is not None:\n",
    "                point_tag = A_Tag\n",
    "            else:\n",
    "                point_tag = gmsh.model.occ.addPoint(point[0], point[1], point[2])\n",
    "                A_Tag = point_tag\n",
    "        elif i == len(points) - 1:\n",
    "            if B_Tag is not None:\n",
    "                point_tag = B_Tag\n",
    "            else:\n",
    "                point_tag = gmsh.model.occ.addPoint(point[0], point[1], point[2])\n",
    "                B_Tag = point_tag\n",
    "        else:\n",
    "            point_tag = gmsh.model.occ.addPoint(point[0], point[1], point[2])\n",
    "        points_tags.append(point_tag)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create a B-spline curve using GMSH\n",
    "    bspline = gmsh.model.occ.addBSpline(points_tags)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if create_group:\n",
    "        # Create a physical group for the B-spline\n",
    "        gmsh.model.addPhysicalGroup(2, [bspline], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(2, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((1, bspline), name_overwrite=name)\n",
    "    \n",
    "    return bspline, A_Tag, B_Tag  # Return the tag of the created B-spline\n",
    "\n",
    "def create_curveloop(tags, name=\"CurveLoop\", create_group=False):\n",
    "    \"\"\"Create a curve loop using GMSH.\"\"\"\n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "\n",
    "    # Create a curve loop using GMSH\n",
    "    curve_loop = gmsh.model.occ.addCurveLoop(tags)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if create_group:\n",
    "        # Create a physical group for the curve loop\n",
    "        gmsh.model.addPhysicalGroup(1, [curve_loop], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(1, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((1, curve_loop), name_overwrite=name)\n",
    "    \n",
    "    return curve_loop  # Return the tag of the created curve loop\n",
    "\n",
    "def create_plane_surface(tags, name=\"PlaneSurface\", create_group=False):\n",
    "    \"\"\"Create a plane surface using GMSH.\"\"\"\n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create a plane surface using GMSH\n",
    "    try:\n",
    "        plane_surface = gmsh.model.occ.addPlaneSurface(tags)\n",
    "    except Exception as e:\n",
    "        plane_surface = gmsh.model.occ.addSurfaceFilling(tags[0])\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Verify the plane surface\n",
    "    if plane_surface is None:\n",
    "        raise ValueError(\"Error: Plane surface creation failed. Please check the input tags.\")\n",
    "    \n",
    "    # Create a physical group for the plane surface\n",
    "    if create_group:\n",
    "        # Create a physical group for the plane surface\n",
    "        gmsh.model.addPhysicalGroup(2, [plane_surface], tag=1 + start_tag)\n",
    "        gmsh.model.setPhysicalName(2, 1 + start_tag, name)\n",
    "        gmsh.model.occ.synchronize()\n",
    "        \n",
    "        # Actualize the start tag\n",
    "        start_tag += 1\n",
    "    \n",
    "    # Actualize the bible\n",
    "    correct_bible_gmsh_by_entity((2, plane_surface), name_overwrite=name)\n",
    "    \n",
    "    return plane_surface  # Return the tag of the created plane surface\n",
    "\n",
    "def create_plane_4_points(points, points_tags = None, name=\"PlaneSurface\", debug=False):\n",
    "    \"\"\"Create a plane surface using 4 points in GMSH.\"\"\"\n",
    "    \n",
    "    # Get start tag\n",
    "    global start_tag\n",
    "    # Get the bible\n",
    "    global Bible\n",
    "    \n",
    "    if len(points) != 4:\n",
    "        raise ValueError(\"Error: You must provide exactly 4 points to create a plane surface.\")\n",
    "    if points_tags is not None:\n",
    "        if len(points) != len(points_tags) and points_tags:\n",
    "            raise ValueError(\"Error: The number of points must match the number of point tags.\")\n",
    "    \n",
    "    # Create lines between the points\n",
    "    lines = []\n",
    "    for i in range(4):\n",
    "        if points_tags is not None:\n",
    "            A_Tag = points_tags[i]\n",
    "            B_Tag = points_tags[(i + 1) % 4]\n",
    "        else:\n",
    "            A_Tag = None\n",
    "            B_Tag = None\n",
    "        A_coord = points[i]\n",
    "        B_coord = points[(i + 1) % 4]  # Connect to the next point, wrapping around\n",
    "        line, _, _ = create_line(A_coord, B_coord, name=f\"Line_{i}\", create_group=False, A_Tag=A_Tag, B_Tag=B_Tag)\n",
    "        lines.append(line)\n",
    "    \n",
    "    # Create a curve loop from the lines\n",
    "    curve_loop = create_curveloop(lines, name=\"CurveLoop\", create_group=False)\n",
    "    \n",
    "    # Create a plane surface from the curve loop\n",
    "    plane_surface = create_plane_surface([curve_loop], name=name, create_group=True)\n",
    "    \n",
    "    return plane_surface  # Return the tag of the created plane surface\n",
    "    \n",
    "    \n",
    "def profile_gmsh_instruction(profile, reinforcement=False, name=None, create_group=False, A_Tag=None, B_Tag=None, debug=False):\n",
    "    \"\"\"This function will create the instruction to generate the profile in GMSH.\"\"\"\n",
    "        \n",
    "    # In case of a reinforcement, this is more complicated and need to be done in a different way\n",
    "    if reinforcement:\n",
    "        global number_of_points_profile\n",
    "        instructions = create_reinforcement_instructions(number_of_points_profile, debug=debug)\n",
    "        if debug:\n",
    "            print(f\"Instructions for reinforcement: {instructions}\")\n",
    "        return instructions\n",
    "    \n",
    "    # If the profile as 2 points, we can create a line, if it has at least 3 points, we can create a B-spline\n",
    "    if len(profile) == 2:\n",
    "        #create_line(A_coord, B_coord, name=\"Line\", create_group=False, A_Tag=None, B_Tag=None):\n",
    "        return [[\"line\", name, profile[0], profile[1], name, create_group, A_Tag, B_Tag]]\n",
    "    elif len(profile) >= 3:\n",
    "        #create_bspline(points, name=\"BSpline\", create_group=False, A_Tag=None, B_Tag=None)\n",
    "        return [[\"bspline\", name, profile, name, create_group, A_Tag, B_Tag]]\n",
    "    else:\n",
    "        print(\"Error: The profile must have at least 2 points.\")\n",
    "        return None\n",
    "\n",
    "def verify_instructions(instructions, proximity_tol=1e-5, debug=False):\n",
    "    '''\n",
    "    This function will verify the instructions to create the geometry.\n",
    "    It will check if the instructions are valid and if the points are in the right order.\n",
    "    It will also check their is no duplicate points.\n",
    "    '''\n",
    "    # Create a list of all the points\n",
    "    all_points = []\n",
    "    \n",
    "    # Check if instructions is a list and not empty\n",
    "    if not isinstance(instructions, list) or len(instructions) == 0:\n",
    "        raise ValueError(\"Instructions must be a non-empty list.\")\n",
    "\n",
    "    prev_end = None\n",
    "    start_points = []\n",
    "    for idx, instr in enumerate(instructions):\n",
    "        # Check instruction type\n",
    "        if not isinstance(instr, list) or len(instr) < 2:\n",
    "            raise ValueError(f\"Instruction at index {idx} is not valid: {instr}\")\n",
    "\n",
    "        instr_type = instr[0]\n",
    "        if instr_type not in [\"line\", \"bspline\"]:\n",
    "            raise ValueError(f\"Unknown instruction type '{instr_type}' at index {idx}.\")\n",
    "\n",
    "        # Check points for line\n",
    "        if instr_type == \"line\":\n",
    "            if len(instr) < 4:\n",
    "                raise ValueError(f\"Line instruction at index {idx} does not have enough arguments.\")\n",
    "            A, B = np.array(instr[2]), np.array(instr[3])\n",
    "            start_points.append(tuple(A))\n",
    "            all_points.append(tuple(A))\n",
    "            all_points.append(tuple(B))\n",
    "            if np.allclose(A, B, atol=proximity_tol):\n",
    "                raise ValueError(f\"Duplicate points in line at index {idx}: {A} and {B}\")\n",
    "            # Check consecutive instructions\n",
    "            if prev_end is not None and not np.allclose(prev_end, A, atol=proximity_tol):\n",
    "                raise ValueError(f\"Consecutive instructions at index {idx-1} and {idx} do not have matching points: {prev_end} != {A}\")\n",
    "            prev_end = B\n",
    "\n",
    "        # Check points for bspline\n",
    "        if instr_type == \"bspline\":\n",
    "            if len(instr) < 3:\n",
    "                raise ValueError(f\"BSpline instruction at index {idx} does not have enough arguments.\")\n",
    "            points = np.array(instr[2])\n",
    "            if len(points) < 3:\n",
    "                raise ValueError(f\"BSpline at index {idx} must have at least 3 points.\")\n",
    "            # Check for duplicate consecutive points\n",
    "            for i in range(1, len(points)):\n",
    "                if np.allclose(points[i], points[i-1], atol=proximity_tol):\n",
    "                    warning_text = f\"Duplicate consecutive points in bspline at index {idx}: {points[i-1]} and {points[i]}\"\n",
    "                    warnings.warn(warning_text, UserWarning)\n",
    "            start_points.append(tuple(points[0]))\n",
    "            all_points.extend([tuple(pt) for pt in points])\n",
    "            # Check consecutive instructions\n",
    "            if prev_end is not None and not np.allclose(prev_end, points[0], atol=proximity_tol):\n",
    "                raise ValueError(f\"Consecutive instructions at index {idx-1} and {idx} do not have matching points: {prev_end} != {points[0]}\")\n",
    "            prev_end = points[-1]\n",
    "\n",
    "    # Check for duplicate start points\n",
    "    seen = set()\n",
    "    for pt in start_points:\n",
    "        for seen_pt in seen:\n",
    "            if np.allclose(pt, seen_pt, atol=proximity_tol):\n",
    "                raise ValueError(f\"Duplicate start points found: {pt} and {seen_pt}\")\n",
    "        seen.add(pt)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Instructions verified: all checks passed.\")\n",
    "    return True\n",
    "    \n",
    "     \n",
    "def create_from_instructions(instructions, debug=False):\n",
    "    \"\"\"\n",
    "    Create a geometry from a list of instructions.\n",
    "    A list of instructions is always a continuity. \n",
    "    \n",
    "    :param instructions: List of instructions to create the geometry.\n",
    "    :return: list of outputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify the instructions\n",
    "    verify_instructions(instructions, debug=debug)\n",
    "    \n",
    "    entities_tags = []\n",
    "    points_tags = []\n",
    "    entities_names = []\n",
    "    \n",
    "    # Loop through the instructions\n",
    "    for i, instruction in enumerate(instructions):\n",
    "        type_instruction = instruction[0]\n",
    "        entity_name = instruction[1]\n",
    "        entities_names.append(entity_name)\n",
    "        arguments = instruction[2:]\n",
    "        \n",
    "        # We need to adapt the arguments to get a continuity of the tags\n",
    "        if i > 0 :\n",
    "            arguments[-2] = points_tags[-1] # Last point of the previous instruction for the first point of the current instruction            \n",
    "        if type_instruction == \"line\":\n",
    "            # Create a line\n",
    "            line, A_Tag, B_Tag = create_line(*arguments)\n",
    "            entities_tags.append(line)\n",
    "        elif type_instruction == \"bspline\":\n",
    "            # Create a B-spline\n",
    "            bspline, A_Tag, B_Tag = create_bspline(*arguments)\n",
    "            entities_tags.append(bspline)\n",
    "        else:\n",
    "            print(f\"Unknown instruction type: {type_instruction}\")\n",
    "            continue\n",
    "        \n",
    "        if i == 0:\n",
    "            # Add the first point to the list\n",
    "            points_tags.append(A_Tag)\n",
    "        else: \n",
    "            # Check if the first point of the current instruction is the same as the last point of the previous instruction\n",
    "            if points_tags[-1] != A_Tag:\n",
    "                print(f\"Warning: The first point of the current instruction is not the same as the last point of the previous instruction. {points_tags[-1]} != {A_Tag}\")\n",
    "        # Add the last point to the list\n",
    "        points_tags.append(B_Tag)\n",
    "    \n",
    "    return entities_tags, points_tags, entities_names\n",
    "\n",
    "def create_revolved_line(A, B, angle_revolution, surface_name=\"Revolved_Line\", debug=False):\n",
    "    \"\"\"Create a revolved line around the X-axis.\"\"\"\n",
    "    \n",
    "    # Get the start tag\n",
    "    global start_tag\n",
    "    \n",
    "    # Create the line\n",
    "    line = create_line(A, B, name=surface_name, create_group=False)\n",
    "    \n",
    "    # Revolve the line\n",
    "    revolved_line = gmsh.model.occ.revolve([(1, line[0])], 0, 0, 0, 1, 0, 0, angle_revolution)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Get the tag of the surface\n",
    "    surface_tag = [tag[1] for tag in revolved_line if isinstance(tag, tuple) and tag[0] == 2]\n",
    "\n",
    "    # Create the physical group for the revolved line\n",
    "    start_tag += 1\n",
    "    if revolved_line is None:\n",
    "        raise Exception(f\"Failed to create the revolved line {surface_name}.\")\n",
    "    if not create_physical_group(dim=2, tags=surface_tag, name=surface_name, debug=debug):\n",
    "        raise Exception(f\"Failed to create the physical group for the revolved line {surface_name}.\")\n",
    "    \n",
    "    return surface_tag\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9865a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Define the different profiles === ###\n",
    "\n",
    "def remove_invalid_points(profile, proximity_tol=min_carac_length/10):\n",
    "    \"\"\"\n",
    "    Remove invalid points from a profile based on proximity tolerance.\n",
    "    Points that are too close to each other will be removed.\n",
    "    \"\"\"\n",
    "    profile = np.array(profile, dtype=float)\n",
    "    if len(profile) < 2:\n",
    "        return profile  # No need to process if there are less than 2 points\n",
    "    \n",
    "    valid_profile = [profile[0]]  # Start with the first point\n",
    "    for i in range(1, len(profile)):\n",
    "        if not np.allclose(profile[i], valid_profile[-1], atol=proximity_tol):\n",
    "            valid_profile.append(profile[i])\n",
    "    valid_profile = np.array(valid_profile, dtype=float)\n",
    "    mask = np.all(np.isfinite(valid_profile), axis=1)  # Ensure all points are finite\n",
    "    result = valid_profile[mask]\n",
    "    return result\n",
    "\n",
    "def define_profiles_from_CSV():\n",
    "    global geometry_data\n",
    "    # We define the different profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Channel_Angle_Size, Channel_Number\n",
    "    global Channel_Angle_Size_Mean\n",
    "    global Angle_Size\n",
    "    global Radius_Study_Margin\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    global Channel_Width\n",
    "    global Channel_Number\n",
    "    \n",
    "    # Get the data\n",
    "    x = geometry_data[\"x\"]\n",
    "    y_nozzle_inner = geometry_data[\"nozzle inner wall\"].astype(float).values\n",
    "    y_nozzle_outer = geometry_data[\"nozzle outer wall\"].astype(float).values\n",
    "    y_channel_inner = geometry_data[\"channel inner wall\"].astype(float).values\n",
    "    y_channel_outer = geometry_data[\"channel outer wall\"].astype(float).values\n",
    "    y_channel_width = geometry_data[\"channel width\"].astype(float).values\n",
    "    y_channel_number = geometry_data[\"number channels\"].astype(float).values\n",
    "    \n",
    "    # We create the exterior limit profile via the max outside profile and the Radius Study Margin\n",
    "    y_exterior = np.full_like(x, np.max(y_nozzle_outer) + Radius_Study_Margin)\n",
    "    \n",
    "    #We create the center profile as a profile of height 0\n",
    "    y_center= np.zeros_like(x)\n",
    "    \n",
    "    # Create the profiles\n",
    "    Nozzle_Profile_Inner = remove_invalid_points(np.array([x[::-1], y_nozzle_inner[::-1]]).T)\n",
    "    Nozzle_Profile_Outer = remove_invalid_points(np.array([x, y_nozzle_outer]).T)\n",
    "    Channel_Profile_Inner = remove_invalid_points(np.array([x[::-1], y_channel_inner[::-1]]).T)\n",
    "    Channel_Profile_Outer = remove_invalid_points(np.array([x, y_channel_outer]).T)\n",
    "    Center_Profile = remove_invalid_points(np.array([x, y_center]).T)\n",
    "    Exterior_Profile = remove_invalid_points(np.array([x, y_exterior]).T)\n",
    "    \n",
    "    # Define the channel angle size and channel number\n",
    "    Channel_Angle_Size = [y_channel_width[i] / np.mean([y_channel_inner[i], y_channel_outer[i]]) for i in range(len(x))]\n",
    "    Channel_Angle_Size_Mean = np.mean(Channel_Angle_Size)\n",
    "    Channel_Number = int(np.mean(y_channel_number))\n",
    "    Channel_Width = np.array([x, y_channel_width]).T\n",
    "    Channel_Angle_Size = np.mean(Channel_Angle_Size)  # Use the mean value for the channel angle size    \n",
    "    \n",
    "    # Define other variables\n",
    "    Angle_Size = Nozzle_Angle_Revolution\n",
    "    \n",
    "    return True\n",
    "\n",
    "def plot_profiles(nozzle=False, channel=False):\n",
    "\n",
    "    # Get the profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    \n",
    "    # Plot the profiles\n",
    "    plt.figure()\n",
    "    plt.plot(Nozzle_Profile_Inner[:, 0], Nozzle_Profile_Inner[:, 1], label=\"Nozzle Inner Profile\", color='blue')\n",
    "    plt.plot(Nozzle_Profile_Outer[:, 0], Nozzle_Profile_Outer[:, 1], label=\"Nozzle Outer Profile\", color='red')\n",
    "    plt.plot(Channel_Profile_Inner[:, 0], Channel_Profile_Inner[:, 1], label=\"Channel Inner Profile\", color='green')\n",
    "    plt.plot(Channel_Profile_Outer[:, 0], Channel_Profile_Outer[:, 1], label=\"Channel Outer Profile\", color='orange')\n",
    "    plt.plot(Center_Profile[:, 0], Center_Profile[:, 1], label=\"Center Profile\", color='black', linestyle='--')\n",
    "    plt.plot(Exterior_Profile[:, 0], Exterior_Profile[:, 1], label=\"Exterior Profile\", color='gray', linestyle='--')\n",
    "    plt.title(\"Profiles of the Rocket Engine\")\n",
    "    plt.xlabel(\"X-axis\")\n",
    "    plt.ylabel(\"Y-axis\")\n",
    "    plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "    plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Add independent plots for nozzle and channel\n",
    "    if nozzle:\n",
    "        plt.figure()\n",
    "        plt.plot(Nozzle_Profile_Inner[:, 0], Nozzle_Profile_Inner[:, 1], label=\"Nozzle Inner Profile\", color='blue')\n",
    "        plt.plot(Nozzle_Profile_Outer[:, 0], Nozzle_Profile_Outer[:, 1], label=\"Nozzle Outer Profile\", color='red')\n",
    "        plt.plot(Center_Profile[:, 0], Center_Profile[:, 1], label=\"Center Profile\", color='black', linestyle='--')\n",
    "        plt.plot(Exterior_Profile[:, 0], Exterior_Profile[:, 1], label=\"Exterior Profile\", color='gray', linestyle='--')\n",
    "        plt.title(\"Nozzle Profiles\")\n",
    "        plt.xlabel(\"X-axis\")\n",
    "        plt.ylabel(\"Y-axis\")\n",
    "        plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    if channel:\n",
    "        plt.figure()\n",
    "        plt.plot(Channel_Profile_Inner[:, 0], Channel_Profile_Inner[:, 1], label=\"Channel Inner Profile\", color='green')\n",
    "        plt.plot(Channel_Profile_Outer[:, 0], Channel_Profile_Outer[:, 1], label=\"Channel Outer Profile\", color='orange')\n",
    "        plt.title(\"Channel Profiles\")\n",
    "        plt.xlabel(\"X-axis\")\n",
    "        plt.ylabel(\"Y-axis\")\n",
    "        plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "\n",
    "        # Add a circular plot showing all the possible channels with the angle size\n",
    "        plt.figure()\n",
    "        angle_positions = np.linspace(0, 2 * np.pi, Channel_Number, endpoint=False)\n",
    "        for i in range(Channel_Number):\n",
    "            start_angle = angle_positions[i]\n",
    "            # Draw the sector for each channel\n",
    "            points = np.array([\n",
    "                (np.cos(start_angle + a), np.sin(start_angle + a))\n",
    "                for a in np.linspace(0, Channel_Angle_Size_Mean, 100)\n",
    "            ])\n",
    "            plt.plot(points[:, 0], points[:, 1], color='green', alpha=0.5)\n",
    "        plt.title(\"Channel Angle Positions\")\n",
    "        plt.xlabel(\"X-axis\")\n",
    "        plt.ylabel(\"Y-axis\")\n",
    "        plt.axhline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.axvline(0, color='black', lw=0.5, ls='--')\n",
    "        plt.grid()\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def treat_the_profiles():\n",
    "    \n",
    "    # Get the profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    \n",
    "    # Get the information of the reinforcements\n",
    "    global Radial_Reinforcement_Density, Radial_Reinforcement_Number\n",
    "    global Radial_Reinforcement_Thickness, Radial_Reinforcement_Width\n",
    "    \n",
    "    # Get the information of the treatement\n",
    "    global number_of_points_profile, reduce_points_method, ratio_for_accel_points\n",
    "    global Cooling_Channel_Extension\n",
    "    global Nozzle_Modificator_Inner, Nozzle_Modificator_Outer\n",
    "    global Cooling_Channel_Modificator_Inner, Cooling_Channel_Modificator_Outer\n",
    "    \n",
    "    # Treat the cooling profiles by adding extensions at each end\n",
    "    Inner_Start_Cooling_Channel_Point = np.array([Channel_Profile_Inner[0][0] + Cooling_Channel_Extension, Channel_Profile_Inner[0][1]])\n",
    "    Inner_End_Cooling_Channel_Point = np.array([Channel_Profile_Inner[-1][0] - Cooling_Channel_Extension, Channel_Profile_Inner[-1][1]])\n",
    "    Outer_Start_Cooling_Channel_Point = np.array([Channel_Profile_Outer[0][0] - Cooling_Channel_Extension, Channel_Profile_Outer[0][1]])\n",
    "    Outer_End_Cooling_Channel_Point = np.array([Channel_Profile_Outer[-1][0] + Cooling_Channel_Extension, Channel_Profile_Outer[-1][1]])\n",
    "    Channel_Profile_Inner = np.vstack((Inner_Start_Cooling_Channel_Point, Channel_Profile_Inner, Inner_End_Cooling_Channel_Point))\n",
    "    Channel_Profile_Outer = np.vstack((Outer_Start_Cooling_Channel_Point, Channel_Profile_Outer, Outer_End_Cooling_Channel_Point))\n",
    "    \n",
    "    # Application of the potential modificators\n",
    "    Nozzle_Profile_Inner = profile_points_modificator(Nozzle_Profile_Inner, Nozzle_Modificator_Inner)\n",
    "    Nozzle_Profile_Outer = profile_points_modificator(Nozzle_Profile_Outer, Nozzle_Modificator_Outer)\n",
    "    Channel_Profile_Inner = profile_points_modificator(Channel_Profile_Inner, Cooling_Channel_Modificator_Inner)\n",
    "    Channel_Profile_Outer = profile_points_modificator(Channel_Profile_Outer, Cooling_Channel_Modificator_Outer)\n",
    "    Center_Profile = profile_points_modificator(Center_Profile, lambda x: 0*x)  # No modification for the center profile\n",
    "    Exterior_Profile = profile_points_modificator(Exterior_Profile, lambda x: 0*x)  # No modification for the exterior profile\n",
    "    \n",
    "    # Remove duplicates\n",
    "    Nozzle_Profile_Inner = remove_duplicate_points(Nozzle_Profile_Inner)\n",
    "    Nozzle_Profile_Outer = remove_duplicate_points(Nozzle_Profile_Outer)\n",
    "    Channel_Profile_Inner = remove_duplicate_points(Channel_Profile_Inner)\n",
    "    Channel_Profile_Outer = remove_duplicate_points(Channel_Profile_Outer)\n",
    "    Center_Profile = remove_duplicate_points(Center_Profile)\n",
    "    Exterior_Profile = remove_duplicate_points(Exterior_Profile)\n",
    "    \n",
    "    # Reduce the number of points\n",
    "    Nozzle_Profile_Inner = reduce_number_points_list(Nozzle_Profile_Inner, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Nozzle_Profile_Outer = reduce_number_points_list(Nozzle_Profile_Outer, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Channel_Profile_Inner = reduce_number_points_list(Channel_Profile_Inner, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Channel_Profile_Outer = reduce_number_points_list(Channel_Profile_Outer, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Center_Profile = reduce_number_points_list(Center_Profile, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    Exterior_Profile = reduce_number_points_list(Exterior_Profile, number_of_points_profile, ratio_for_accel_points, reduce_points_method)\n",
    "    \n",
    "    # Debug: plot all the profiles\n",
    "    if DEBUG:\n",
    "        plot_profiles()\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def generate_profiles(debug=False):\n",
    "    \"\"\"Create the profiles of the rocket engine.\"\"\"\n",
    "    \n",
    "\n",
    "    # Define the profiles from the CSV file\n",
    "    define_profiles_from_CSV()\n",
    "    print(\"Profiles defined from CSV file.\")\n",
    "    \n",
    "    # Debug: plot the profiles\n",
    "    if debug:\n",
    "        plot_profiles(nozzle=True, channel=True)\n",
    "    \n",
    "    # Treat the profiles\n",
    "    treat_the_profiles()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "58362e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Create the reinforcement === ###\n",
    "\n",
    "def create_positions_reinforcement(debug=False, tol_factor=0.1):\n",
    "    \"\"\"Create the positions of the reinforcements.\"\"\"\n",
    "    # Get the parameters from the user\n",
    "    global X_Parameters_Nozzle\n",
    "    global Radial_Reinforcement_Number, Radial_Reinforcement_Density\n",
    "    global Radial_Reinforcement_Width\n",
    "    global Radial_Reinforcement_Margin_Entry, Radial_Reinforcement_Margin_Exit\n",
    "    \n",
    "    # Get the positions from the density\n",
    "    normalized_positions = positions_from_density(Radial_Reinforcement_Density, Radial_Reinforcement_Number, debug=debug)\n",
    "    # Unnormalize the positions\n",
    "    start_positions = X_Parameters_Nozzle[0] + Radial_Reinforcement_Margin_Entry\n",
    "    end_positions = X_Parameters_Nozzle[2] - Radial_Reinforcement_Margin_Exit - Radial_Reinforcement_Width # The noramlized positions are the start positions\n",
    "    reinforcement_start_positions = normalized_positions * (end_positions - start_positions) + start_positions\n",
    "    reinforcement_end_positions = reinforcement_start_positions + Radial_Reinforcement_Width\n",
    "    \n",
    "    # Verify and correct any overlaps\n",
    "    for i in range(len(reinforcement_start_positions) - 1):\n",
    "        if reinforcement_end_positions[i] > reinforcement_start_positions[i + 1]:\n",
    "            # Overlap detected, adjust the end position of the current reinforcement\n",
    "            reinforcement_end_positions[i] = reinforcement_start_positions[i + 1] - Radial_Reinforcement_Width * tol_factor\n",
    "    \n",
    "    # Create the list of start, end for the reinforcements\n",
    "    reinforcement_positions = [(reinforcement_start_positions[i], reinforcement_end_positions[i]) for i in range(len(reinforcement_start_positions))]\n",
    "    \n",
    "    return reinforcement_positions\n",
    "\n",
    "def profile_to_bspline_instruction(profile_func, start, end, points_number, name=None, create_group=False):\n",
    "    \"\"\"Create the instruction to generate the profile in GMSH.\"\"\"\n",
    "    \n",
    "    # Get the list of points\n",
    "    x = np.linspace(start, end, points_number)\n",
    "    y = profile_func(x)\n",
    "    points = np.array([x, y]).T\n",
    "    \n",
    "    # Remove duplicates\n",
    "    points = remove_duplicate_points(points)\n",
    "    \n",
    "    # Create the instruction for the profile\n",
    "    instructions = profile_gmsh_instruction(points, reinforcement=False, name=name, create_group=create_group)\n",
    "    \n",
    "    return instructions\n",
    "\n",
    "def create_instruction_one_reinforcement(reinforcement_position, reinforcement_number, number_points, profile_func, debug=False):\n",
    "    \"\"\"Create the instruction for one reinforcement.\"\"\"\n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Outer\n",
    "    global Radial_Reinforcement_Height\n",
    "    \n",
    "    # Get the start and end positions of the reinforcement\n",
    "    start_position = reinforcement_position[0]\n",
    "    end_position = reinforcement_position[1]\n",
    "    \n",
    "    # Create the four points for the reinforcement\n",
    "    A = np.array([start_position, profile_func(start_position)])\n",
    "    B = np.array([start_position, profile_func(start_position) + Radial_Reinforcement_Height])\n",
    "    C = np.array([end_position, profile_func(end_position) + Radial_Reinforcement_Height])    \n",
    "    D = np.array([end_position, profile_func(end_position)])\n",
    "    \n",
    "    # Create the profile function for the outer part\n",
    "    profile_func_outer = lambda x: profile_func(x) + Radial_Reinforcement_Height\n",
    "    \n",
    "    # Create the instruction for the start line of the reinforcement\n",
    "    instruction_front = profile_gmsh_instruction([A, B], reinforcement=False, name=f\"Reinforcement_{reinforcement_number}_Front\", create_group=False)\n",
    "    instruction_outer = profile_to_bspline_instruction(profile_func_outer, start_position, end_position, number_points, name=f\"Reinforcement_{reinforcement_number}_Outer\", create_group=False)\n",
    "    instruction_back = profile_gmsh_instruction([C, D], reinforcement=False, name=f\"Reinforcement_{reinforcement_number}_Back\", create_group=False)\n",
    "    \n",
    "    # We create the list of instructions\n",
    "    instructions_reinforcement = [instruction_front, instruction_outer, instruction_back]\n",
    "\n",
    "    # Debug: print the instructions\n",
    "    if debug:\n",
    "        print(f\"Reinforcement {reinforcement_number}:\")\n",
    "        print(f\"Start position: {A}\")\n",
    "        print(f\"End position: {D}\")\n",
    "        print(f\"Instructions: {instructions_reinforcement}\")\n",
    "    return instructions_reinforcement\n",
    "\n",
    "\n",
    "def create_reinforcement_instructions(number_of_points, debug=False):\n",
    "    \"\"\"Create the instructions for all the reinforcements.\"\"\"\n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Outer\n",
    "    global X_Parameters_Nozzle\n",
    "    global Radial_Reinforcement_Height, Radial_Reinforcement_Width\n",
    "    global Radial_Reinforcement_Margin_Entry, Radial_Reinforcement_Margin_Exit\n",
    "    global Radial_Reinforcement_Number, Radial_Reinforcement_Density\n",
    "    \n",
    "    # Get the positions of the reinforcements\n",
    "    reinforcement_positions = create_positions_reinforcement(debug=debug)\n",
    "    \n",
    "    # Create the profile function\n",
    "    profile_func = scipy.interpolate.interp1d(Nozzle_Profile_Outer[:, 0], Nozzle_Profile_Outer[:, 1], fill_value=\"extrapolate\")\n",
    "    \n",
    "    # Create the list of instructions\n",
    "    instructions_reinforcements = []\n",
    "    counter_outer = 1 # To name the sections of the Outer profile\n",
    "    \n",
    "    # We first create the instruction in case of entry margin\n",
    "    if Radial_Reinforcement_Margin_Entry > 0:\n",
    "        # Get the first point of the Nozzle profile\n",
    "        start_point = Nozzle_Profile_Outer[0]\n",
    "        first_reinforcement_position = reinforcement_positions[0]\n",
    "        # Create the instruction for the first reinforcement\n",
    "        instruction_entry_margin = profile_to_bspline_instruction(profile_func, start_point[0], first_reinforcement_position[0], number_of_points, name=\"Nozzle_Outer_Wall_\" + str(counter_outer), create_group=False)\n",
    "        instructions_reinforcements.append(instruction_entry_margin)\n",
    "        counter_outer += 1\n",
    "        \n",
    "    # Loop through the reinforcements\n",
    "    for i, reinforcement_position in enumerate(reinforcement_positions):\n",
    "        # Create the instruction for one reinforcement\n",
    "        instruction = create_instruction_one_reinforcement(reinforcement_position, i + 1, number_of_points, profile_func, debug=debug)\n",
    "        for inst in instruction:\n",
    "                instructions_reinforcements.append(inst)\n",
    "        # Create the instruction for inner sections if it is not the last one\n",
    "        if i < len(reinforcement_positions) - 1:\n",
    "            # Get the start and end positions of the next reinforcement\n",
    "            next_reinforcement_position = reinforcement_positions[i + 1]\n",
    "            # Create the instruction for the inner section\n",
    "            instruction_inner = profile_to_bspline_instruction(profile_func, reinforcement_position[1], next_reinforcement_position[0], number_of_points, name=\"Nozzle_Outer_Wall_\" + str(counter_outer), create_group=False)\n",
    "            instructions_reinforcements.append(instruction_inner)\n",
    "            counter_outer += 1\n",
    "    \n",
    "    # We create the instruction in case of exit margin\n",
    "    if Radial_Reinforcement_Margin_Exit > 0:\n",
    "        # Get the last point of the Nozzle profile\n",
    "        end_point = Nozzle_Profile_Outer[-1]\n",
    "        last_reinforcement_position = reinforcement_positions[-1]\n",
    "        # Create the instruction for the last reinforcement\n",
    "        instruction_exit_margin = profile_to_bspline_instruction(profile_func, last_reinforcement_position[1], end_point[0], number_of_points, name=\"Nozzle_Outer_Wall_\" + str(counter_outer), create_group=False)\n",
    "        instructions_reinforcements.append(instruction_exit_margin)\n",
    "        \n",
    "    # Flatten the list of instructions\n",
    "    instructions_reinforcements = [item for sublist in instructions_reinforcements for item in sublist]\n",
    "    \n",
    "    # Debug: print the instructions\n",
    "    if debug:\n",
    "        print(f\"Reinforcement positions: {reinforcement_positions}\")\n",
    "        print(f\"Instructions for reinforcements: {instructions_reinforcements}\")\n",
    "        \n",
    "    return instructions_reinforcements\n",
    "   \n",
    "if False:\n",
    "    create_reinforcement_instructions(10, debug=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2474e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Create the curved element (GMSH)=== ###\n",
    "    \n",
    "def generate_minimal_curved_element(Type = \"Nozzle\", overwrite_start_tag=None, channel_number=None, \n",
    "                                    custom_inner = None, custom_outer = None, custom_angle = None, custom_name = None,\n",
    "                                    debug=False):\n",
    "    \"\"\"Generate the rocket engine geometry using GMSH.\"\"\"\n",
    "    \n",
    "    # Get the profiles\n",
    "    global Nozzle_Profile_Inner, Nozzle_Profile_Outer\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer\n",
    "    global Center_Profile, Exterior_Profile\n",
    "    \n",
    "    # Get the information of the reinforcements\n",
    "    global Radial_Reinforcement_Number\n",
    "    \n",
    "    # Get the angle size\n",
    "    global Nozzle_Angle_Revolution, Channel_Angle_Size\n",
    "    \n",
    "    \n",
    "    # We choose the datas according to the type of element\n",
    "    if Type == \"Nozzle\":\n",
    "        profile_inner = Nozzle_Profile_Inner\n",
    "        profile_outer = Nozzle_Profile_Outer\n",
    "        physical_group_prefix = \"Nozzle\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Cooling_Channel\":\n",
    "        profile_inner = Channel_Profile_Inner\n",
    "        profile_outer = Channel_Profile_Outer\n",
    "        physical_group_prefix = \"Cooling_Channel_\" + str(channel_number)\n",
    "        angle_revolution = Channel_Angle_Size\n",
    "    elif Type == \"Inner_Fluid\":\n",
    "        profile_inner = Center_Profile\n",
    "        profile_outer = Nozzle_Profile_Inner\n",
    "        physical_group_prefix = \"Inner_Fluid\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Outer_Fluid\":\n",
    "        profile_inner = Nozzle_Profile_Outer  # Reverse the outer profile for the inner volume\n",
    "        profile_outer = Exterior_Profile[::-1]\n",
    "        physical_group_prefix = \"Outer_Fluid\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Study_Volume\":\n",
    "        profile_inner = Center_Profile #  Nozzle_Profile_Inner[::-1]\n",
    "        profile_outer = Exterior_Profile[::-1]\n",
    "        physical_group_prefix = \"Study_Volume\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    elif Type == \"Custom\":\n",
    "        if custom_inner is None or custom_outer is None or custom_angle is None or custom_name is None:\n",
    "            print(\"Error: Custom profiles must be provided for 'Custom' type.\")\n",
    "            return False\n",
    "        profile_inner = custom_inner\n",
    "        profile_outer = custom_outer\n",
    "        physical_group_prefix = custom_name\n",
    "        angle_revolution = custom_angle\n",
    "    else:\n",
    "        print(\"Error: Invalid Type specified. Please choose from 'Nozzle', 'Cooling_Channel', 'Inner_Fluid', 'Outer_Fluid', 'Study_Volume', or 'Custom'.\")\n",
    "        print(\"By default, the Nozzle is used.\")\n",
    "        profile_inner = Nozzle_Profile_Inner\n",
    "        profile_outer = Nozzle_Profile_Outer\n",
    "        physical_group_prefix = \"Nozzle\"\n",
    "        angle_revolution = Nozzle_Angle_Revolution\n",
    "    \n",
    "    \n",
    "    #Get the start tag\n",
    "    if overwrite_start_tag is None:\n",
    "        global start_tag\n",
    "    else:\n",
    "        start_tag = overwrite_start_tag\n",
    "    \n",
    "    # If their is a reinforcement, we do not need to use gmsh to create the outer profile for a nozzle type\n",
    "    if Type in [\"Nozzle\", \"Outer_Fluid\"]and Radial_Reinforcement_Number > 0:\n",
    "        reinforcement_to_create = True\n",
    "    else:\n",
    "        reinforcement_to_create = False\n",
    "    \n",
    "    # We create the list of instructions to create the profiles\n",
    "    if Type == \"Outer_Fluid\":\n",
    "        instructions_inner = profile_gmsh_instruction(profile_inner, reinforcement=reinforcement_to_create, name=physical_group_prefix + \"_Inner_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "        instructions_outer = profile_gmsh_instruction(profile_outer, reinforcement=False, name=physical_group_prefix + \"_Outer_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "    else:\n",
    "        instructions_inner = profile_gmsh_instruction(profile_inner, reinforcement=False, name=physical_group_prefix + \"_Inner_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "        instructions_outer = profile_gmsh_instruction(profile_outer, reinforcement=reinforcement_to_create, name=physical_group_prefix + \"_Outer_Wall\", create_group=False, A_Tag=None, B_Tag=None, debug=debug)\n",
    "    \n",
    "    # We follow the instructions to create the profiles\n",
    "    inner_entities_tags, inner_points_tags, inner_entities_names = create_from_instructions(instructions_inner, debug=debug)\n",
    "    outer_entities_tags, outer_points_tags, outer_entities_names = create_from_instructions(instructions_outer, debug=debug)\n",
    "    \n",
    "    # Get the tags of the first and last points of the inner and outer profiles\n",
    "    First_Inner_Tag = inner_points_tags[0]\n",
    "    Last_Inner_Tag = inner_points_tags[-1]\n",
    "    First_Outer_Tag = outer_points_tags[0]\n",
    "    Last_Outer_Tag = outer_points_tags[-1]\n",
    "\n",
    "    # Create the instructions to create the lines without forgetting that the inner profile is reversed\n",
    "    instructions_line_entry = [[\"line\", physical_group_prefix + \"_Entry_Wall\", profile_inner[-1], profile_outer[0], physical_group_prefix + \"_Entry_Wall\", False, Last_Inner_Tag, First_Outer_Tag]]\n",
    "    instructions_line_exit = [[\"line\", physical_group_prefix + \"_Exit_Wall\", profile_outer[-1], profile_inner[0], physical_group_prefix + \"_Exit_Wall\", False, Last_Outer_Tag, First_Inner_Tag]]\n",
    "    \n",
    "    # We follow the instructions to create the lines\n",
    "    line_entry_tags, line_entry_points_tags, line_entry_entities_names = create_from_instructions(instructions_line_entry, debug=debug)\n",
    "    line_exit_tags, line_exit_points_tags, line_exit_entities_names = create_from_instructions(instructions_line_exit, debug=debug)\n",
    "    \n",
    "    # Create the arrays of tags and names\n",
    "    inner_entities_tag_name = np.array([(inner_entities_tags[n], inner_entities_names[n]) for n in range(len(inner_entities_tags))])\n",
    "    outer_entities_tag_name = np.array([(outer_entities_tags[n], outer_entities_names[n]) for n in range(len(outer_entities_tags))])\n",
    "    line_entry_tag_name = np.array([(line_entry_tags[n], line_entry_entities_names[n]) for n in range(len(line_entry_tags))])\n",
    "    line_exit_tag_name = np.array([(line_exit_tags[n], line_exit_entities_names[n]) for n in range(len(line_exit_tags))])\n",
    "    \n",
    "    # Create a closed loop for the profile\n",
    "    profile_loop_tags_names = np.concatenate((outer_entities_tag_name, line_exit_tag_name, inner_entities_tag_name, line_entry_tag_name))\n",
    "    profile_loop_tags = [tag if isinstance(tag, int) else tag[0] if isinstance(tag, (tuple, list)) and isinstance(tag[0], int) else int(tag) for tag, name in profile_loop_tags_names]\n",
    "    profile_loop = create_curveloop(profile_loop_tags, name=physical_group_prefix + \"_Profile_Loop\", create_group=False)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Profile loop tags: {profile_loop_tags}\")\n",
    "        print(f\"Profile loop names: {profile_loop_tags_names}\")\n",
    "    \n",
    "    # Debug: Check the created loop\n",
    "    if not profile_loop is not None:\n",
    "        raise Exception(\"Failed to create the profile loop.\")\n",
    "    \n",
    "    # Create a surface loop from the profile loop\n",
    "    surface_loop = create_plane_surface([profile_loop], name=physical_group_prefix + \"_Initial_Wall\", create_group=False)\n",
    "    initial_tag_name = [(surface_loop, physical_group_prefix + \"_Initial_Wall\")]\n",
    "    revolved_tag_name = [(None, physical_group_prefix + \"_Revolved_Wall\")]\n",
    "    volume_tag_name = np.concatenate((initial_tag_name, revolved_tag_name, profile_loop_tags_names))\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Debug: Check the created surface loop and print the tag_name\n",
    "    if surface_loop is None:\n",
    "        raise Exception(\"Failed to create the surface loop.\")\n",
    "    \n",
    "    \n",
    "    # Revolve the profile to create the 3D nozzle geometry using OCC\n",
    "    axis_origin = [0, 0, 0]  # Origin of the axis of revolution\n",
    "    axis_direction = [1, 0, 0]\n",
    "    ax, ay, az = axis_direction\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Axis of revolution: {axis_direction}\")\n",
    "        print(f\"Angle of revolution: {angle_revolution}\")\n",
    "        \n",
    "    # Revolve inner and outer curves\n",
    "    revolved_volume = gmsh.model.occ.revolve([(2, surface_loop)], *axis_origin, ax, ay, az, angle_revolution)\n",
    "    gmsh.model.occ.synchronize()    \n",
    "    \n",
    "    # Debug: Check the created volume\n",
    "    if not revolved_volume:\n",
    "        raise Exception(\"Failed to create the profile volume.\")\n",
    "    profile_volume = np.concatenate((np.array([(2, surface_loop)]), np.array(revolved_volume)))\n",
    "\n",
    "    # Create the different physical groups for the different walls\n",
    "    counter = 0\n",
    "    for i in range(len(profile_volume)):\n",
    "        # Get the tag and name of the surfaces of the volume\n",
    "        dim, tag = profile_volume[i]\n",
    "\n",
    "        if dim == 3:\n",
    "            \n",
    "            # Create a physical group for the volume\n",
    "            create_physical_group(dim=dim, tags=[tag], name=physical_group_prefix + \"_Volume\", debug=debug)\n",
    "            # Correct the bible\n",
    "            correct_bible_gmsh_by_entity((dim, tag), name_overwrite=physical_group_prefix + \"_Volume\")\n",
    "        elif dim == 2:\n",
    "            tag_surface, name_surface = volume_tag_name[counter]\n",
    "            counter += 1\n",
    "            if angle_revolution >=2*np.pi and (\"_Revolved_Wall\" in name_surface or \"_Initial_Wall\" in name_surface):\n",
    "                delete_entity([(2,tag_surface)])\n",
    "            else:\n",
    "                # Create a physical group for the surface\n",
    "                create_physical_group(dim=dim, tags=[tag], name=name_surface, debug=debug)\n",
    "                # Correct the bible\n",
    "                #correct_bible_gmsh_by_entity((dim, tag), name_overwrite=name_surface)\n",
    "                add_to_bible(dimtag_entity=(dim, tag), entity_name=name_surface)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Physical groups created: {gmsh.model.getPhysicalGroups(2)}\")\n",
    "    \n",
    "    return profile_volume\n",
    "    \n",
    "if False:\n",
    "    #Get rid of a past gmsh instance\n",
    "    try:\n",
    "        gmsh.finalize()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Initialize GMSH\n",
    "    GMSH_initialise()\n",
    "    # Initialize the Bible\n",
    "    global Bible\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Set the debug mode\n",
    "    DEBUG = True\n",
    "    # Define the start tag\n",
    "    start_tag = 1\n",
    "    \n",
    "    # Generate the profiles\n",
    "    generate_profiles()\n",
    "    \n",
    "    # Generate the curved element\n",
    "    generate_minimal_curved_element(Type=\"Nozzle\", overwrite_start_tag=1, debug=DEBUG)\n",
    "    \n",
    "    # Bible\n",
    "    #correct_bible_gmsh(debug=DEBUG)\n",
    "    save_bible(debug=DEBUG)\n",
    "    # Save in a file\n",
    "    gmsh.model.mesh.generate(3)\n",
    "    gmsh.write(\"test_curved_element.msh\")    \n",
    "    \n",
    "    # Finalize GMSH\n",
    "    gmsh.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "adb404c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Cooling channels positions === ###\n",
    "\n",
    "def create_cooling_channel_positions(debug=False):\n",
    "    \"\"\"Create the positions of the cooling channels.\"\"\"\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Channel_Number\n",
    "    global Cooling_Channel_Angle_Offset\n",
    "    global Channel_Angle_Size\n",
    "    global Channel_Angle_Size_Mean\n",
    "    global Nozzle_Angle_Revolution\n",
    "\n",
    "    # Create all the possible positions and consider the offset due to the angle size\n",
    "    angle_between_channels = 2 * np.pi / Channel_Number\n",
    "    possible_positions = np.array([i * angle_between_channels + Channel_Angle_Size_Mean / 2 - Nozzle_Angle_Revolution / 2 for i in range(Channel_Number)])\n",
    "\n",
    "    # Offset the positions to center them\n",
    "    cooling_channel_offset = Channel_Angle_Size / 2\n",
    "    possible_positions = (possible_positions - cooling_channel_offset) % (2 * np.pi)\n",
    "\n",
    "    # Offset the positions as the user wants\n",
    "    angle_between_channels = 2 * np.pi / Channel_Number\n",
    "    user_offset = Cooling_Channel_Angle_Offset * angle_between_channels\n",
    "    channel_positions = (possible_positions + user_offset) % (2 * np.pi)\n",
    "    \n",
    "    # Debug: print the positions\n",
    "    if DEBUG:\n",
    "        print(f\"Cooling channel positions: {channel_positions}\")\n",
    "        print(f\"Angle size: {Channel_Angle_Size}\")\n",
    "        print(f\"User offset: {user_offset}\")\n",
    "    return channel_positions\n",
    "\n",
    "def test_channel_positions(channel_positions, debug=False):\n",
    "    # Get the paramters from the user\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Channel_Angle_Size\n",
    "    \n",
    "    # Create the possible interval\n",
    "    total_angle_size = Nozzle_Angle_Revolution + Channel_Angle_Size\n",
    "    start_interval = - total_angle_size / 2 % (2 * np.pi)\n",
    "    end_interval = total_angle_size / 2 % (2 * np.pi)\n",
    "    \n",
    "    # Create the interval for the nozzle\n",
    "    if start_interval > end_interval:\n",
    "        interval_nozzle = [[start_interval, 2 * np.pi], [0, end_interval]]\n",
    "    else:\n",
    "        interval_nozzle = [[start_interval, end_interval]]\n",
    "    \n",
    "    # Create the overlap intervals\n",
    "    overlap_initial_interval = [float(start_interval - 2*Channel_Angle_Size/2), float(start_interval + 2*Channel_Angle_Size/2)]\n",
    "    overlap_revolved_interval = [float(end_interval - 2*Channel_Angle_Size/2), float(end_interval + 2*Channel_Angle_Size/2)]\n",
    "\n",
    "    # Debug: print the interval\n",
    "    if debug:\n",
    "        print(f\"Interval for the cooling channels: {interval_nozzle}\")\n",
    "        print(f\"Overlap initial interval: {overlap_initial_interval}\")\n",
    "        print(f\"Overlap revolved interval: {overlap_revolved_interval}\")\n",
    "        print(f\"Positions of the cooling channels: {channel_positions}\")\n",
    "        \n",
    "    # Create the list of indicators\n",
    "    indicators = []\n",
    "    overlap_initial = None ; overlap_revolved = None\n",
    "    for i in range(len(channel_positions)):\n",
    "        position = channel_positions[i]\n",
    "        # Check if the position is in the interval\n",
    "        for interval in interval_nozzle:\n",
    "            if interval[0] <= position <= interval[1]:\n",
    "                boolean = True\n",
    "                break\n",
    "            else:\n",
    "                boolean = False\n",
    "        indicators.append(boolean)\n",
    "        \n",
    "    # Get the number of cooling channels possible\n",
    "    number_channels_possible = sum(indicators)\n",
    "    \n",
    "    # Check each possible solution for overlaps\n",
    "    counter = 1\n",
    "    for i, position in enumerate(channel_positions):\n",
    "        # If the position is not possible, continue\n",
    "        if not indicators[i]:\n",
    "            continue\n",
    "        # Check if the position is in the overlap intervals\n",
    "        if (position >= overlap_initial_interval[0] and position <= overlap_initial_interval[1]):\n",
    "            overlap_initial = counter\n",
    "        if (position >= overlap_revolved_interval[0] and position <= overlap_revolved_interval[1]):\n",
    "            overlap_revolved = counter\n",
    "        counter += 1\n",
    "    \n",
    "    return indicators, overlap_initial, overlap_revolved\n",
    "\n",
    "\n",
    "def overlap_manager(channel_tag, type_overlap, debug=False):\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "\n",
    "    #Create the name of the face to change\n",
    "    if type_overlap == \"Revolved\":\n",
    "        old_face_name = str(f\"Cooling_Channel_{channel_tag}_Revolved_Wall\")\n",
    "        new_face_name = str(f\"Nozzle_Revolved_Wall_Alt\")\n",
    "    elif type_overlap == \"Initial\":\n",
    "        old_face_name = str(f\"Cooling_Channel_{channel_tag}_Initial_Wall\")\n",
    "        new_face_name = str(f\"Nozzle_Initial_Wall_Alt\")\n",
    "    else:\n",
    "        raise ValueError(\"Type of overlap must be 'Revolved' or 'Initial'.\")\n",
    "    \n",
    "    #Find the index of the face in the Bible\n",
    "    index = Bible[Bible[\"entity_name\"] == old_face_name].index\n",
    "    if index.empty:\n",
    "        raise ValueError(f\"Face {old_face_name} not found in the Bible.\")\n",
    "    \n",
    "    #Change the name of the face in the Bible\n",
    "    Bible.at[index[0], \"entity_name\"] = new_face_name\n",
    "    Bible.at[index[0], \"group_name\"] = new_face_name\n",
    "     \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "470e152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Create Cooling Channels === ###\n",
    "\n",
    "def create_exact_cooling_channel(channel_number=1, angle_position=None, old_angle_calculation = False, debug=False):\n",
    "    \"\"\"\n",
    "    Create an exact 3D cooling channel using addThruSections.\n",
    "    Each section is made of 4 B-splines: outer, entry, inner, exit.\n",
    "    \"\"\"\n",
    "    global Channel_Profile_Inner, Channel_Profile_Outer, Channel_Width\n",
    "\n",
    "    prefix = f\"Cooling_Channel_{channel_number+1}\"\n",
    "\n",
    "    # Generate 3D profiles (z = +/- width/2)\n",
    "    def place_to_position(point, angle):\n",
    "        if angle is None:\n",
    "            return point\n",
    "        point_polar = cartesian_to_polar_x_axis(point, 0)\n",
    "        point_polar_placed = [point_polar[0], point_polar[1] + angle, point_polar[2]]\n",
    "        return polar_to_cartesian(point_polar_placed, 0)\n",
    "    \n",
    "    inner_profile_1 = []\n",
    "    inner_profile_2 = []\n",
    "    outer_profile_1 = []\n",
    "    outer_profile_2 = []\n",
    "    for i in range(len(Channel_Profile_Inner)):\n",
    "        x_inner = Channel_Profile_Inner[i][0]\n",
    "        x_outer = Channel_Profile_Outer[i][0]\n",
    "        y_inner = Channel_Profile_Inner[i][1]\n",
    "        y_outer = Channel_Profile_Outer[i][1]\n",
    "        width = Channel_Width[i][1] / 2\n",
    "        \n",
    "        # Calculate the inner and outer widths\n",
    "        mean_radius = (y_outer + y_inner) / 2\n",
    "        inner_width = width\n",
    "        outer_width = width\n",
    "        if old_angle_calculation:\n",
    "            thales_factor_inner = y_inner / mean_radius - 1\n",
    "            thales_factor_outer = y_outer / mean_radius - 1\n",
    "            inner_width = width * (1 + thales_factor_inner)  #y_outer * thales_factor\n",
    "            outer_width = width * (1 + thales_factor_outer) #y_inner * thales_factor\n",
    "        \n",
    "        # Create the points for the profiles\n",
    "        inner_1_point = [x_inner, y_inner, -inner_width]\n",
    "        inner_2_point = [x_inner, y_inner, inner_width]\n",
    "        outer_1_point = [x_outer, y_outer, -outer_width]\n",
    "        outer_2_point = [x_outer, y_outer, outer_width]\n",
    "            \n",
    "        # Append points for the profiles\n",
    "        inner_profile_1.append(place_to_position(inner_1_point, angle_position))\n",
    "        inner_profile_2.append(place_to_position(inner_2_point, angle_position))\n",
    "        outer_profile_1.append(place_to_position(outer_1_point, angle_position))\n",
    "        outer_profile_2.append(place_to_position(outer_2_point, angle_position))\n",
    "\n",
    "    # Remove duplicates\n",
    "    def dedup(pts, tol=1e-8):\n",
    "        out = [pts[0]]\n",
    "        for p in pts[1:]:\n",
    "            if not np.allclose(p, out[-1], atol=tol):\n",
    "                out.append(p)\n",
    "        return out\n",
    "\n",
    "    inner_profile_1 = dedup(inner_profile_1)[::-1]  # Reverse inner profile for correct orientation\n",
    "    inner_profile_2 = dedup(inner_profile_2)[::-1]  # Reverse inner profile for correct orientation\n",
    "    outer_profile_1 = dedup(outer_profile_1)\n",
    "    outer_profile_2 = dedup(outer_profile_2)\n",
    "\n",
    "    # Helper to split a profile into 4 segments\n",
    "    def split_profile(outer, inner):\n",
    "        # Outer: 0..n-1, Entry: outer[n-1] to inner[n-1], Inner: n-1..0, Exit: inner[0] to outer[0]\n",
    "        outer_pts = outer\n",
    "        entry_pts = [outer[-1], inner[-1]]\n",
    "        inner_pts = inner[::-1]\n",
    "        exit_pts = [inner[0], outer[0]]\n",
    "        return outer_pts, entry_pts, inner_pts, exit_pts\n",
    "    s1_outer, s1_entry, s1_inner, s1_exit = split_profile(outer_profile_1, inner_profile_1)\n",
    "    s2_outer, s2_entry, s2_inner, s2_exit = split_profile(outer_profile_2, inner_profile_2)\n",
    "\n",
    "    # Create points and B-splines for each segment\n",
    "    def make_loop(outer, entry, inner, exit):\n",
    "        bs_outer = create_bspline(outer, name=f\"{prefix}_Outer_Wall\", create_group=False)\n",
    "        bs_entry = create_bspline(entry, name=f\"{prefix}_Entry_Wall\", create_group=False)\n",
    "        bs_inner = create_bspline(inner, name=f\"{prefix}_Inner_Wall\", create_group=False)\n",
    "        bs_exit = create_bspline(exit, name=f\"{prefix}_Exit_Wall\", create_group=False)\n",
    "        return [bs_outer[0], bs_entry[0], bs_inner[0], bs_exit[0]]\n",
    "\n",
    "    loop1_curves = make_loop(s1_outer, s1_entry, s1_inner, s1_exit)\n",
    "    loop2_curves = make_loop(s2_outer, s2_entry, s2_inner, s2_exit)\n",
    "    \n",
    "    loop1 = gmsh.model.occ.addCurveLoop(loop1_curves)\n",
    "    loop2 = gmsh.model.occ.addCurveLoop(loop2_curves)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Debug: plot the section if needed\n",
    "    if debug:\n",
    "        import matplotlib.pyplot as plt\n",
    "        from mpl_toolkits.mplot3d import Axes3D\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        for seg in [s1_outer, s1_entry, s1_inner, s1_exit]:\n",
    "            seg = np.array(seg)\n",
    "            ax.plot(seg[:,0], seg[:,1], seg[:,2])\n",
    "        for seg in [s2_outer, s2_entry, s2_inner, s2_exit]:\n",
    "            seg = np.array(seg)\n",
    "            ax.plot(seg[:,0], seg[:,1], seg[:,2])\n",
    "        plt.show()\n",
    "\n",
    "    #Create surfaces from the loops to ensure that the volume is created correctly\n",
    "    surface1 = gmsh.model.occ.addSurfaceFilling(loop1)  #create_plane_surface([loop1], name=f\"{prefix}_Initial_Wall\", create_group=False)\n",
    "    surface2 = gmsh.model.occ.addSurfaceFilling(loop2)  #create_plane_surface([loop2], name=f\"{prefix}_Revolved_Wall\", create_group=False)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    # Use addThruSections to generate the solid\n",
    "    volume = gmsh.model.occ.addThruSections([loop1, loop2], makeSolid=True)\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Create the group for the volume\n",
    "    create_physical_group(dim=3, tags=[volume[0][1]], name=f\"{prefix}_Volume\", debug=debug)\n",
    "    add_to_bible(dimtag_entity=(3, volume[0][1]), entity_name=f\"{prefix}_Volume\")\n",
    "    # Verify that the group is created\n",
    "    if not volume:\n",
    "        raise Exception(\"Failed to create the volume for the cooling channel.\")\n",
    "    if group_tags_via_group_name(f\"{prefix}_Volume\") is None:\n",
    "        raise Exception(f\"Failed to create the physical group for the cooling channel volume: {prefix}_Volume.\")\n",
    "    \n",
    "    # Create physical groups\n",
    "    volume_entities = get_child_entities(volume, minimal_dim=2, debug=debug)    \n",
    "    # Get the position of each entity of dim 2\n",
    "    entities_dimtag_position = [(dimtag, cartesian_to_polar_x_axis(entity_position(dimtag, use_gmsh=True), Angle=-angle_position)) for dimtag in volume_entities]\n",
    "    \n",
    "    # Now we manually chose the name for the groups\n",
    "    # THe entity with the lowest x is the entry wall, the one with the highest x is the exit wall\n",
    "    entities_dimtag_position = sorted(entities_dimtag_position, key=lambda x: x[1][0])\n",
    "    entry_dimtag = entities_dimtag_position[0][0]  # Entry wall\n",
    "    exit_dimtag = entities_dimtag_position[-1][0]  # Exit wall\n",
    "    # Delete the entry and exit from the list\n",
    "    entities_dimtag_position = [entry for entry in entities_dimtag_position if entry[0] not in (entry_dimtag, exit_dimtag)]\n",
    "    # The entity with the lowest theta is the initial wall, the one with the highest theta is the revolved wall\n",
    "    entities_dimtag_position = sorted(entities_dimtag_position, key=lambda x: x[1][1])\n",
    "    initial_dimtag = entities_dimtag_position[0][0]  # Initial wall\n",
    "    revolved_dimtag = entities_dimtag_position[-1][0]  # Revolved wall\n",
    "    # Delete the initial and revolved from the list\n",
    "    entities_dimtag_position = [entry for entry in entities_dimtag_position if entry[0] not in (initial_dimtag, revolved_dimtag)]\n",
    "    #The entity with the lowest r is the inner wall, the one with the highest r is the outer wall\n",
    "    entities_dimtag_position = sorted(entities_dimtag_position, key=lambda x: x[1][2])\n",
    "    outer_dimtag = entities_dimtag_position[0][0]  # Inner wall\n",
    "    inner_dimtag = entities_dimtag_position[-1][0]  # Outer wall\n",
    "    # Create the list of entities dimtag\n",
    "    volume_entities_dimtag = [\n",
    "        (entry_dimtag, f\"{prefix}_Entry_Wall\"),\n",
    "        (exit_dimtag, f\"{prefix}_Exit_Wall\"),\n",
    "        (outer_dimtag, f\"{prefix}_Outer_Wall\"),\n",
    "        (initial_dimtag, f\"{prefix}_Initial_Wall\"),\n",
    "        (inner_dimtag, f\"{prefix}_Inner_Wall\"),\n",
    "        (revolved_dimtag, f\"{prefix}_Revolved_Wall\")\n",
    "    ]\n",
    "\n",
    "    # Create the physical groups for each entity\n",
    "    for dimtag, name in volume_entities_dimtag:\n",
    "        create_physical_group(dim=dimtag[0], tags=[dimtag[1]], name=name, debug=debug)\n",
    "        #Actualize the Bible\n",
    "        add_to_bible(dimtag_entity=dimtag, entity_name=name)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Entities dimtag position: {entities_dimtag_position}\")    \n",
    "        \n",
    "    return volume\n",
    "\n",
    "def create_cooling_channels(debug=False, indicators_for_possible_channels = None):\n",
    "    \"\"\"Create the cooling channels.\"\"\"\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Channel_Number\n",
    "    global Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Create the positions of the cooling channels\n",
    "    channel_positions = create_cooling_channel_positions()\n",
    "    \n",
    "    # If we want to keep only the possible positions, we need to verify the positions\n",
    "    if indicators_for_possible_channels is None:\n",
    "        indicators = [True] * Channel_Number\n",
    "    else:\n",
    "        indicators = indicators_for_possible_channels\n",
    "    \n",
    "    # Get the current time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create the cooling channels\n",
    "    cooling_channels = []\n",
    "    channel_number = 0\n",
    "    total_channels_to_do = sum(indicators)\n",
    "    \n",
    "    for i in range(Channel_Number):\n",
    "        # Check if the position is possible\n",
    "        if not indicators[i]:\n",
    "            if debug:\n",
    "                print(f\"Cooling channel {i} is not possible. Skipping.\")\n",
    "            continue     \n",
    "        \n",
    "        channel_position = channel_positions[i]\n",
    "        channel_tag = create_exact_cooling_channel(channel_number, channel_position, debug=debug)\n",
    "        channel_number += 1\n",
    "\n",
    "        # Check if the channel tag is valid\n",
    "        if channel_tag is None:\n",
    "            raise ValueError(f\"Failed to create cooling channel {i} with position {channel_position}.\")\n",
    "        # Add the channel tag to the list\n",
    "        for n in range(len(channel_tag)):\n",
    "            cooling_channels.append(channel_tag[n])\n",
    "        \n",
    "        print(f\"=== Cooling channel {i + 1} out of {total_channels_to_do} created with tag: {channel_tag}===\")\n",
    "        # Debug: calculate remaining time\n",
    "        if debug:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            remaining_time = (elapsed_time / (i + 1)) * (Channel_Number - i - 1)\n",
    "            print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "            print(f\"Estimated remaining time: {remaining_time:.2f} seconds\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    return cooling_channels\n",
    "   \n",
    "def add_cooling_channels(nozzle_tag, cooling_channels_tags, overlap_initial_id = None, overlap_revolved_id = None, debug=False):\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Extract the tag of the nozzle\n",
    "    nozzle_volume_tags = extract_dimtags_list(nozzle_tag, dim=3)\n",
    "    print(f\"Nozzle volume tags: {nozzle_volume_tags}\")\n",
    "        \n",
    "    # Extract from the cooling channels tags the volume tags\n",
    "    cooling_channels_tags = extract_dimtags_list(cooling_channels_tags, dim=3)\n",
    "    print(f\"Cooling channels tags: {cooling_channels_tags}\")\n",
    "    \n",
    "    # Verify that their is at least one tag\n",
    "    if not cooling_channels_tags:\n",
    "        print(\"No cooling channels tags found ! Adding cooling channels failed.\")\n",
    "        return None\n",
    "    \n",
    "    # Recover the dimtags of entry and exit of cooling channels\n",
    "    number_cooling_channels = len(extract_dimtags_list(cooling_channels_tags, dim=3))\n",
    "    ignore_tags = []\n",
    "    filtered = Bible[\n",
    "        Bible[\"entity_name\"].str.contains(\"Cooling\", na=False) &\n",
    "        Bible[\"entity_name\"].str.contains(\"Entry|Exit\", na=False)\n",
    "    ]\n",
    "    ignore_tags = filtered[\"dimtag_entity\"].tolist()\n",
    "    \n",
    "    # Manage the overlap\n",
    "    if overlap_initial_id is not None:\n",
    "        # Add the faces to the Bible\n",
    "        if not overlap_manager(overlap_initial_id,\"Initial\", debug=debug):\n",
    "            print(\"Failed to add the Initial Wall faces to the Bible. Cannot add cooling channels.\")\n",
    "            return None\n",
    "    \n",
    "    if overlap_revolved_id is not None:\n",
    "        # Add the faces to the Bible\n",
    "        if not overlap_manager(overlap_revolved_id,\"Revolved\", debug=debug):\n",
    "            print(\"Failed to add the Revolved Wall faces to the Bible. Cannot add cooling channels.\")\n",
    "            return None\n",
    "    \n",
    "    ignore_tags = extract_dimtags_list(ignore_tags)\n",
    "    # Debug: print the ignore tags\n",
    "    if debug:\n",
    "        print(f\"Ignore tags for the boolean operation: {ignore_tags}\")\n",
    "    # Do the boolean operation\n",
    "    nozzle_with_cooling_channels = gmsh_function_preserve_physical_groups(\"cut\", [[(3, 1)], cooling_channels_tags], ignore_dimtags=ignore_tags, debug=debug)\n",
    "\n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Verify the result\n",
    "    if nozzle_with_cooling_channels is not None:\n",
    "        print(f\"Cooling channels added to the nozzle with the resulting tag: {nozzle_with_cooling_channels}\")\n",
    "    else:\n",
    "        print(\"Failed to add cooling channels to the nozzle.\")\n",
    "    \n",
    "    return nozzle_with_cooling_channels\n",
    "   \n",
    "if False:\n",
    "    # We debug the creation of a cooling channel\n",
    "    try:\n",
    "        gmsh.finalize()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Initialize GMSH\n",
    "    GMSH_initialise(caracteristic_length_min= min_carac_length/10)\n",
    "    # Initialize the Bible\n",
    "    global Bible\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Initialize profiles\n",
    "    generate_profiles()\n",
    "    \n",
    "    # Initialize start_tag\n",
    "    global start_tag\n",
    "    start_tag = 1\n",
    "    \n",
    "    # Set the debug mode\n",
    "    debug = True\n",
    "    \n",
    "    #create_exact_cooling_channel(channel_number=1, angle_position=0, debug=debug)\n",
    "    create_cooling_channels(debug=False, indicators_for_possible_channels=None)\n",
    "    gmsh.write(\"test_exact_cooling_channels.brep\")\n",
    "    # Save in a file\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    gmsh.model.occ.synchronize()   \n",
    "    gmsh.model.mesh.generate(3)\n",
    "    gmsh.write(\"test_exact_channel.msh\")\n",
    "    # Finalize GMSH\n",
    "    gmsh.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c73d8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Creators of the different volumes === ###  \n",
    "\n",
    "def create_inner_volume_via_revolution(debug=False):\n",
    "    \"\"\"Create the inner volume of the Nozzle via the same method as the creation of the Nozzle.\"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Inner, Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Create the inner volume\n",
    "    inner_volume = generate_minimal_curved_element(Type=\"Inner_Fluid\", overwrite_start_tag=None, debug=debug)\n",
    "    \n",
    "    #Extract the volume tag\n",
    "    inner_volume = extract_dimtags_list(inner_volume, dim=3)\n",
    "    \n",
    "    # Verify the result\n",
    "    if inner_volume is None:\n",
    "        raise Exception(\"Failed to create the inner volume of the Nozzle.\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    return inner_volume\n",
    "\n",
    "def create_exterior_volume_via_revolution(debug=False):\n",
    "    \"\"\"Create the outer volume of the Nozzle via the same method as the creation of the Nozzle.\"\"\"\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Get the parameters from the user\n",
    "    global Nozzle_Profile_Outer, Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Create the outer volume\n",
    "    outer_volume = generate_minimal_curved_element(Type=\"Outer_Fluid\", overwrite_start_tag=None, debug=debug)\n",
    "    \n",
    "    #Extract the volume tag\n",
    "    outer_volume = extract_dimtags_list(outer_volume, dim=3)\n",
    "    \n",
    "    # Verify the result\n",
    "    if outer_volume is None:\n",
    "        raise Exception(\"Failed to create the outer volume of the Nozzle.\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    return outer_volume\n",
    "\n",
    "def create_cooling_channels_boolean_tool(debug=False):\n",
    "    \"\"\"Create the volume that will cut the cooling chanels to get their volume.\"\"\"\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    # Get the varaibles\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Cooling_Channel_Extension\n",
    "    global Exterior_Profile\n",
    "    global X_Parameters_Nozzle\n",
    "    \n",
    "    # Create the study volume\n",
    "    study_volume = generate_minimal_curved_element(Type=\"Study_Volume\", debug=debug)\n",
    "    if study_volume is None: # or tube is None:\n",
    "        raise Exception(\"Failed to create the cooling channels boolean tool or the study volume.\")\n",
    "    \n",
    "    # Extract the tags\n",
    "    study_volume_tag = extract_dimtags_list(study_volume, dim=3)\n",
    "    \n",
    "    #Rotate the study volume to align it with the cooling channels\n",
    "    study_volume_rotated = gmsh_function_preserve_physical_groups(\"rotate\",[study_volume_tag, 0, 0, 0, 1, 0, 0, - Nozzle_Angle_Revolution / 2], debug=debug)\n",
    "    \n",
    "    return study_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "dea823a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Creator for U Channel for testing === ###\n",
    "\n",
    "def create_surface_from_N_points(points, name_surface=None, names_lines=None, create_group=True, debug=False):\n",
    "    \"\"\"\n",
    "    Create a surface from N points using existing functions.\n",
    "    \"\"\"\n",
    "    global start_tag\n",
    "\n",
    "    if len(points) < 3:\n",
    "        raise ValueError(\"At least 3 points are required to create a surface.\")\n",
    "\n",
    "    instructions = []\n",
    "    n = len(points)\n",
    "    for i in range(n):\n",
    "        A = points[i]\n",
    "        B = points[(i + 1) % n]\n",
    "        line_name = (names_lines[i] if names_lines and i < len(names_lines)\n",
    "                     else f\"{name_surface}_Line_{i}\" if name_surface else f\"Line_{i}\")\n",
    "        instructions.append([\"line\", line_name, A, B, line_name, False, None, None])\n",
    "\n",
    "    line_tags, point_tags, _ = create_from_instructions(instructions, debug=debug)\n",
    "    curve_loop_tag = create_curveloop(line_tags, name=f\"{name_surface}_CurveLoop\" if name_surface else \"CurveLoop\", create_group=False)\n",
    "    surface_tag = create_plane_surface([curve_loop_tag], name=name_surface or \"PlaneSurface\", create_group=create_group)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Created surface with tag: {surface_tag}, points: {point_tags}, lines: {line_tags}\")\n",
    "        print(f\"Start tag: {start_tag}\")\n",
    "    start_tag += 1\n",
    "    return surface_tag, point_tags, line_tags\n",
    "\n",
    "def volume_extrude_face(face_tag, extrusion_vector, name_volume=None, name_extruded_faces=None, create_group=True, debug=False):\n",
    "    \"\"\"\n",
    "    Extrude a face along a vector to create a volume.\n",
    "    \"\"\"\n",
    "    global start_tag\n",
    "\n",
    "    # Normalize face_tag to (2, tag)\n",
    "    if isinstance(face_tag, tuple) and len(face_tag) == 2:\n",
    "        face_dimtag = face_tag\n",
    "    elif isinstance(face_tag, int):\n",
    "        face_dimtag = (2, face_tag)\n",
    "    elif isinstance(face_tag, list) and len(face_tag) == 1:\n",
    "        if isinstance(face_tag[0], tuple) and len(face_tag[0]) == 2:\n",
    "            face_dimtag = face_tag[0]\n",
    "        else:\n",
    "            face_dimtag = (2, face_tag[0])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid face_tag: {face_tag}\")\n",
    "\n",
    "    extruded = gmsh.model.occ.extrude([face_dimtag], *extrusion_vector, numElements=[1], recombine=True)\n",
    "    gmsh.model.occ.synchronize()\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Extruded volume: {extruded}\")\n",
    "        print(f\"Start tag: {start_tag}\")\n",
    "\n",
    "    if not extruded:\n",
    "        raise Exception(\"Failed to extrude the face.\")\n",
    "    \n",
    "    \n",
    "    # We go through the created dim tags to create physical groups\n",
    "    for dimtag in extruded:\n",
    "        dim,tag = dimtag[:2]\n",
    "        if dim == 3:\n",
    "            # Create a physical group for the volume\n",
    "            create_physical_group(dim=dim, tags=[tag], name=name_volume or \"Extruded_Volume\", debug=debug)\n",
    "            add_to_bible(dimtag_entity=(dim, tag), entity_name=name_volume or \"Extruded_Volume\")\n",
    "        elif dim == 2 and name_extruded_faces:\n",
    "            # Create a physical group for the face\n",
    "            if isinstance(name_extruded_faces, list) and len(name_extruded_faces) > 0:\n",
    "                face_name = name_extruded_faces.pop(0)\n",
    "            else:\n",
    "                face_name = f\"Extruded_Face_{dimtag[1]}\"\n",
    "            create_physical_group(dim=dim, tags=[tag], name=face_name, debug=debug)\n",
    "            add_to_bible(dimtag_entity=(dim, tag), entity_name=face_name)\n",
    "\n",
    "    \n",
    "    return extruded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e1927df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### === Mesh generator === ###\n",
    "\n",
    "def create_solid_mesh(debug=False):\n",
    "    # Get the variables\n",
    "    global Bible\n",
    "    global start_tag\n",
    "    global Channel_Number\n",
    "    global Nozzle_Angle_Revolution\n",
    "    \n",
    "    # Generate the nozzle\n",
    "    print(\"=== GENERATING NOZZLE ===\")\n",
    "    nozzle_tag = generate_minimal_curved_element(Type=\"Nozzle\", debug=debug)\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Rotate the nozzle\n",
    "    print(\"=== ROTATING NOZZLE ===\")\n",
    "    nozzle_tag = extract_dimtags_list(nozzle_tag, dim=3)\n",
    "    nozzle_tag = gmsh_function_preserve_physical_groups(\"rotate\",[nozzle_tag, 0, 0, 0, 1, 0, 0, - Nozzle_Angle_Revolution / 2], debug=debug)\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Create the cooling channels\n",
    "    if Channel_Number > 0:\n",
    "        print(\"=== CALCULATING COOLING CHANNELS POSITIONS ===\")\n",
    "        indicators, overlap_initial_id, overlap_revolved_id = test_channel_positions(create_cooling_channel_positions(), debug=debug)\n",
    "\n",
    "        channels_to_create = sum(indicators)\n",
    "        \n",
    "        if sum(indicators) == 0:\n",
    "            print(\"=== NO COOLING CHANNELS TO CREATE ===\")\n",
    "            return nozzle_tag\n",
    "        else:\n",
    "            print(\"=== CREATING COOLING CHANNELS ===\")\n",
    "            cooling_channels_tags = create_cooling_channels(debug=debug, indicators_for_possible_channels=indicators)\n",
    "            \n",
    "            # Add the cooling channels to the nozzle\n",
    "            print(\"=== ADDING COOLING CHANNELS TO NOZZLE ===\")\n",
    "            nozzle_with_cooling_channels = add_cooling_channels(nozzle_tag, cooling_channels_tags, overlap_initial_id=overlap_initial_id, overlap_revolved_id=overlap_revolved_id, debug=debug)\n",
    "    else:\n",
    "        print(\"=== NO COOLING CHANNELS TO ADD ===\")\n",
    "        return nozzle_tag\n",
    "    \n",
    "    # Verify the result\n",
    "    if nozzle_with_cooling_channels is None:\n",
    "        raise Exception(\"Failed to create the solid mesh of the Nozzle.\")\n",
    "    return nozzle_with_cooling_channels\n",
    "\n",
    "def create_inner_fluid_mesh(debug=False):\n",
    "    \n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create the inner volume\n",
    "    print(\"=== CREATING INNER VOLUME ===\")\n",
    "    inner_volume = create_inner_volume_via_revolution(debug=debug)\n",
    "    \n",
    "    # Verify the result\n",
    "    if inner_volume is None:\n",
    "        raise Exception(\"Failed to create the inner volume of the Nozzle.\")\n",
    "    return inner_volume\n",
    "\n",
    "def create_outer_fluid_mesh(debug=False):\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    # Create the outer volume\n",
    "    print(\"=== CREATING OUTER VOLUME ===\")\n",
    "    outer_volume = create_exterior_volume_via_revolution(debug=debug)\n",
    "    \n",
    "    # Verify the result\n",
    "    if outer_volume is None:\n",
    "        raise Exception(\"Failed to create the outer volume of the Nozzle.\")\n",
    "    return outer_volume\n",
    "\n",
    "def create_cooling_channels_mesh(debug=False):\n",
    "    # Get the Bible\n",
    "    global Bible\n",
    "    \n",
    "    print(\"=== CALCULATING COOLING CHANNELS POSITIONS ===\")\n",
    "    indicators, overlap_initial_id, overlap_revolved_id = test_channel_positions(create_cooling_channel_positions(), debug=debug)\n",
    "\n",
    "    print(\"=== CREATING COOLING CHANNELS ===\")\n",
    "    cooling_channels_tags = create_cooling_channels(debug=debug, indicators_for_possible_channels=indicators)\n",
    "    if cooling_channels_tags is None:\n",
    "        raise Exception(\"Failed to create the cooling channels.\")\n",
    "    cooling_channels_dimtags = extract_dimtags_list(cooling_channels_tags, dim=3)\n",
    "        \n",
    "    print(\"=== CREATING COOLING CHANNELS BOOLEAN TOOL ===\")\n",
    "    cooling_channels_boolean_tool = create_cooling_channels_boolean_tool(debug=debug)\n",
    "    boolean_tool_dimtags = extract_dimtags_list(cooling_channels_boolean_tool, dim=3)\n",
    "\n",
    "    # Correct the bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)       \n",
    "    \n",
    "    # Intersect the cooling channels with the tool\n",
    "    print(\"=== INTERSECTING COOLING CHANNELS WITH TOOL ===\")\n",
    "    delete_entities_without_physical_group(dimDeletion=2, debug=debug)\n",
    "    cooling_channels_tags = gmsh_function_preserve_physical_groups(\"intersect\", [cooling_channels_dimtags, boolean_tool_dimtags], debug=debug)\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    gmsh.model.occ.synchronize()\n",
    "    \n",
    "    if cooling_channels_tags is None:\n",
    "        raise Exception(\"Failed to cut the cooling channels from the tool.\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "\n",
    "def create_u_channel(debug=False, \n",
    "                     length=1.0, width_Y=0.1, low_height_Z=0.02, high_height_Z=0.02,\n",
    "                     channel_height=0.06, channel_depth=0.05, origin=(0.0, 0.0, 0.0),\n",
    "                     name_prefix=\"U_Channel\", for_fluid=False):\n",
    "    \"\"\"\n",
    "    Create a U-shaped channel (rectangular prism) for testing purposes.\n",
    "    Parameters:\n",
    "        debug (bool): Enable debug output.\n",
    "        length (float): Length of the U-channel (extrusion in X direction).\n",
    "        width_Y (float): Width of the U-channel (Y direction).\n",
    "        low_height_Z (float): Height of the U-channel (Z direction).\n",
    "        high_height_Z (float): Height of the U-channel (Z direction).\n",
    "        channel_height (float): Height of the U-channel (Z direction).\n",
    "        channel_depth (float): Depth of the U-channel (X direction).\n",
    "        origin (tuple): Origin (x, y, z) of the bottom-left corner.\n",
    "        name_prefix (str): Prefix for naming entities.\n",
    "        for_fluid (bool): If True, create a fluid channel, otherwise a solid channel.\n",
    "    Returns:\n",
    "        int: Tag of the created volume.\n",
    "    \"\"\"\n",
    "    global Bible\n",
    "\n",
    "    \n",
    "    \"\"\"Schematic\n",
    "    U-channel creation:\n",
    "    \n",
    "        +-----------------+\n",
    "       /                 /|\n",
    "      /                 / |\n",
    "     /                 /  |\n",
    "    +-----------------+   |\n",
    "    |                 |   |\n",
    "    +-------+         |   +\n",
    "     /      |         |  /\n",
    "    +-------+         | /\n",
    "    |                 |/\n",
    "    +-----------------+\n",
    "    \n",
    "    \"\"\"\n",
    "    x0, y0, z0 = origin\n",
    "    points = [\n",
    "        [x0, y0, z0],\n",
    "        \n",
    "    ]\n",
    "    # Define the points of the face to extrude\n",
    "    p0 = [x0, y0, z0]  # Bottom-left\n",
    "    p1 = [x0, y0 + width_Y, z0]  # Bottom-right\n",
    "    p2 = [x0, y0 + width_Y, z0 + low_height_Z + high_height_Z + channel_height]  # Top-right\n",
    "    p3 = [x0, y0, z0 + low_height_Z + high_height_Z + channel_height]  # Top-left\n",
    "    p4 = [x0, y0, z0 + low_height_Z + channel_height]  # Top-left channel\n",
    "    p5 = [x0, y0 + channel_depth, z0 + low_height_Z + channel_height]  # Top-right channel\n",
    "    p6 = [x0, y0 + channel_depth, z0 + low_height_Z]  # Bottom-right channel\n",
    "    p7 = [x0, y0, z0 + low_height_Z]  # Bottom-left channel\n",
    "    \n",
    "    if not for_fluid:\n",
    "        points = [p0, p1, p2, p3, p4, p5, p6, p7]\n",
    "\n",
    "        names_lines = [\n",
    "            f\"{name_prefix}_Line_0\",  # bottom edge\n",
    "            f\"{name_prefix}_Line_1\",  # right edge\n",
    "            f\"{name_prefix}_Line_2\",  # top edge\n",
    "            f\"{name_prefix}_Line_3\",  # left edge\n",
    "            f\"{name_prefix}_Line_4\",  # channel bottom edge\n",
    "            f\"{name_prefix}_Line_5\",  # channel right edge\n",
    "            f\"{name_prefix}_Line_6\",  # channel top edge\n",
    "            f\"{name_prefix}_Line_7\",  # channel left edge\n",
    "        ]\n",
    "\n",
    "        names_extruded_faces = [\n",
    "            f\"{name_prefix}_Exit\",  # bottom face\n",
    "            f\"{name_prefix}_Bottom\",  # top face\n",
    "            f\"{name_prefix}_Right\",  # side face 1\n",
    "            f\"{name_prefix}_Top\",  # side face 2\n",
    "            f\"{name_prefix}_Left_Top\",  # side face 3\n",
    "            f\"{name_prefix}_Channel_Top\",  # side face 4\n",
    "            f\"{name_prefix}_Channel_Right\",  # side face 5\n",
    "            f\"{name_prefix}_Channel_Bottom\",  # side face 6\n",
    "            f\"{name_prefix}_Left_Bottom\"  # channel entry face\n",
    "        ]\n",
    "        \n",
    "    else:\n",
    "        points = [p4, p5, p6, p7]  # Only the channel part\n",
    "        \n",
    "        names_lines = [\n",
    "            f\"{name_prefix}_Line_0\",  # channel bottom edge\n",
    "            f\"{name_prefix}_Line_1\",  # channel right edge\n",
    "            f\"{name_prefix}_Line_2\",  # channel top edge\n",
    "            f\"{name_prefix}_Line_3\"   # channel left edge\n",
    "        ]\n",
    "        \n",
    "        names_extruded_faces = [\n",
    "            f\"{name_prefix}_Exit\",  # bottom face\n",
    "            f\"{name_prefix}_Top\",  # top face\n",
    "            f\"{name_prefix}_Right\",  # side face 1\n",
    "            f\"{name_prefix}_Bottom\",  # side face 2\n",
    "            f\"{name_prefix}_Left\",  # side face 3\n",
    "        ]\n",
    "    \n",
    "    # Create the surface from the points\n",
    "    surface_tag, point_tags, line_tags = create_surface_from_N_points(\n",
    "        points,\n",
    "        name_surface=f\"{name_prefix}_Entry\",\n",
    "        names_lines=names_lines,\n",
    "        create_group=True,\n",
    "        debug=debug\n",
    "    )\n",
    "    # Extrude the surface to create a volume\n",
    "    extrusion_vector = [length, 0, 0]  # Extrude in the X direction\n",
    "    \n",
    "    volume_tag = volume_extrude_face(\n",
    "        surface_tag,\n",
    "        extrusion_vector,\n",
    "        name_volume=f\"{name_prefix}_Volume\",\n",
    "        name_extruded_faces=names_extruded_faces,\n",
    "        create_group=True,\n",
    "        debug=debug\n",
    "    )\n",
    "    if volume_tag is None:\n",
    "        raise Exception(\"Failed to create the U-channel volume.\")\n",
    "\n",
    "    # Correct the Bible and optionally print info\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    if debug:\n",
    "        print(f\"U-channel created: volume_tag={volume_tag}, surface_tag={surface_tag}, points={points}\")\n",
    "\n",
    "    return volume_tag\n",
    "\n",
    "def u_channel_values(debug=False):\n",
    "    \"\"\"Print the values used to create the U-channel.\"\"\"\n",
    "    length = 0.1  # Length of the U-channel\n",
    "    width_Y = 0.002  # Width of the U-channel\n",
    "    low_height_Z = 0.001  # Height of the U-channel (bottom part)\n",
    "    high_height_Z = 0.001  # Height of the U-channel (top part)\n",
    "    channel_height = 0.004  # Height of the U-channel (channel part)\n",
    "    channel_depth = 0.001  # Depth of the U-channel (channel part)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"U-Channel Values:\\n\"\n",
    "              f\"Length: {length}\\n\"\n",
    "              f\"Width Y: {width_Y}\\n\"\n",
    "              f\"Low Height Z: {low_height_Z}\\n\"\n",
    "              f\"High Height Z: {high_height_Z}\\n\"\n",
    "              f\"Channel Height: {channel_height}\\n\"\n",
    "              f\"Channel Depth: {channel_depth}\")\n",
    "    \n",
    "    return {\n",
    "        \"length\": length,\n",
    "        \"width_Y\": width_Y,\n",
    "        \"low_height_Z\": low_height_Z,\n",
    "        \"high_height_Z\": high_height_Z,\n",
    "        \"channel_height\": channel_height,\n",
    "        \"channel_depth\": channel_depth\n",
    "    }\n",
    "    \n",
    "def create_u_channel_solid_mesh(debug=False):\n",
    "    \"\"\"Create a solid mesh for the U-channel.\"\"\"\n",
    "    \n",
    "    # Get the U-channel values\n",
    "    u_channel_params = u_channel_values(debug=debug)\n",
    "    \n",
    "    # Create the U-channel\n",
    "    print(\"=== CREATING U-CHANNEL ===\")\n",
    "    u_channel_tag = create_u_channel(\n",
    "        debug=debug,\n",
    "        length=u_channel_params[\"length\"],\n",
    "        width_Y=u_channel_params[\"width_Y\"],\n",
    "        low_height_Z=u_channel_params[\"low_height_Z\"],\n",
    "        high_height_Z=u_channel_params[\"high_height_Z\"],\n",
    "        channel_height=u_channel_params[\"channel_height\"],\n",
    "        channel_depth=u_channel_params[\"channel_depth\"],\n",
    "        origin=(0.0, 0.0, 0.0),\n",
    "        name_prefix=\"U_Channel_Solid\",\n",
    "        for_fluid=False\n",
    "    )\n",
    "    \n",
    "    # Verify the result\n",
    "    if u_channel_tag is None:\n",
    "        raise Exception(\"Failed to create the U-channel solid mesh.\")\n",
    "    \n",
    "    return u_channel_tag\n",
    "\n",
    "def create_u_channel_fluid_mesh(debug=False):\n",
    "    \"\"\"Create a fluid mesh for the U-channel.\"\"\"\n",
    "    \n",
    "    # Get the U-channel values\n",
    "    u_channel_params = u_channel_values(debug=debug)\n",
    "    \n",
    "    # Create the U-channel\n",
    "    print(\"=== CREATING U-CHANNEL FLUID ===\")\n",
    "    u_channel_tag = create_u_channel(\n",
    "        debug=debug,\n",
    "        length=u_channel_params[\"length\"],\n",
    "        width_Y=u_channel_params[\"width_Y\"],\n",
    "        low_height_Z=u_channel_params[\"low_height_Z\"],\n",
    "        high_height_Z=u_channel_params[\"high_height_Z\"],\n",
    "        channel_height=u_channel_params[\"channel_height\"],\n",
    "        channel_depth=u_channel_params[\"channel_depth\"],\n",
    "        origin=(0.0, 0.0, 0.0),\n",
    "        name_prefix=\"U_Channel_Fluid\",\n",
    "        for_fluid=True\n",
    "    )\n",
    "    \n",
    "    # Verify the result\n",
    "    if u_channel_tag is None:\n",
    "        raise Exception(\"Failed to create the U-channel fluid mesh.\")\n",
    "    \n",
    "    return u_channel_tag\n",
    "\n",
    "def mesh_generator(mesh_to_generate, path_for_save=None, debug=False):\n",
    "    \"\"\"Generate the mesh for the rocket engine.\"\"\"\n",
    "    \n",
    "    # Choose the generator\n",
    "    precision = 1\n",
    "    groups_to_delete = None\n",
    "    if mesh_to_generate == \"Solid\":\n",
    "        generator_used = create_solid_mesh\n",
    "    elif mesh_to_generate == \"Inner_Fluid\":\n",
    "        generator_used = create_inner_fluid_mesh\n",
    "    elif mesh_to_generate == \"Outer_Fluid\":\n",
    "        generator_used = create_outer_fluid_mesh\n",
    "    elif mesh_to_generate == \"Cooling_Channels\":\n",
    "        generator_used = create_cooling_channels_mesh\n",
    "    elif mesh_to_generate == \"U_Channel_Fluid\":\n",
    "        generator_used = create_u_channel_fluid_mesh\n",
    "        precision = 1e-5\n",
    "    elif mesh_to_generate == \"U_Channel_Solid\":\n",
    "        generator_used = create_u_channel_solid_mesh\n",
    "        precision = 1e-5\n",
    "    else:\n",
    "        raise ValueError(\"Mesh generator not recognized. Use 'Solid', 'Inner_Fluid', 'Outer_Fluid' or 'Cooling_Channels'.\")\n",
    "    \n",
    "    print(f\"%%%%%%% ========= CREATING MESH {mesh_to_generate} ========== %%%%%%%\")\n",
    "    \n",
    "    # Get the variables\n",
    "    global Bible\n",
    "    global start_tag\n",
    "    global Channel_Number\n",
    "    global start_tag\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Cooling_Channel_Angle_Offset\n",
    "    global Radial_Reinforcement_Number\n",
    "    global Radial_Reinforcement_Density\n",
    "    global DEBUG\n",
    "    global MULTITHREADING\n",
    "    \n",
    "    # Overwrite and define some parameters\n",
    "    DEBUG = debug\n",
    "    start_tag = 1\n",
    "    \n",
    "    if MULTITHREADING is not None:\n",
    "        thread_number = MULTITHREADING\n",
    "    else:\n",
    "        thread_number = 1\n",
    "        \n",
    "    try:\n",
    "        if Channel_Number is not None:\n",
    "            channel_number_temp = Channel_Number # It needs to be saved because the profile generator will overwrite it\n",
    "        else:\n",
    "            channel_number_temp = None\n",
    "    except NameError:\n",
    "        channel_number_temp = None\n",
    "    \n",
    "    #Get rid of a past gmsh instance\n",
    "    try:\n",
    "        gmsh.finalize()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Initialize GMSH\n",
    "    print(\"=== INITIALIZING GMSH ===\")\n",
    "    GMSH_initialise(caracteristic_length_min=min(min_carac_length/500, precision), thread_number=thread_number)\n",
    "    \n",
    "    # Initialize the Bible\n",
    "    print(\"=== INITIALIZING BIBLE ===\")\n",
    "    Bible = create_bible()\n",
    "    \n",
    "    # Generate the profiles\n",
    "    print(\"=== GENERATING PROFILES ===\")\n",
    "    generate_profiles(debug=debug)\n",
    "    if channel_number_temp is not None:\n",
    "        Channel_Number = channel_number_temp  # Restore the channel number\n",
    "    \n",
    "    # Use the generator to create the mesh\n",
    "    result = generator_used(debug=debug)\n",
    "    \n",
    "    # Remove entities without physical group\n",
    "    print(\"=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\")\n",
    "    delete_entities_without_physical_group(dimDeletion=2, debug=debug)\n",
    "    \n",
    "    if groups_to_delete is not None:\n",
    "        # Delete all the physical groups with the prefix \"Study_Volume_\"\n",
    "        print(f\"=== DELETING PHYSICAL GROUPS WITH PREFIX {groups_to_delete} ===\")\n",
    "        gmsh.model.occ.synchronize()\n",
    "        for dimtag in gmsh.model.getPhysicalGroups():\n",
    "            name = gmsh.model.getPhysicalName(dim=dimtag[0], tag=dimtag[1])\n",
    "            if name.startswith(groups_to_delete):\n",
    "                # Delete entities with this physical group\n",
    "                for entity in gmsh.model.getEntitiesForPhysicalGroup(dim=dimtag[0], tag=dimtag[1]):\n",
    "                    dim = dimtag[0]\n",
    "                    dimtag_entity = (dimtag[0], entity)\n",
    "                    print(f\"Deleting entity: {dimtag_entity} from physical group: {name}\")\n",
    "                    gmsh.model.removeEntities([dimtag_entity],recursive=True)\n",
    "                    gmsh.model.occ.remove([dimtag_entity],recursive=True)\n",
    "                    gmsh.model.occ.synchronize()\n",
    "                print(f\"Deleting physical group: {name} with tag: {dimtag[1]}\")\n",
    "                gmsh.model.remove_physical_groups([dimtag])\n",
    "                gmsh.model.occ.synchronize()\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Save in a file\n",
    "    print(\"=== SAVING MESH ===\")\n",
    "    complete_path = path_for_save + f\"{mesh_to_generate}_mesh\" if path_for_save else f\"{mesh_to_generate}_mesh.msh\"\n",
    "\n",
    "    gmsh.model.occ.synchronize()\n",
    "    print(\"Healing shapes in the model...\")\n",
    "    gmsh.model.occ.healShapes()\n",
    "    gmsh.model.occ.synchronize()\n",
    "    gmsh.model.occ.removeAllDuplicates()\n",
    "    print(\"Removing duplicates in the model...\")    \n",
    "    gmsh.model.occ.synchronize()\n",
    "    # Output in .brep\n",
    "    if True:\n",
    "        gmsh.write(complete_path + \".brep\")\n",
    "        print(f\"Mesh saved in {complete_path}.brep\")\n",
    "    print(\"Generating the mesh...\")\n",
    "    \n",
    "    gmsh.model.mesh.generate(DIM_MESH)\n",
    "    \n",
    "    if output_in_msh:\n",
    "        gmsh.write(complete_path+ \".msh\")\n",
    "        print(f\"Mesh saved in {complete_path}.msh\")\n",
    "    if output_in_stl:\n",
    "        gmsh.write(complete_path + \".stl\")\n",
    "        print(f\"Mesh saved in {complete_path}.stl\")\n",
    "    if other_type_output is not None:\n",
    "        gmsh.write(complete_path + f\"{other_type_output}\")\n",
    "        print(f\"Mesh saved in {complete_path}{other_type_output}\")\n",
    "    \n",
    "    # Correct the Bible\n",
    "    print(\"=== CORRECTING BIBLE ===\")\n",
    "    correct_bible_gmsh(debug=debug)\n",
    "    \n",
    "    # Finalize GMSH\n",
    "    gmsh.finalize()\n",
    "    print(\"=== MESH DONE ===\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a07b70ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%% ========= CREATING MESH Solid ========== %%%%%%%\n",
      "=== INITIALIZING GMSH ===\n",
      "=== GMSH initialized ===\n",
      "Minumum caracterist length used : 1e-05 \n",
      "Maximum caracterist length used : 0.01 \n",
      "Number of threads used : 10\n",
      "=== INITIALIZING BIBLE ===\n",
      "=== GENERATING PROFILES ===\n",
      "Profiles defined from CSV file.\n",
      "=== GENERATING NOZZLE ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== ROTATING NOZZLE ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== CALCULATING COOLING CHANNELS POSITIONS ===\n",
      "=== CREATING COOLING CHANNELS ===\n",
      "=== Cooling channel 1 out of 1 created with tag: [(3, 2)]===\n",
      "=== ADDING COOLING CHANNELS TO NOZZLE ===\n",
      "Nozzle volume tags: []\n",
      "Cooling channels tags: [(3, 2)]\n",
      "[DEBUG] Result of the assignment : ['(2, 1) -> (2, 9)', '(2, 2) -> (2, 11)', '(2, 3) -> (2, 18)', '(2, 4) -> (2, 10)', '(2, 5) -> (2, 12)', '(2, 6) -> (2, 13)', '(2, 7) -> (2, 7)', '(2, 8) -> (2, 8)', '(2, 9) -> (2, 16)', '(2, 11) -> (2, 15)', '(2, 13) -> (2, 14)', '(2, 14) -> (2, 17)', '(3, 1) -> (3, 1)']\n",
      "[0, 3, 4, 5, 6, 1, 14, 15, 12, 10, 11, 13, 2]\n",
      "Cooling channels added to the nozzle with the resulting tag: ([(3, 1)], [[(3, 1)], []])\n",
      "=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\n",
      "Error removing entity 7: Surface 7 does not exist\n",
      "Entity 7 is not deleted.\n",
      "Error removing entity 8: Surface 8 does not exist\n",
      "Entity 8 is not deleted.\n",
      "=== CORRECTING BIBLE ===\n",
      "=== SAVING MESH ===\n",
      "Healing shapes in the model...\n",
      "Removing duplicates in the model...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Solid_mesh.brep\n",
      "Generating the mesh...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Solid_mesh.msh\n",
      "=== CORRECTING BIBLE ===\n",
      "=== MESH DONE ===\n",
      "%%%%%%% ========= CREATING MESH Inner_Fluid ========== %%%%%%%\n",
      "=== INITIALIZING GMSH ===\n",
      "=== GMSH initialized ===\n",
      "Minumum caracterist length used : 1e-05 \n",
      "Maximum caracterist length used : 0.01 \n",
      "Number of threads used : 10\n",
      "=== INITIALIZING BIBLE ===\n",
      "=== GENERATING PROFILES ===\n",
      "Profiles defined from CSV file.\n",
      "=== CREATING INNER VOLUME ===\n",
      "=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== SAVING MESH ===\n",
      "Healing shapes in the model...\n",
      "Removing duplicates in the model...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Inner_Fluid_mesh.brep\n",
      "Generating the mesh...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Inner_Fluid_mesh.msh\n",
      "=== CORRECTING BIBLE ===\n",
      "=== MESH DONE ===\n",
      "%%%%%%% ========= CREATING MESH Outer_Fluid ========== %%%%%%%\n",
      "=== INITIALIZING GMSH ===\n",
      "=== GMSH initialized ===\n",
      "Minumum caracterist length used : 1e-05 \n",
      "Maximum caracterist length used : 0.01 \n",
      "Number of threads used : 10\n",
      "=== INITIALIZING BIBLE ===\n",
      "=== GENERATING PROFILES ===\n",
      "Profiles defined from CSV file.\n",
      "=== CREATING OUTER VOLUME ===\n",
      "=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== SAVING MESH ===\n",
      "Healing shapes in the model...\n",
      "Removing duplicates in the model...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Outer_Fluid_mesh.brep\n",
      "Generating the mesh...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Outer_Fluid_mesh.msh\n",
      "=== CORRECTING BIBLE ===\n",
      "=== MESH DONE ===\n",
      "%%%%%%% ========= CREATING MESH Cooling_Channels ========== %%%%%%%\n",
      "=== INITIALIZING GMSH ===\n",
      "=== GMSH initialized ===\n",
      "Minumum caracterist length used : 1e-05 \n",
      "Maximum caracterist length used : 0.01 \n",
      "Number of threads used : 10\n",
      "=== INITIALIZING BIBLE ===\n",
      "=== GENERATING PROFILES ===\n",
      "Profiles defined from CSV file.\n",
      "=== CALCULATING COOLING CHANNELS POSITIONS ===\n",
      "=== CREATING COOLING CHANNELS ===\n",
      "=== Cooling channel 1 out of 1 created with tag: [(3, 1)]===\n",
      "=== CREATING COOLING CHANNELS BOOLEAN TOOL ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== INTERSECTING COOLING CHANNELS WITH TOOL ===\n",
      "Error removing entity 1: Surface 1 does not exist\n",
      "Entity 1 is not deleted.\n",
      "Error removing entity 2: Surface 2 does not exist\n",
      "Entity 2 is not deleted.\n",
      "[DEBUG] Result of the assignment : ['(2, 3) -> (2, 1)', '(2, 5) -> (2, 6)', '(2, 6) -> (2, 5)', '(2, 7) -> (2, 4)', '(2, 11) -> (2, 3)', '(2, 12) -> (2, 2)', '(3, 1) -> (3, 1)']\n",
      "[5, 3, 1, 4, 13, 14, 0]\n",
      "=== CORRECTING BIBLE ===\n",
      "=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== SAVING MESH ===\n",
      "Healing shapes in the model...\n",
      "Removing duplicates in the model...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Cooling_Channels_mesh.brep\n",
      "Generating the mesh...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/Cooling_Channels_mesh.msh\n",
      "=== CORRECTING BIBLE ===\n",
      "=== MESH DONE ===\n",
      "%%%%%%% ========= CREATING MESH U_Channel_Solid ========== %%%%%%%\n",
      "=== INITIALIZING GMSH ===\n",
      "=== GMSH initialized ===\n",
      "Minumum caracterist length used : 1e-05 \n",
      "Maximum caracterist length used : 0.01 \n",
      "Number of threads used : 10\n",
      "=== INITIALIZING BIBLE ===\n",
      "=== GENERATING PROFILES ===\n",
      "Profiles defined from CSV file.\n",
      "=== CREATING U-CHANNEL ===\n",
      "=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== SAVING MESH ===\n",
      "Healing shapes in the model...\n",
      "Removing duplicates in the model...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/U_Channel_Solid_mesh.brep\n",
      "Generating the mesh...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/U_Channel_Solid_mesh.msh\n",
      "=== CORRECTING BIBLE ===\n",
      "=== MESH DONE ===\n",
      "%%%%%%% ========= CREATING MESH U_Channel_Fluid ========== %%%%%%%\n",
      "=== INITIALIZING GMSH ===\n",
      "=== GMSH initialized ===\n",
      "Minumum caracterist length used : 1e-05 \n",
      "Maximum caracterist length used : 0.01 \n",
      "Number of threads used : 10\n",
      "=== INITIALIZING BIBLE ===\n",
      "=== GENERATING PROFILES ===\n",
      "Profiles defined from CSV file.\n",
      "=== CREATING U-CHANNEL FLUID ===\n",
      "=== DELETING ENTITIES WITHOUT PHYSICAL GROUP ===\n",
      "=== CORRECTING BIBLE ===\n",
      "=== SAVING MESH ===\n",
      "Healing shapes in the model...\n",
      "Removing duplicates in the model...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/U_Channel_Fluid_mesh.brep\n",
      "Generating the mesh...\n",
      "Mesh saved in c:\\Users\\thoma\\Documents\\ArianeGroup\\Mesh_Generator\\Notebook_version\\Rocket_Engine_Meshes/U_Channel_Fluid_mesh.msh\n",
      "=== CORRECTING BIBLE ===\n",
      "=== MESH DONE ===\n",
      "All meshes generated successfully.\n"
     ]
    }
   ],
   "source": [
    "### === Main function === ###\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Get the parameters from the user\n",
    "    global Channel_Number\n",
    "    global start_tag\n",
    "    global Nozzle_Angle_Revolution\n",
    "    global Cooling_Channel_Angle_Offset\n",
    "    global Radial_Reinforcement_Number\n",
    "    global Radial_Reinforcement_Density\n",
    "    global DEBUG\n",
    "    global output_folder\n",
    "    \n",
    "    # Overwrite data for debug \n",
    "    Cooling_Channel_Angle_Offset = 0.0\n",
    "    Nozzle_Angle_Revolution = 2*np.pi /100\n",
    "    #Channel_Number = 0\n",
    "    Radial_Reinforcement_Number = 0.0\n",
    "    Radial_Reinforcement_Density = lambda x:  1.0 / (1.0 + np.exp(-x))\n",
    "    DEBUG = False\n",
    "    \n",
    "    # Generate all the meshes in a local folder in the current directory \n",
    "    mesh_folder = output_folder\n",
    "    if not os.path.exists(mesh_folder):\n",
    "        os.makedirs(mesh_folder)\n",
    "    \n",
    "    # Generate the meshes\n",
    "    mesh_generator(\"Solid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"Inner_Fluid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"Outer_Fluid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"Cooling_Channels\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"U_Channel_Solid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    mesh_generator(\"U_Channel_Fluid\", path_for_save=mesh_folder, debug=DEBUG)\n",
    "    print(\"All meshes generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
